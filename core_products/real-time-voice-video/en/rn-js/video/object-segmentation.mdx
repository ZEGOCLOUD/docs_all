---
articleID: 17973
date: "2024-09-06"
---
# Object Segmentation

- - -

## Feature Overview

Object Segmentation is a value-added capability provided by the Express SDK. It uses AI algorithms to identify content in video frames and set `transparency information` for each pixel. Pixels in the main subject area are set to "opaque", while pixels outside the main subject area are set to "transparent". Developers can use this transparency information to apply different processing to the main subject and background areas, enabling various features.

<Warning title="Note">
- The official SDK does not include "Object Segmentation" related features. If needed, please contact ZEGOCLOUD Technical Support for a special build and provide your AppID to enable the relevant permissions.
- "Object Segmentation" is a paid feature. Please contact ZEGOCLOUD sales for trial access or official pricing information.
</Warning>



### Object Segmentation Types

For users in different environments, ZEGO provides two segmentation capabilities: "Green Screen Background Segmentation" and "Arbitrary Background Segmentation".

<table>

<tbody><tr>
<th>Segmentation Type</th>
<th>Green Screen Background Segmentation</th>
<th>Arbitrary Background Segmentation</th>
</tr>
<tr>
<th>Capability Description</th>
<td><p>When users have set up a green screen, the main subject in non-green screen areas can be retained.</p><p>Suitable for e-commerce live streaming, online exams, and other scenarios.</p></td>
<td><p>Most users don't have the conditions to set up a green screen. Through ZEGO's arbitrary background segmentation capability, the main subject in the frame can be identified without a green screen.</p><p>Suitable for online education, video conferences, and other scenarios.</p></td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_greenscreen.png" /></Frame></td>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_realenvironment.jpg" /></Frame></td>
</tr>
</tbody></table>

### Feature Scenarios

Based on the Object Segmentation capability, developers can implement scenarios such as background blur, virtual background, presenter mode, and multi-user real-time interaction, creating more diverse interactive experiences.

<table>

<tbody><tr>
<th>Feature</th>
<th>Background Blur</th>
<th>Virtual Background</th>
<th>Transparent Background</th>
<th>Object Segmentation and Transmission</th>
</tr>
<tr>
<th>Feature Description</th>
<td>Blur the area outside the main subject.</td>
<td>Replace the area outside the main subject with custom images or colors.</td>
<td><p>Render the main subject over other video content locally.</p><p>For example, implement presenter mode over screen sharing or playing video content.</p></td>
<td>Combine with the Alpha channel data transmission capability provided by Express SDK to transmit the segmented main subject to the playing stream side, where subject rendering is performed, achieving the visual effect of multiple users in different locations appearing in the same scene in real-time.</td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/6364d2bc42.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/de1e9cf26f.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/5bc5b6b70d.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/multiplayer.jpeg" /></Frame></td>
</tr>
</tbody></table>


### Hardware Compatibility

<table>

<tbody><tr>
<th>Platform</th>
<th>Hardware Requirements</th>
</tr>
<tr>
<td>Android</td>
<td><ul><li><p>Qualcomm Snapdragon chips:</p><ul><li>Snapdragon 6 series: Snapdragon 675 and above</li><li>Snapdragon 7 series: Snapdragon 730 and above</li><li>Snapdragon 8 series: Snapdragon 835 and above</li></ul></li><li><p>HiSilicon Kirin chips:</p><ul><li>Kirin 8 series: Kirin 820 and above</li><li>Kirin 9 series: Kirin 980 and above</li></ul></li><li><p>MediaTek chips:</p><ul><li>Helio P series: Helio P60 and above</li><li>Dimensity series: Dimensity 820 and above</li></ul></li><li>Samsung chips: Exynos 1080 and above</li></ul></td>
</tr>
<tr>
<td>iOS</td>
<td>A-series chips: Apple A9 and above, e.g., iPhone 6s</td>
</tr>
</tbody></table>


**Please note that when using ReactNative SDK on the above platforms, hardware compatibility requirements are the same.**

## Prerequisites

Before using the Object Segmentation feature, ensure that:

- You have contacted ZEGOCLOUD Technical Support for a special build.

- You have created a project in the [ZEGOCLOUD Console](https://console.zegocloud.com) and applied for a valid AppID and AppSign. For details, refer to [Console - Project Information](/console/project-info).
- You have integrated ZEGO Express SDK in your project and implemented basic audio/video stream publishing and playing. For details, refer to [Quick Start - Integration](/real-time-video-rn/quick-start/integrating-sdk) and [Quick Start - Implementation](/real-time-video-rn/quick-start/implementing-video-call).


## Implementation Flow

<Warning title="Note">
- Enabling Object Segmentation will consume additional system resources. To ensure user experience, currently only one channel's published stream can have Object Segmentation enabled.
- If using custom pre-processing third-party filters, ensure that the third-party filters support Alpha channel pass-through functionality.
</Warning>



<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/subject_segmentation_rn.png" /></Frame>

Note that developers can choose whether to implement the **(Optional)** steps shown in the diagram above based on their business scenario needs. For implementation details, refer to the specific instructions below.

### Initialization and Room Login

For the specific flow of initialization and room login, refer to "[Create Engine](/real-time-video-rn/quick-start/implementing-video-call)" and "[Login Room](/real-time-video-rn/quick-start/implementing-video-call)" in the Implementing Video Call documentation.


### Listen for Object Segmentation State Callback

Call the [videoObjectSegmentationStateChanged](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/interfaces/_zegoexpresseventhandler_.zegoeventlistener.html#videoobjectsegmentationstatechanged) interface to listen for Object Segmentation state callbacks.

<Warning title="Note">
The Object Segmentation state callback depends on starting preview or publishing stream. That is, to listen for the [videoObjectSegmentationStateChanged](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/interfaces/_zegoexpresseventhandler_.zegoeventlistener.html#videoobjectsegmentationstatechanged) callback, you need to call preview [startPreview](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#startpreview) or publishing stream [startPublishingStream](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#startpublishingstream).
</Warning>



```javascript
ZegoExpressEngine.instance().on('videoObjectSegmentationStateChanged', (state, channel, errorCdoe) => {
    console.log("JS videoObjectSegmentationStateChanged: " + state + " channel: " + channel + " errorCode: " + errorCdoe);
})
```


### Use Object Segmentation to Implement Different Business Features

<Warning title="Note">


If developers need to update the Object Segmentation type or background processing type, they need to modify the [ZegoObjectSegmentationConfig](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressdefines_.zegoobjectsegmentationconfig.html) configuration and call the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface again to enable Object Segmentation. The Object Segmentation effect will be updated, and the result will be notified to developers through the [videoObjectSegmentationStateChanged](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/interfaces/_zegoexpresseventhandler_.zegoeventlistener.html#videoobjectsegmentationstatechanged) callback.

</Warning>



#### Background Blur

<Accordion title="Implement background blur using Object Segmentation" defaultOpen="false">
Call the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface to enable Object Segmentation and set the background processing type to "Blur".

```javascript
let config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.AnyBackground;//Select the Object Segmentation type to enable based on actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessType.Blur;//Set background processing mode to blur
config.backgroundConfig.blurLevel = ZegoBackgroundBlurLevel.Medium;//Set background blur level to medium
ZegoExpressEngine.instance().enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.Main);//Enable Object Segmentation
```
</Accordion>

#### Virtual Background

<Accordion title="Implement virtual background using Object Segmentation" defaultOpen="false">
<Warning title="Note">
- When using this feature, developers should pay attention to the aspect ratio of custom images, otherwise parts of the image that exceed the view will be cropped.
- Currently supports "PNG" and "JPEG" image formats, i.e., image files with ".png", ".jpg", and ".jpeg" extensions.
</Warning>



Call the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface to enable Object Segmentation and set the background processing type to "Image".

```javascript
let config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.AnyBackground;//Select the Object Segmentation type to enable based on actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessType.Image;//Set background processing mode to image
config.backgroundConfig.imageURL = "<image_path>";//Set background image path
ZegoExpressEngine.instance().enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.Main);//Enable Object Segmentation
```
</Accordion>

#### Transparent Background

<a name="enableAlphaChannelVideoEncoder"></a>

<Accordion title="Implement transparent background using Object Segmentation" defaultOpen="false">
<Warning title="Note">


If developers need to implement business functions similar to "Presenter Mode", they need to mix the "main subject video" with "video content to be mixed" into a single video stream on the business side.


</Warning>



Call the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface to enable Object Segmentation and set the background processing type to "Transparent".

```javascript
let config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.AnyBackground;//Select the Object Segmentation type to enable based on actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessType.Transparent;//Set background processing mode to transparent
ZegoExpressEngine.instance().enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.Main);//Enable Object Segmentation
```
</Accordion>

### (Optional) Use Alpha Channel to Transmit Segmented Subject

<Accordion title="Use Alpha Channel to transmit segmented subject" defaultOpen="false">
If the publishing stream side needs to transmit the segmented subject video to the playing stream side through the Alpha channel for subject rendering, first call the [enableAlphaChannelVideoEncoder](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablealphachannelvideoencoder) interface to set the encoder to support the transparent channel, then call the [startPublishingStream](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#startpublishingstream) interface to publish the stream for smooth transmission to the playing stream side.

<Warning title="Note">


Currently only supports transparent channel data arranged below RGB or YUV data.

</Warning>



- Enable Alpha channel data transmission:

    ```javascript
    let layoutType = ZegoAlphaLayoutType.Bottom; // Transparent channel data arranged below RGB or YUV data
    ZegoExpressEngine.instance().enableAlphaChannelVideoEncoder(true, layoutType, ZegoPublishChannel.Main); // Enable encoder to support transparent channel
    ```

- Disable Alpha channel data transmission:

    ```javascript
    let layoutType = ZegoAlphaLayoutType.Bottom; // Transparent channel data arranged below RGB or YUV data
    ZegoExpressEngine.instance().enableAlphaChannelVideoEncoder(false, layoutType, ZegoPublishChannel.Main); // Disable encoder transparent channel support
    ```
</Accordion>

### Start Preview and Publish Stream

After enabling the Object Segmentation feature through the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface, you can start preview.

<Note title="Note">
Developers can also start preview first, then enable Object Segmentation. This article introduces enabling Object Segmentation first, then starting preview.
</Note>



```javascript
let view = {"reactTag": findNodeHandle(this.refs.zego_preview_view), "viewMode": 0, "backgroundColor": 0};
view.alphaBlend = true;//Enable internal rendering Alpha blending, which supports Alpha blending between the segmented subject and background layer
ZegoExpressEngine.instance().startPreview(view);
ZegoExpressEngine.instance().startPublishingStream(streamID);
```

### (Optional) Set Alpha Channel Rendering on Playing Stream Side and Start Playing Stream

<Accordion title="Set Alpha Channel rendering on playing stream side and start playing stream" defaultOpen="false">
<Warning title="Note">


Alpha channel rendering on the playing stream side is only required when the publishing stream side has enabled Alpha channel transmission.

</Warning>



```javascript
let view = {"reactTag": findNodeHandle(this.refs.zego_play_view), "viewMode": 0, "backgroundColor": 0};
view.alphaBlend = true;//Enable internal rendering Alpha blending, which supports Alpha blending between the segmented subject and background layer
ZegoExpressEngine.instance().startPlayingStream(streamID, canvas);
```
</Accordion>

### Disable Object Segmentation

Call the [enableVideoObjectSegmentation](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#enablevideoobjectsegmentation) interface to disable Object Segmentation.

```javascript
let objectType = ZegoObjectSegmentationType.AnyBackground;//Select the Object Segmentation type to disable based on actual situation
ZegoExpressEngine.instance().enableVideoObjectSegmentation(false, objectType, ZegoPublishChannel.Main);//Disable Object Segmentation
```

### Destroy Engine

Call the [destroyEngine](https://www.zegocloud.com/docs/unique-api/express-video-sdk/en/javascript_react-native/classes/_zegoexpressengine_.zegoexpressengine.html#destroyengine) interface to destroy the engine.

```javascript
ZegoExpressEngine.destroyEngine();
```
