---
articleID: 18321
date: "2024-09-06"
---
# Object Segmentation

- - -

## Feature Introduction

Object segmentation is a value-added capability provided by Express SDK. It uses AI algorithms to recognize content in video images and sets `transparency information` for each pixel. Among them, the pixels of the main subject will be set to "opaque", and the pixels outside the main subject will be set to "transparent". Developers can use the transparency information of these pixels to process the main subject and non-main subject parts in the image differently, thereby realizing different functions.

<Warning title="Note">
- The current official website SDK does not include "Object Segmentation" related functions. If necessary, please contact ZEGOCLOUD Technical Support for special packaging and provide your AppID to enable relevant permissions.
- The "Object Segmentation" function is a paid function. If you need to apply for experience or consult formal charging standards, please contact ZEGO business personnel.
</Warning>



### Object Segmentation Objects

For users in different environments, ZEGO provides two segmentation capabilities: "Green Screen Background Segmentation" and "Arbitrary Background Segmentation".

<table>

<tbody><tr>
<th>Segmentation Type</th>
<th>Green Screen Background Segmentation</th>
<th>Arbitrary Background Segmentation</th>
</tr>
<tr>
<th>Capability Description</th>
<td><p>When users set up a green screen by themselves, the main subject in the non-green screen area can be retained.</p><p>Suitable for e-commerce live streaming, online exams and other scenarios.</p></td>
<td><p>Most users do not have the conditions to set up a green screen. Through the arbitrary background segmentation capability provided by ZEGO, the main subject in the image can be recognized without a green screen.</p><p>Suitable for online education, video conferences and other scenarios.</p></td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_greenscreen.png" /></Frame></td>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_realenvironment.jpg" /></Frame></td>
</tr>
</tbody></table>

### Functional Scenarios

Based on the object segmentation capability, developers can implement business scenarios such as background blurring, virtual background, presentation mode, and multi-person real-time co-location interaction, creating more diverse interactive experiences.

<table>

<tbody><tr>
<th>Function Point</th>
<th>Background Blurring</th>
<th>Virtual Background</th>
<th>Background Transparency</th>
<th>Object Segmentation and Transmission</th>
</tr>
<tr>
<th>Function Description</th>
<td>Blur the image outside the main subject.</td>
<td>Replace the image outside the main subject with custom images and colors.</td>
<td><p>Render the image of the main subject on other video content locally.</p><p>For example, on content such as screen sharing or currently playing videos, implement functions such as presentation mode.</p></td>
<td>Combine with the Alpha channel data transmission capability provided by Express SDK to transmit the segmented main subject in the image to the playing end, and render the main subject at the playing end to achieve the visual effect of multiple people in different places appearing in the same scene in real time</td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/6364d2bc42.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/de1e9cf26f.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/5bc5b6b70d.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/multiplayer.jpeg" /></Frame></td>
</tr>
</tbody></table>


### Hardware Compatibility

<table>

<tbody><tr>
<th>Platform</th>
<th>Hardware Requirements</th>
</tr>
<tr>
<td>macOS</td>
<td>M series chips: Apple M1 and above</td>
</tr>
<tr>
<td>Windows</td>
<td>Intel Core i5 and above</td>
</tr>
</tbody></table>


## Example Source Code

Please refer to [Download Example Source Code](/real-time-video-electron-js/quick-start/run-example-code) to obtain the source code.

For related source code, please check the files in the "/ZegoExpressExample/Others/src/main/java/com/example/others/videoobjectsegmentation" directory.

## Prerequisites

Before using the object segmentation function, please ensure:

- You have contacted ZEGOCLOUD Technical Support for special packaging.

- A project has been created in the [ZEGOCLOUD Console](https://console.zegocloud.com), and valid AppID and AppSign have been applied for. For details, please refer to [Console - Project Information](/console/project-info).
- ZEGO Express SDK has been integrated into the project, and basic audio and video publishing and playing functionality has been implemented. For details, please refer to [Quick Start - Integration](/real-time-video-electron-js/quick-start/integrating-sdk) and [Quick Start - Implementation Process](/real-time-video-electron-js/quick-start/implementing-video-call).


## Implementation Process

<Warning title="Note">


- Enabling the object segmentation function will consume additional system resources. To ensure user experience, currently only supports enabling object segmentation for one channel of publishing stream image.
- If there are custom pre-processed third-party filters, you need to ensure that the third-party filters support Alpha channel passthrough functionality.

</Warning>



<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/subject_segmentation_electron.png" /></Frame>

Please note that developers can choose whether to implement the **(Optional)** steps in the above figure according to their business scenario needs. If implementation is needed, please refer to the specific instructions below.

### Initialize and Login to Room

For the specific process of initialization and logging in to the room, please refer to "[Create Engine](/real-time-video-electron-js/quick-start/implementing-video-call)" and "[Login Room](/real-time-video-electron-js/quick-start/implementing-video-call)" in the Implement Video Call document.

### Listen to Object Segmentation State Callback

Call the [onVideoObjectSegmentationStateChanged](/real-time-video-electron-js/quick-start/setting-callback) interface to listen to the object segmentation state callback.

<Warning title="Note">


The object segmentation state callback depends on enabling preview or publishing stream. That is, to listen to the [onVideoObjectSegmentationStateChanged](/real-time-video-electron-js/quick-start/setting-callback) callback, you need to call preview [startPreview](@startPreview) or publish stream [startPublishingStream](@startPublishingStream).

</Warning>



```js
zgEngine.on('onVideoObjectSegmentationStateChanged', (res) =>{
   console.log('onVideoObjectSegmentationStateChanged: '+ res.state)
   if(res.state == zgDefines.ZegoObjectSegmentationState.On)
   {
       //Object segmentation enabled
   }
   else
   {
      //Object segmentation disabled
      //Abnormal shutdown, please check the error code
   }
})
```

### Use Object Segmentation to Implement Different Business Functions

<Warning title="Note">


If developers need to update the object segmentation type or background processing type, they need to modify the configuration of [ZegoObjectSegmentationConfig](@-ZegoObjectSegmentationConfig) and call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface again to enable object segmentation, which can update the object segmentation effect; the update result will be notified to developers through the [onVideoObjectSegmentationStateChanged](/real-time-video-electron-js/quick-start/setting-callback) callback.

</Warning>



#### Background Blurring

<Accordion title="Use Object Segmentation to Implement Background Blurring" defaultOpen="false">
Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable object segmentation and set the background processing type to "Blur".

```js
// Set background processing method to blur
// Set background blur level to medium
var config = {objectSegmentationType: zgDefines.ZegoObjectSegmentationType.AnyBackground, backgroundConfig: {processType: zgDefines.ZegoBackgroundProcessType.Blur, blurLevel: zgDefines.ZegoBackgroundBlurLevel.Medium}};
//Enable object segmentation
zgEngine.enableVideoObjectSegmentation(true, config, zgDefines.ZegoPublishChannel.Main)
```
</Accordion>

#### Virtual Background

<Accordion title="Use Object Segmentation to Implement Virtual Background" defaultOpen="false">
<Warning title="Note">


- When using this function, developers should pay attention to the aspect ratio of custom images, otherwise parts of the image exceeding the view will be cropped.
- Currently supports two image formats: "PNG" and "JPEG", that is, image files with three suffixes: ".png", ".jpg", and ".jpeg".

</Warning>



Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable object segmentation and set the background processing type to "Image".

```js
// Set background processing method to image
var config = {objectSegmentationType: zgDefines.ZegoObjectSegmentationType.AnyBackground, backgroundConfig: {processType: zgDefines.ZegoBackgroundProcessType.Image, imageURL: "Set background image path"}};
//Enable object segmentation
zgEngine.enableVideoObjectSegmentation(true, config, zgDefines.ZegoPublishChannel.Main)
```
</Accordion>

#### Transparent Background

<Accordion title="Use Object Segmentation to Implement Transparent Background" defaultOpen="false">
<Warning title="Note">


If developers need to implement business functions similar to "presentation mode", they need to mix the "main subject image" and "video source content to be mixed" into one video stream on the business side.

</Warning>



Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable object segmentation and set the background processing type to "Transparent".

```js
// Set background processing method to transparent
var config = {objectSegmentationType: zgDefines.ZegoObjectSegmentationType.AnyBackground, backgroundConfig: {processType: zgDefines.ZegoBackgroundProcessType.Transparent}};
//Enable object segmentation
zgEngine.enableVideoObjectSegmentation(true, config, zgDefines.ZegoPublishChannel.Main)
```
</Accordion>

### (Optional) Use Alpha Channel to Transmit Segmented Main Subject

<Accordion title="Use Alpha Channel to Transmit Segmented Main Subject" defaultOpen="false">
If the publishing end needs to transmit the segmented main subject image to the playing end through the Alpha channel and render the main subject at the playing end, you need to first call the [enableAlphaChannelVideoEncoder](@enableAlphaChannelVideoEncoder) interface to set the encoder to support transparent channels, and then call the [startPublishingStream](@startPublishingStream) interface to publish the stream, so that it can be smoothly transmitted to the playing end.

<Warning title="Note">


Currently only supports transparent channel data arranged below RGB or YUV data.

</Warning>



- Enable Alpha channel data transmission:

    ```js
   // Transparent channel data arranged below RGB or YUV data
   // Set encoder to support transparent channels
   zgEngine.enableAlphaChannelVideoEncoder(true, zgDefines.ZegoAlphaLayoutType.Bottom, zgDefines.ZegoPublishChannel.Main)
    ```
- Disable Alpha channel data transmission:

    ```js
    // Transparent channel data arranged below RGB or YUV data
    // Set encoder to support transparent channels
    zgEngine.enableAlphaChannelVideoEncoder(false, zgDefines.ZegoAlphaLayoutType.Bottom, zgDefines.ZegoPublishChannel.Main)
    ```
</Accordion>

### Start Preview and Publishing Stream

After enabling the object segmentation function through the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface, you can preview.

<Note title="Note">


Developers can also enable preview first and then enable object segmentation. This article takes enabling object segmentation first and then previewing as an example.

</Note>



```js
zgEngine.startPreview();
zgEngine.startPublishingStream(streamID);
```

### Play Stream

Start playing stream through the [startPlayingStream](@startPlayingStream) interface.

```js
zgEngine.startPlayingStream(StreamID, {
    canvas: localCanvas
});
```

### Disable Object Segmentation

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to disable object segmentation.

```js
// Disable object segmentation
zgEngine.enableVideoObjectSegmentation(false, {}, zgDefines.ZegoPublishChannel.Main)
```

### Destroy Engine

Call the [destroyEngine](@destroyEngine) interface to destroy the engine.

```js
zgEngine.destroyEngine();
```
