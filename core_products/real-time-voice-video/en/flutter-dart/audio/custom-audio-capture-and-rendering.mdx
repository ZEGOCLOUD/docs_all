---
articleID: 17137
date: "2024-02-27"
---
# Custom Audio Capture and Rendering
- - -

## Overview

### Custom Audio Capture

In the following scenarios, it is recommended to use the custom audio capture feature:

- Developers need to obtain captured input from existing audio streams, audio files, or customized capture systems and hand it over to the SDK for transmission.
- Developers have their own requirements for special audio effects processing on PCM input sources, and after audio effects processing, hand it over to the SDK for transmission.

### Custom Audio Rendering

When developers have their own rendering requirements, such as performing special applications or processing on the captured raw PCM data before rendering, it is recommended to use the SDK's custom audio rendering feature.

<Warning title="Caution">

Audio capture and rendering are divided into 3 situations:

- Internal capture, internal rendering
- Custom capture, custom rendering
- Custom capture, internal rendering

Please choose the appropriate audio capture and rendering method according to your business scenario.

</Warning>



## Prerequisites

Before implementing custom audio capture and rendering, please ensure:

- You have created a project in the [ZEGOCLOUD Console](https://console.zegocloud.com) and obtained a valid AppID and AppSign. For details, please refer to [Console - Project Information](/console/project-info).
- You have integrated the ZEGO Express SDK into your project and implemented basic audio and video publishing and playing functions. For details, please refer to [Quick Start - Integration](/real-time-video-flutter/quick-start/integrating-sdk) and [Quick Start - Implementation](/real-time-video-flutter/quick-start/implementing-video-call).



## Usage Steps

The following figure shows the API call sequence diagram:

<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/Express/custom_audio_capture_render_ios.png" /></Frame>

### 1 Initialize SDK

Please refer to "Create Engine" in [Quick Start - Implementation](/real-time-video-flutter/quick-start/implementing-video-call).

### 2 Enable custom audio capture and rendering

<Warning title="Caution">

[enableCustomAudioIO ](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/enableCustomAudioIO.html) must be called before [startPublishingStream](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEnginePublisher/startPublishingStream.html), [startPlayingStream](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEnginePlayer/startPlayingStream.html), [startPreview](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEnginePublisher/startPreview.html), [createMediaPlayer](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineMediaPlayer/createMediaPlayer.html), [createAudioEffectPlayer](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineAudioEffectPlayer/createAudioEffectPlayer.html), and [createRealTimeSequentialDataManager](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineIM/createRealTimeSequentialDataManager.html) to take effect.

</Warning>



Call the [enableCustomAudioIO ](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/enableCustomAudioIO.html) interface to enable custom audio IO functionality.

```dart
// Set audio source to custom capture and rendering
var config = ZegoCustomAudioConfig(ZegoAudioSourceType.Custom);
ZegoExpressEngine.instance.enableCustomAudioIO(true,config);
```

### 3 Login to room and publish/play streams

Please refer to "Login room", "Publish stream", and "Play stream" in [Quick Start - Implementation](/real-time-video-flutter/quick-start/implementing-video-call).

### 4 Capture audio data

Open the audio capture device and pass the captured audio data to the engine through [sendCustomAudioCaptureAACData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/sendCustomAudioCaptureAACData.html) or [sendCustomAudioCapturePCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/sendCustomAudioCapturePCMData.html).

### 5 Render audio data

Use [fetchCustomAudioRenderPCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/fetchCustomAudioRenderPCMData.html) to get the data to be rendered from the engine, and then play it through the rendering device after obtaining the audio data.

## FAQ

1. **When to call custom audio capture and rendering related interfaces?**

    - [enableCustomAudioIO](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/enableCustomAudioIO.html): Should be called before the engine starts, that is, before starting preview, publishing, and playing streams.
    - [sendCustomAudioCaptureAACData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/sendCustomAudioCaptureAACData.html)/[sendCustomAudioCapturePCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/sendCustomAudioCapturePCMData.html): Should be called after starting preview and publishing streams. If called before starting preview and publishing streams, the SDK will directly discard the received data.
    - [fetchCustomAudioRenderPCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/fetchCustomAudioRenderPCMData.html): Should be called after starting to play stream. The data obtained before starting to play stream is all invalid mute data.

2. **Frequency of calling custom audio capture and rendering related interfaces?**

    The optimal way is to drive according to the clock of the physical audio device, call [sendCustomAudioCaptureAACData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/sendCustomAudioCaptureAACData.html) and [sendCustomAudioCapturePCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/fetchCustomAudioRenderPCMData.html) when the physical capture device captures data; call [fetchCustomAudioRenderPCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/fetchCustomAudioRenderPCMData.html) when the physical rendering device needs data.

    If there is no specific physical device to drive in the actual scenario, it is recommended to call the above interfaces once every 10 ms to 20 ms.

3. **When calling [fetchCustomAudioRenderPCMData](https://doc-zh.zego.im/unique-api/express-video-sdk/zh/dart_flutter/zego_express_engine/ZegoExpressEngineCustomAudioIO/fetchCustomAudioRenderPCMData.html), if the internal data of the SDK is insufficient for "dataLength", how does the SDK handle it?**

    When the "param" is filled normally, if the internal data of the SDK is insufficient for "dataLength", the remaining insufficient length will be filled with mute data.


4. **Android device with external microphone, using custom audio capture and rendering, if the user puts on Bluetooth headphones midway, how to use Express SDK to capture audio?**

    Since Express SDK will not automatically switch to internal capture, developers need to handle business logic: stop external capture. The mobile SDK will select devices based on the system's current route (audio route). If the system's route is Bluetooth, it will use Bluetooth for capture.
