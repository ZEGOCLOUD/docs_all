---
articleID: 16480
date: "2024-09-06"
---
# Subject Segmentation

- - -


## Introduction

Subject Segmentation is a value-added capability provided by Express SDK. It uses AI algorithms to identify content in video frames and sets `transparency information` for each pixel. Pixels of the main subject are set to "opaque", while pixels outside the subject are set to "transparent". Developers can use this transparency information to process the subject and non-subject parts differently, thereby implementing various features.

<Warning title="Attention">

- The current official SDK does not include "Subject Segmentation" related features. If needed, please contact ZEGO Technical Support for special packaging and provide your AppID to enable relevant permissions.
- The "Subject Segmentation" feature is a paid feature. For trial applications or formal pricing inquiries, please contact ZEGO sales personnel.
</Warning>

### Subject Segmentation Types

For users in different environments, ZEGO provides two segmentation capabilities: "Green Screen Background Segmentation" and "Arbitrary Background Segmentation".

<table>
  <colgroup>
    <col width="12%"/>
    <col width="44%"/>
    <col width="44%"/>
  </colgroup>
<tbody><tr>
<th>Segmentation Type</th>
<th>Green Screen Background Segmentation</th>
<th>Arbitrary Background Segmentation</th>
</tr>
<tr>
<th>Capability Description</th>
<td><p>When users set up a green screen themselves, the subject in non-green screen areas can be retained.</p><p>Suitable for e-commerce live streaming, online exams, and other scenarios.</p></td>
<td><p>Most users don't have the conditions to set up a green screen. Through ZEGO's arbitrary background segmentation capability, they can identify subjects in the frame without a green screen.</p><p>Suitable for online education, video conferences, and other scenarios.</p></td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_greenscreen.png" /></Frame></td>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_realenvironment.jpg" /></Frame></td>
</tr>
</tbody></table>

### Feature Scenarios

Based on the subject segmentation capability, developers can implement business scenarios such as background blurring, virtual background, presenter mode, and multi-person real-time co-hosting, creating more diverse interactive experiences.

<table>
  <colgroup>
    <col width="12%"/>
    <col width="22%"/>
    <col width="22%"/>
    <col width="22%"/>
  </colgroup>
<tbody><tr>
<th>Feature</th>
<th>Background Blur</th>
<th>Virtual Background</th>
<th>Transparent Background</th>
<th>Subject Segmentation and Transmission</th>
</tr>
<tr>
<th>Feature Description</th>
<td>Apply blur processing to areas outside the subject.</td>
<td>Replace areas outside the subject with custom images, videos, or colors.</td>
<td><p>Render the subject's visuals on top of other video content locally.</p><p>For example, implement features like presenter mode on top of screen sharing or playing video content.</p></td>
<td>Combine with the Alpha channel data transmission capability provided by Express SDK to transmit the segmented subject to the playing end, where subject rendering is performed, achieving the visual effect of multiple people in different locations being in the same scene in real time</td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/6364d2bc42.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/de1e9cf26f.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/5bc5b6b70d.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/multiplayer.jpeg" /></Frame></td>
</tr>
</tbody></table>


### Hardware Compatibility

<table>
  <colgroup>
    <col width="34%"/>
    <col width="66%"/>
  </colgroup>
<tbody><tr>
<th>Platform</th>
<th>Hardware Requirements</th>
</tr>
<tr>
<td>Android</td>
<td><ul><li><p>Qualcomm chips:</p><ul><li>Snapdragon 6 series: Snapdragon 675 and above</li><li>Snapdragon 7 series: Snapdragon 730 and above</li><li>Snapdragon 8 series: Snapdragon 835 and above</li></ul></li><li><p>HiSilicon Kirin chips:</p><ul><li>Kirin 8 series: Kirin 820 and above</li><li>Kirin 9 series: Kirin 980 and above</li></ul></li><li><p>MediaTek chips:</p><ul><li>Helio P series: Helio P60 and above</li><li>Dimensity series: Dimensity 820 and above</li></ul></li><li>Samsung chips: Exynos 1080 and above</li></ul></td>
</tr>
<tr>
<td>iOS</td>
<td>A series chips: Apple A9 and above, for example iPhone 6s</td>
</tr>
<tr>
<td>macOS</td>
<td>M series chips: Apple M1 and above</td>
</tr>
<tr>
<td>Windows</td>
<td>Intel Core i5 and above</td>
</tr>
</tbody></table>

## Sample Source Code

Please refer to [Download Sample Source Code](/real-time-video-android-java/client-sdk/download-demo) to obtain the source code.

For related source code, please check files in the "/ZegoExpressExample/Others/src/main/java/com/example/others/videoobjectsegmentation" directory.

## Prerequisites

Before using the subject segmentation feature, please ensure:

- You have contacted ZEGO Technical Support for special packaging.
- The processor is M1 or above.

- A project has been created in the [ZEGO Console](https://console.zegocloud.com), and valid AppID and AppSign have been obtained. For details, please refer to [Console - Project Information](/console/project-info).
- ZEGO Express SDK has been integrated into the project, and basic audio/video streaming functionality has been implemented. For details, please refer to [Quick Start - Integration](/real-time-video-macos-oc/quick-start/integrating-sdk) and [Quick Start - Implementation Flow](/real-time-video-macos-oc/quick-start/implementing-video-call).


## Implementation Flow

<Warning title="Attention">


- Enabling subject segmentation will consume additional system resources. To ensure user experience, currently only supports enabling subject segmentation for publishing stream on one channel.
- If using third-party filters with custom pre-processing, ensure the third-party filters support Alpha channel pass-through functionality.
</Warning>

<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/subject_segmentation_macos.png" /></Frame>

Please note that developers can choose whether to implement the **(Optional)** steps in the diagram above according to their business scenario needs. If implementation is needed, please refer to the specific instructions below.

### Initialize and Login Room

For the specific process of initialization and room login, please refer to "[Create Engine](/real-time-video-macos-oc/quick-start/implementing-video-call)" and "[Login Room](/real-time-video-macos-oc/quick-start/implementing-video-call)" in the implementing video call documentation.


### (Optional) Implement Custom Rendering Class


<Accordion title="Implement Custom Rendering Class" defaultOpen="false">
Developers can perform custom rendering according to actual situations. Note that the raw video data contains an Alpha channel, and the raw data has not undergone Alpha premultiplication processing. Taking rendering playing stream data by drawing NSImage as an example:

1. Listen for custom rendering data callbacks.

    <Warning title="Attention">
    Do not render directly in the callback, as it will block the callback thread and cause rendering abnormalities.
    </Warning>

    ```objc
    - (void)onRemoteVideoFrameRawData:(unsigned char * _Nonnull *)data dataLength:(unsigned int *)dataLength param:(ZegoVideoFrameParam *)param streamID:(NSString *)streamID
    {

    }
    ```

2. Cache the raw video frame data.

    ```objc
    auto video_frame = std::make_shared<ZegoVideoFrameBuffer>();
    video_frame->data = std::make_unique<uint8_t[]>(dataLength[0]);
    video_frame->data_length =dataLength[0];
    video_frame->format = param.format;
    video_frame->width = (int)param.size.width;
    video_frame->height = (int)param.size.height;
    video_frame->bitsPerPixel = param.strides[0];

    memcpy(video_frame->data.get(), data[0], dataLength[0]);
    {
        // Cache one frame
        std::lock_guard<std::mutex> lock(play_video_frame_mutex_);
        play_video_frames_[[streamID UTF8String]] = video_frame;
    }
    ```

3. Periodically draw the bitmap to the rendering view.

    ```objc
    dispatch_async(dispatch_get_main_queue(), ^{
        std::shared_ptr<ZegoVideoFrameBuffer> frame;
        {
           std::lock_guard<std::mutex> lock(self->play_video_frame_mutex_);
            frame = self->play_video_frames_[[streamID UTF8String]];
            if (!frame) {
                return;
            }
            self->play_video_frames_[[streamID UTF8String]].reset();
        }

        CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
        CGDataProviderRef dataProvider = CGDataProviderCreateWithData(NULL, frame->data.get(), frame->data_length, NULL);
        CGImageRef cgImageFromBytes = CGImageCreate(frame->width, frame->height, 8, 32, frame->bitsPerPixel, colorSpace, kCGImageByteOrder32Little|kCGImageAlphaFirst, dataProvider, NULL, NO, kCGRenderingIntentDefault);

        NSImage *finalImage = [[NSImage alloc]initWithCGImage:cgImageFromBytes size:NSMakeSize(frame->width, frame->height)];
        CGDataProviderRelease(dataProvider);
        CGImageRelease(cgImageFromBytes);

        self.playView1.layer.contentsGravity = kCAGravityResizeAspect;
        self.playView1.layer.contents = finalImage;
    });
    ```
</Accordion>

### (Optional) Enable Custom Rendering

<Accordion title="Enable Custom Rendering" defaultOpen="false">
Call the [enableCustomVideoRender](@enableCustomVideoRender) interface, set engine advanced configuration and enable custom rendering, and call the [setCustomVideoRenderHandler](@setCustomVideoRenderHandler) interface to set custom video rendering callbacks. For details, please refer to [Custom Video Rendering](/real-time-video-macos-oc/video/custom-video-rendering).

<Warning title="Attention">


When using custom rendering for subject segmentation, [bufferType|\_blank](@bufferType-ZegoCustomVideoRenderConfig) only supports the `ZegoVideoBufferType.RAW_DATA` type.
</Warning>


```objc
ZegoCustomVideoRenderConfig *renderConfig = [[ZegoCustomVideoRenderConfig alloc] init];
renderConfig.bufferType = ZegoVideoBufferTypeRawData;// Select RAW_DATA type video frame data
renderConfig.frameFormatSeries = ZegoVideoFrameFormatSeriesRGB;// Select RGB color series data format
[[ZegoExpressEngine sharedEngine] enableCustomVideoRender:YES config:renderConfig];// Start custom video rendering
[[ZegoExpressEngine sharedEngine] setCustomVideoRenderHandler:self];// Set custom video rendering callback
```
</Accordion>

### Listen for Subject Segmentation State Callback

Call the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) interface to listen for subject segmentation state callbacks.

<Warning title="Attention">

The subject segmentation state callback depends on enabling preview or publishing stream. That is, to listen for the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback, you need to call preview [startPreview](@startPreview) or publish stream [startPublishingStream](@startPublishingStream).
</Warning>

```objc
-(void)onVideoObjectSegmentationStateChanged:(ZegoObjectSegmentationState)state channel:(ZegoPublishChannel)channel errorCode:(int)errorCode{
    if(state == ZegoObjectSegmentationStateOn){
        //Subject segmentation enabled
    }else{
        //Subject segmentation disabled
        //Abnormal shutdown, please check the error code
    }
}
```

### Use Subject Segmentation to Implement Different Business Features

<Warning title="Attention">


If developers need to update the subject segmentation type or background processing type, they need to modify the configuration of [ZegoObjectSegmentationConfig](@-ZegoObjectSegmentationConfig) and call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface again to enable subject segmentation, which can update the subject segmentation effect; the update result will be notified to developers through the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback.
</Warning>

#### Background Blur

<Accordion title="Use Subject Segmentation to Implement Background Blur" defaultOpen="false">
Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable subject segmentation and set the background processing type to "Blur".

```objc
ZegoObjectSegmentationConfig *config = [[ZegoObjectSegmentationConfig alloc]init];
config.objectSegmentationType = ZegoObjectSegmentationTypeAnyBackground;//Select the subject segmentation type to enable according to actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessTypeBlur;//Set background processing method to blur
config.backgroundConfig.blurLevel = ZegoBackgroundBlurLevelMedium;//Set background blur level to medium
[[ZegoExpressEngine sharedEngine]enableVideoObjectSegmentation:YES config:config channel:ZegoPublishChannelMain];//Enable subject segmentation
```
</Accordion>

#### Virtual Background

<Accordion title="Use Subject Segmentation to Implement Virtual Background" defaultOpen="false">
Virtual background supports two types of materials:

- Images.
  Currently supports "PNG" and "JPEG" image formats, that is, image files with ".png", ".jpg", and ".jpeg" extensions.
- Videos, with the following restrictions:
    - Video format: MP4, FLV, MKV, AVI.
    - Video source: Local video.
    - Video playback method: Loop playback.
    - Resolution: Maximum not exceeding 4096 px, recommended within 1920 px.
    - Video duration: Maximum not exceeding 30 seconds, recommended within 15 seconds.
    - Video size: Maximum not exceeding 50 MB, recommended within 10 MB.


<Warning title="Attention">


When using this feature, developers should pay attention to the aspect ratio of custom image and video materials, otherwise parts exceeding the view will be cropped.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable subject segmentation and set the background processing type to "Image" or "Video".

```objc
ZegoObjectSegmentationConfig *config = [[ZegoObjectSegmentationConfig alloc]init];
config.objectSegmentationType = ZegoObjectSegmentationTypeAnyBackground;//Select the subject segmentation type to enable according to actual situation

//Set background processing method to Image
config.backgroundConfig.processType = ZegoBackgroundProcessTypeImage;
config.backgroundConfig.imageUrl= @"<image_path>";//Set background image path
[[ZegoExpressEngine sharedEngine]enableVideoObjectSegmentation:YES config:config channel:ZegoPublishChannelMain];//Enable subject segmentation

//Set background processing method to Video
config.backgroundConfig.processType = ZegoBackgroundProcessTypeVideo;
config.backgroundConfig.videoURL= @"<video_path>";//Set background video path
[[ZegoExpressEngine sharedEngine]enableVideoObjectSegmentation:YES config:config channel:ZegoPublishChannelMain];//Enable subject segmentation
```
</Accordion>

#### Transparent Background

<Accordion title="Use Subject Segmentation to Implement Transparent Background" defaultOpen="false">
<Warning title="Attention">


If developers need to implement business features similar to "presenter mode", they need to mix the "subject visuals" and "video source content to be mixed" into one video stream on the business side.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to enable subject segmentation and set the background processing type to "Transparent".

```objc
ZegoObjectSegmentationConfig *config = [[ZegoObjectSegmentationConfig alloc]init];
config.objectSegmentationType = ZegoObjectSegmentationTypeAnyBackground;//Select the subject segmentation type to enable according to actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessTypeTransparent;//Set background processing method to transparent
[[ZegoExpressEngine sharedEngine]enableVideoObjectSegmentation:YES config:config channel:ZegoPublishChannelMain];//Enable subject segmentation
```
</Accordion>

### (Optional) Use Alpha Channel to Transmit Segmented Subject

<Accordion title="Use Alpha Channel to Transmit Segmented Subject" defaultOpen="false">
If the publishing end needs to transmit the segmented subject visuals to the playing end through the Alpha channel for subject rendering at the playing end, you need to first call the [enableAlphaChannelVideoEncoder](@enableAlphaChannelVideoEncoder) interface to set the encoder to support transparent channel, then call the [startPublishingStream](@startPublishingStream) interface to publish stream, enabling smooth transmission to the playing end.

<Warning title="Attention">

Currently only supports transparent channel data arranged below RGB or YUV data.
</Warning>

- Enable Alpha channel data transmission:

    ```objc
    ZegoAlphaLayoutType layoutType = ZegoAlphaLayoutTypeBottom; // Transparent channel data arranged below RGB or YUV data
    [[ZegoExpressEngine sharedEngine]enableAlphaChannelVideoEncoder:YES alphaLayout:layoutType channel:ZegoPublishChannelMain]; // Set encoder to support transparent channel
    ```

- Disable Alpha channel data transmission:

    ```objc
    ZegoAlphaLayoutType layoutType = ZegoAlphaLayoutTypeBottom; // Transparent channel data arranged below RGB or YUV data
    [[ZegoExpressEngine sharedEngine]enableAlphaChannelVideoEncoder:NO alphaLayout:layoutType channel:ZegoPublishChannelMain]; // Set encoder to support transparent channel
    ```
</Accordion>

### Start Preview and Publish Stream

After enabling the subject segmentation feature through the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface, you can perform preview.

<Note title="Note">


Developers can also enable preview first, then enable subject segmentation. This article uses enabling subject segmentation first, then preview as an example.
</Note>

- **Method 1**: Use internal rendering

    If using internal rendering, before enabling preview, please set [alphaBlend](@alphaBlend-ZegoCanvas) to YES.

    ```objc
    ZegoCanvas *previewCanvas = [ZegoCanvas canvasWithView:self.previewView];
    previewCanvas.alphaBlend = YES;//Enable internal rendering Alpha blending. After enabling, supports Alpha blending of segmented subject with background layer
    [[ZegoExpressEngine sharedEngine]startPreview:previewCanvas];
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly perform preview and publish stream.
    ```objc
    [[ZegoExpressEngine sharedEngine] startPreview:nil];
    [[ZegoExpressEngine sharedEngine] startPublishingStream:streamID];
     ```

### (Optional) Set Alpha Channel Rendering at Playing End and Start Playing Stream

<Accordion title="Set Alpha Channel Rendering at Playing End and Start Playing Stream" defaultOpen="false">
<Warning title="Attention">


Alpha channel rendering at the playing end only needs to be enabled when the publishing end has enabled Alpha channel transmission.
</Warning>

- **Method 1**: Use internal rendering

    If using internal rendering, before the playing end calls the [startPlayingStream](@startPlayingStream) interface to start playing stream, it needs to set the [alphaBlend](@alphaBlend-ZegoCanvas) property of [ZegoCanvas](@-ZegoCanvas) to YES.

    ```objc
    ZegoCanvas *playCanvas = [ZegoCanvas canvasWithView:self.playView1];
    playCanvas.alphaBlend = YES;//Enable internal rendering Alpha blending. After enabling, supports Alpha blending of segmented subject with background layer
    [[ZegoExpressEngine sharedEngine]startPlayingStream:streamID  canvas:playCanvas];
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly start playing stream.
    ```objc
    [[ZegoExpressEngine sharedEngine]startPlayingStream:streamID canvas:nil];
    ```
</Accordion>

### Disable Subject Segmentation

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to disable subject segmentation.

```objc
ZegoObjectSegmentationType objectType = ZegoObjectSegmentationTypeAnyBackground;//Select the subject segmentation type to disable according to actual situation
[[ZegoExpressEngine sharedEngine]enableVideoObjectSegmentation:NO type:objectType channel:ZegoPublishChannelMain];//Disable subject segmentation
```

### Destroy Engine

Call the [destroyEngine](@destroyEngine) interface to destroy the engine.

```objc
[ZegoExpressEngine destroyEngine:nil];
```
