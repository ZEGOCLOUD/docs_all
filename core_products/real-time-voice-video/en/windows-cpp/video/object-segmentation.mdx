---
articleID: 16479
date: "2024-09-06"
---
# Object Segmentation

- - -

## Feature Overview

Object Segmentation is a value-added capability provided by Express SDK. It uses AI algorithms to identify content in the video frame and sets `transparency information` for each pixel. Pixels belonging to the main subject are set as "opaque", while pixels outside the main subject are set as "transparent". Developers can use the transparency information of these pixels to apply different processing to the subject and non-subject parts of the frame, thereby implementing various features.

<Warning title="Note">
- The current official SDK does not include "Object Segmentation" related features. If needed, please contact ZEGOCLOUD Technical Support for special packaging and provide your AppID to enable the relevant permissions.
- The "Object Segmentation" feature is a paid feature. For trial applications or formal pricing inquiries, please contact ZEGOCLOUD sales representatives.
</Warning>

### Object Segmentation Types

For users in different environments, ZEGO provides two segmentation capabilities: "Green Screen Background Segmentation" and "Arbitrary Background Segmentation".

<table>

<tbody><tr>
<th>Segmentation Type</th>
<th>Green Screen Background Segmentation</th>
<th>Arbitrary Background Segmentation</th>
</tr>
<tr>
<th>Capability Description</th>
<td><p>When users have set up a green screen themselves, the subject in non-green screen areas can be retained.</p><p>Suitable for e-commerce live streaming, online exams, and other scenarios.</p></td>
<td><p>Most users do not have the conditions to set up a green screen. Through ZEGO's arbitrary background segmentation capability, the subject in the frame can be identified without a green screen.</p><p>Suitable for online education, video conferencing, and other scenarios.</p></td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_greenscreen.png" /></Frame></td>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_realenvironment.jpg" /></Frame></td>
</tr>
</tbody></table>

### Feature Scenarios

Based on the object segmentation capability, developers can implement business scenarios such as background blur, virtual background, presenter mode, and real-time multi-person interactive stages, creating more diverse interactive experiences.

<table>

<tbody><tr>
<th>Feature</th>
<th>Background Blur</th>
<th>Virtual Background</th>
<th>Transparent Background</th>
<th>Subject Segmentation and Transmission</th>
</tr>
<tr>
<th>Feature Description</th>
<td>Apply blur processing to the area outside the subject.</td>
<td>Replace the area outside the subject with custom images, videos, or colors.</td>
<td><p>Render the subject on top of other video content locally.</p><p>For example, implement presenter mode and other features on top of content such as screen sharing or playing videos.</p></td>
<td>Combine with the Alpha channel data transmission capability provided by Express SDK to transmit the segmented subject from the publishing end to the playing end, where subject rendering is performed to achieve the visual effect of multiple people in different locations appearing in the same scene in real time</td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/6364d2bc42.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/de1e9cf26f.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/5bc5b6b70d.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/multiplayer.jpeg" /></Frame></td>
</tr>
</tbody></table>


### Hardware Compatibility

<table>

<tbody><tr>
<th>Platform</th>
<th>Hardware Requirements</th>
</tr>
<tr>
<td>Android</td>
<td><ul><li><p>Qualcomm chips:</p><ul><li>Qualcomm 6 series: Qualcomm 675 and above</li><li>Qualcomm 7 series: Qualcomm 730 and above</li><li>Qualcomm 8 series: Qualcomm 835 and above</li></ul></li><li><p>HiSilicon Kirin chips:</p><ul><li>Kirin 8 series: Kirin 820 and above</li><li>Kirin 9 series: Kirin 980 and above</li></ul></li><li><p>MediaTek chips:</p><ul><li>Helio P series: Helio P60 and above</li><li>Dimensity series: Dimensity 820 and above</li></ul></li><li>Samsung chips: Exynos 1080 and above</li></ul></td>
</tr>
<tr>
<td>iOS</td>
<td>A series chips: Apple A9 and above, e.g., iPhone 6s</td>
</tr>
<tr>
<td>macOS</td>
<td>M series chips: Apple M1 and above</td>
</tr>
<tr>
<td>Windows</td>
<td>Intel Core i5 and above</td>
</tr>
</tbody></table>


## Sample Source Code Download

Please refer to [Download Sample Source Code](/real-time-video-android-java/client-sdk/download-demo) to obtain the source code.

For related source code, please check the files in the "/ZegoExpressExample/Others/src/main/java/com/example/others/videoobjectsegmentation" directory.

## Prerequisites

Before implementing object segmentation features, please ensure:

- You have contacted ZEGOCLOUD Technical Support for special packaging.

- A project has been created in the [ZEGO Console](https://console.zego.im), and valid AppID and AppSign have been obtained. For details, please refer to [Console - Project Information](/console/project-info).
- ZEGO Express SDK has been integrated into the project, and basic audio/video publishing and playing functionality has been implemented. For details, please refer to [Quick Start - Integration](/real-time-video-windows-cpp/quick-start/integrating-sdk) and [Quick Start - Implementation](/real-time-video-windows-cpp/quick-start/implementing-video-call).


## Implementation Steps

<Warning title="Note">


- Enabling object segmentation consumes additional system resources. To ensure user experience, currently only one channel's publishing stream can have object segmentation enabled.
- If custom third-party filters with pre-processing are used, ensure that the third-party filters support Alpha channel pass-through functionality.
</Warning>

<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/subject_segmentation_win.png" /></Frame>

Please note that developers can choose whether to implement the **(Optional)** steps in the above diagram based on their business scenario requirements. For implementation, please refer to the specific instructions below.

### 1 Initialization and Room Login

For specific steps on initialization and room login, please refer to "[Create Engine](/real-time-video-windows-cpp/quick-start/implementing-video-call)" and "[Login Room](/real-time-video-windows-cpp/quick-start/implementing-video-call)" in the implementing video call documentation.


### 2 (Optional) Implement Custom Rendering Class

<Accordion title="Implement Custom Rendering Class" defaultOpen="false">
Developers can perform custom rendering based on actual conditions. Note that the video raw data contains an Alpha channel, and the raw data has not undergone Alpha premultiplication processing. Taking rendering playing stream data as an example:

1. Listen for custom rendering data callbacks and cache rendering frame data.

    <Warning title="Note">
    Rendering cannot be done directly in the callback as it will block the callback thread, causing rendering abnormalities.
    </Warning>

    ```cpp
    @Override
    void VideoObjectSegmentation::onRemoteVideoFrameRawData(unsigned char** data, unsigned int* dataLength, ZegoVideoFrameParam param, const std::string& streamID)
    {
        Q_UNUSED(dataLength)

        if(param.format == ZEGO_VIDEO_FRAME_FORMAT_BGRA32){
            QImage image(data[0], param.width, param.height, param.strides[0], QImage::Format_ARGB32);
            if(image.isNull())
            {
                // Image is empty, return
                return;
            }
            // Render in UI thread
            if (streamID == m_playStreamId1) {
                sigRenderPlayFrames1(image);
            }
            if (streamID == m_playStreamId2) {
                sigRenderPlayFrames2(image);
            }
        }
    }
    ```

2. Draw the bitmap to the rendering view.

    ```cpp
    auto pix = QPixmap::fromImage(image);
    auto pixmap = pix.scaled(ui->label_playing_stream_1->width(), ui->label_playing_stream_1->height(),Qt::KeepAspectRatio);
    ui->label_playing_stream_1->setPixmap(pixmap);
    ```
</Accordion>


### 3 (Optional) Enable Custom Rendering

<Accordion title="Enable Custom Rendering" defaultOpen="false">
Call the [enableCustomVideoRender](@enableCustomVideoRender) interface, set the engine advanced configuration and enable custom rendering, and call the [setCustomVideoRenderHandler](@setCustomVideoRenderHandler) interface to set the custom video rendering callback. For details, please refer to [Custom Video Rendering](/real-time-video-windows-cpp/video/custom-video-rendering).

<Warning title="Note">
When using custom rendering for object segmentation, [bufferType|\_blank](@bufferType-ZegoCustomVideoRenderConfig) only supports the `ZegoVideoBufferType.RAW_DATA` type.
</Warning>


```cpp
ZegoCustomVideoRenderConfig customVideoRenderConfig;
customVideoRenderConfig.bufferType = ZegoVideoBufferType::ZEGO_VIDEO_BUFFER_TYPE_RAW_DATA;// Select RAW_DATA type video frame data
customVideoRenderConfig.frameFormatSeries = ZEGO_VIDEO_FRAME_FORMAT_SERIES_RGB;// Select RGB color series data format
engine->enableCustomVideoRender(true, &customVideoRenderConfig);// Start custom video rendering
engine->setCustomVideoRenderHandler(std::make_shared<CustomVideoRenderer>(this));// Set custom video rendering callback
```
</Accordion>

### 4 Listen for Object Segmentation Status Callback

Call the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) interface to listen for object segmentation status callbacks.

<Warning title="Note">


The object segmentation status callback depends on enabling preview or publishing stream. To listen for the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback, you need to call preview [startPreview](@startPreview) or publish stream [startPublishingStream](@startPublishingStream).
</Warning>

```cpp
void VideoObjectSegmentation::onVideoObjectSegmentationStateChanged(ZegoObjectSegmentationState state, ZegoPublishChannel channel, int errorCode)
{
    if(state == ZEGO_OBJECT_SEGMENTATION_STATE_ON){
        // Object segmentation enabled
    }
    else
    {
        // Object segmentation disabled
        // Abnormal disable, please check the error code
    }
}
```

### 5 Use Object Segmentation to Implement Different Business Features

<Warning title="Note">
If developers need to update the object segmentation type or background processing type, they need to modify the [ZegoObjectSegmentationConfig](@-ZegoObjectSegmentationConfig) configuration and call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface again to enable object segmentation. The update result will be notified to developers through the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback.
</Warning>

**Background Blur**

<Accordion title="Use Object Segmentation to Implement Background Blur" defaultOpen="false">
Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "Blur".

```cpp
ZegoObjectSegmentationConfig config;
config.objectSegmentationType = ZEGO_OBJECT_SEGMENTATION_TYPE_ANY_BACKGROUND;// Select the required object segmentation type based on actual conditions
config.backgroundConfig.processType = ZEGO_BACKGROUND_PROCESS_TYPE_BLUR;// Set background processing method to blur
config.backgroundConfig.blurLevel = ZEGO_BACKGROUND_BLUR_LEVEL_MEDIUM;// Set background blur level to medium
engine->enableVideoObjectSegmentation(true, config, ZEGO_PUBLISH_CHANNEL_MAIN); // Enable object segmentation
```
</Accordion>

**Virtual Background**

<Accordion title="Use Object Segmentation to Implement Virtual Background" defaultOpen="false">
Virtual background supports two types of materials:

- Images.
  Currently supports "PNG" and "JPEG" image formats, i.e., image files with ".png", ".jpg", and ".jpeg" extensions.
- Videos, with the following restrictions:
    - Video format: MP4, FLV, MKV, AVI.
    - Video source: Local video.
    - Video playback mode: Loop playback.
    - Resolution: Maximum not exceeding 4096 px, recommended within 1920 px.
    - Video duration: Maximum not exceeding 30 seconds, recommended within 15 seconds.
    - Video size: Maximum not exceeding 50 MB, recommended within 10 MB.


<Warning title="Note">
Developers using this feature should pay attention to the aspect ratio of custom images and video materials, otherwise portions exceeding the view will be cropped.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "Image" or "Video".

```cpp
ZegoObjectSegmentationConfig config;
config.objectSegmentationType = ZEGO_OBJECT_SEGMENTATION_TYPE_ANY_BACKGROUND;// Select the required object segmentation type based on actual conditions

// Set background processing method to Image
config.backgroundConfig.processType = ZEGO_BACKGROUND_PROCESS_TYPE_IMAGE;
config.backgroundConfig.imageURL = "<image_path>";// Set background image path
engine->enableVideoObjectSegmentation(true, config, ZEGO_PUBLISH_CHANNEL_MAIN); // Enable object segmentation

// Set background processing method to Video
config.backgroundConfig.processType = ZEGO_BACKGROUND_PROCESS_TYPE_VIDEO;
config.backgroundConfig.videoURL = "<video_path>";// Set background video path
engine->enableVideoObjectSegmentation(true, config, ZEGO_PUBLISH_CHANNEL_MAIN); // Enable object segmentation
```
</Accordion>

**Transparent Background**

<Accordion title="Use Object Segmentation to Implement Transparent Background" defaultOpen="false">
<Warning title="Note">


If developers need to implement business features similar to "Presenter Mode", they need to mix the "Subject Frame" with "Video Source Content to be Mixed" into a single stream on the business side.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "Transparent".

```cpp
ZegoObjectSegmentationConfig config;
config.objectSegmentationType = ZEGO_OBJECT_SEGMENTATION_TYPE_ANY_BACKGROUND;// Select the required object segmentation type based on actual conditions
config.backgroundConfig.processType = ZEGO_BACKGROUND_PROCESS_TYPE_TRANSPARENT;// Set background processing method to transparent
engine->enableVideoObjectSegmentation(true, config, ZEGO_PUBLISH_CHANNEL_MAIN); // Enable object segmentation
```
</Accordion>

### 6 (Optional) Use Alpha Channel to Transmit Segmented Subject

<Accordion title="Use Alpha Channel to Transmit Segmented Subject" defaultOpen="false">
If the publishing end needs to transmit the segmented subject frame to the playing end through the Alpha channel for subject rendering at the playing end, you need to first call the [enableAlphaChannelVideoEncoder](@enableAlphaChannelVideoEncoder) interface to set the encoder to support transparent channel, then call the [startPublishingStream](@startPublishingStream) interface to publish the stream to successfully transmit it to the playing end.

<Warning title="Note">


Currently only supports transparent channel data arranged below RGB or YUV data.
</Warning>

- Enable Alpha channel data transmission:

    ```cpp
    ZegoAlphaLayoutType layoutType = ZEGO_ALPHA_LAYOUT_TYPE_BOTTOM; // Transparent channel data arranged below RGB or YUV data
    engine->enableAlphaChannelVideoEncoder(true,layoutType, ZEGO_PUBLISH_CHANNEL_MAIN); // Set encoder to support transparent channel
    ```
- Disable Alpha channel data transmission:

    ```cpp
    ZegoAlphaLayoutType layoutType = ZEGO_ALPHA_LAYOUT_TYPE_BOTTOM; // Transparent channel data arranged below RGB or YUV data
    engine->enableAlphaChannelVideoEncoder(false,layoutType, ZEGO_PUBLISH_CHANNEL_MAIN); // Set encoder to support transparent channel
    ```
</Accordion>

### 7 Start Preview and Publish Stream

After enabling object segmentation through the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface, you can proceed with preview.

<Note title="Description">


Developers can also enable preview first, then enable object segmentation. This document uses enabling object segmentation first, then preview as an example.
</Note>

- **Method 1**: Use internal rendering

    If using internal rendering, before starting preview, please set [alphaBlend](@alphaBlend-ZegoCanvas) to true.

    ```cpp
    ZegoCanvas canvas;
    canvas.view = ZegoUtilHelper::GetView(ui->label_preview);
    canvas.alphaBlend = true;// Enable internal rendering Alpha blending. After enabling, supports Alpha blending of segmented subject with background layer
    engine->startPreview(&canvas);
    engine->startPublishingStream(streamID);
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly proceed with preview and publish stream.

    ```cpp
    engine->startPreview();
    engine->startPublishingStream(streamID);
    ```

### 8 (Optional) Set Alpha Channel Rendering at Playing End and Start Playing Stream

<Accordion title="Set Alpha Channel Rendering at Playing End and Start Playing Stream" defaultOpen="false">
<Warning title="Note">


Alpha channel rendering needs to be enabled at the playing end only when the publishing end has enabled Alpha channel transmission.
</Warning>

- **Method 1**: Use internal rendering

    If using internal rendering, before calling the [startPlayingStream](@startPlayingStream) interface to start playing stream, the playing end needs to set the [alphaBlend](@alphaBlend-ZegoCanvas) property of [ZegoCanvas](@-ZegoCanvas) to true.

    ```cpp
    ZegoCanvas canvas;
    canvas.view = ZegoUtilHelper::GetView(ui->label_playing_stream_1);
    canvas.alphaBlend = true;// Enable internal rendering Alpha blending. After enabling, supports Alpha blending of segmented subject with background layer
    engine->startPlayingStream(streamID, &canvas);
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly proceed with playing stream.
    ```cpp
    engine->startPlayingStream(streamID, nullptr);
    ```
</Accordion>


### 9 Disable Object Segmentation

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to disable object segmentation.

```cpp
ZegoObjectSegmentationConfig config;
engine->enableVideoObjectSegmentation(false, config, ZEGO_PUBLISH_CHANNEL_MAIN);// Disable object segmentation
```

### 10 Destroy Engine

Call the [destroyEngine](@destroyEngine) interface to destroy the engine.

```cpp
ZegoExpressSDK::destroyEngine(engine);
engine = nullptr;
```
