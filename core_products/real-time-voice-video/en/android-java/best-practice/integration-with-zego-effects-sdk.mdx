---
articleID: 11257
date: "2025-07-30"
---
# Integration with AI Beauty Effects

---

## Usage Guide

### Introduction

Real-time audio and video is a real-time audio and video interaction service product from ZEGO. Developers can build audio and video applications through its flexible and easy-to-use APIs. At the same time, another product from ZEGO - AI Beauty Effects, based on leading AI algorithms, provides features such as beauty effects, body retouching, makeup, and stickers. Combining the two can easily achieve the integration of audio and video interaction and beauty effects, creating real-time beauty applications.

The combination of the two can be widely used in live streaming scenarios such as entertainment live streaming, game live streaming, and video conferencing.

<video poster="https://doc-media.zego.im/sdk-doc/Pics/ZegoEffects/AI_cover.png" src="https://doc-media.zego.im/sdk-doc/doc/video/AI/AI.mp4" width="65%" muted="true" loop="true" autoplay="autoplay" preload="auto" nocontrols></video>

### Concept Explanation

- ZEGO Express SDK: ZEGO real-time audio and video SDK, providing basic real-time audio and video functions, including live streaming publish and play, live co-hosting, etc. Hereinafter referred to as ZEGO Express SDK.
- ZEGO Effects SDK: ZEGO AI Beauty SDK, providing multiple intelligent image rendering and algorithm capabilities, including intelligent beauty effects, AR effects, image segmentation, etc. Hereinafter referred to as ZEGO Effects SDK.


## Example Source Code

To facilitate developers in implementing the integration of the two, ZEGO provides example code. Please refer to [AI Beauty Effects - Run Example Source Code](/ai-effects-android-java/quick-starts/run-sample-codes).


## Prerequisites

- You have created a project in the [ZEGO Console](https://console.zego.im) and applied for a valid AppID and AppSign. For details, please refer to [Console - Project Management](/console/project-info) in "Project Information"; and contact ZEGO Technical Support to enable ZEGO Effects related package service permissions.
- You have integrated ZEGO Express SDK in your project and implemented basic audio and video streaming functionality. For details, please refer to [Quick Start - Integration](/real-time-video-android-java/quick-start/integrating-sdk) and [Quick Start - Implementing Video Call](/real-time-video-android-java/quick-start/implementing-video-call).

- You have integrated ZEGO Effects SDK in your project. For details, please refer to "AI Beauty Effects" [Quick Start - Integration](/ai-effects-android-java/quick-starts/import-the-sdk).
- You have obtained the unique authentication file for ZEGO Effects SDK. For details, please refer to "AI Beauty Effects" [Quick Start - Online Authentication](/ai-effects-android-java/quick-starts/online-authentication).



## Usage Steps

The principle of using ZEGO Effects SDK and ZEGO Express SDK together to perform real-time AI beauty processing on video data is shown in the following figure:
<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/Common/ZegoExpressEngine/video_pre_processing.png" /></Frame>

Through the above process, the specific implementation steps are shown in the following figure:
<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/ZegoEffects/Apple/RTC_AI_bestPractise3.png" /></Frame>

1. Initialize ZEGO Effects SDK and ZEGO Express SDK. There is no timing restriction on initialization.
2. Obtain original video data, which can be obtained through [Custom Video Capture](/real-time-video-android-java/video/custom-video-capture) or [Custom Video Preprocessing](/real-time-video-android-java/video/custom-video-preprocessing) of ZEGO Express SDK.
3. Pass the captured original video data to ZEGO Effects SDK for AI beauty processing.
4. Pass the processed data to ZEGO Express SDK for publishing. If you need to adjust AI beauty effects during the publish and play process, you can use the relevant functions of ZEGO Effects SDK to make real-time changes.
5. Remote users use ZEGO Express SDK to pull and play the processed data.


### Initialize ZEGO Effects/Express SDK

There is no timing restriction on the initialization of the two SDKs. The following steps take "initializing ZEGO Effects SDK first, then initializing ZEGO Express SDK" as an example.

#### Initialize ZEGO Effects SDK

1. Import Effects models and resources.

    When using AI-related functions of ZEGO Effects SDK, you must first import AI models and resources.

    ```java
    // Pass in the absolute path of the face recognition model. Face detection, big eyes, and face slimming functions all need to import
    ArrayList<String> aiResources = new ArrayList<>();
    aiResources.add("sdcard/xxx/xxxxx/FaceDetectionModel.model");
    aiResources.add("sdcard/xxx/xxxxx/SegmentationModel.model");

    // Pass in the absolute path of resources
    aiResources.add("sdcard/xxx/xxxxx/CommonResources.bundle");
    aiResources.add("sdcard/xxx/xxxxx/PendantResources.bundle");
    aiResources.add("sdcard/xxx/xxxxx/FaceWhiteningResources.bundle");
    ...

    // Pass in the path list of resources or models, must be called before create
    ZegoEffects.setResources(aiResources);
    ```

    For all resources and models supported by ZEGO Effects SDK, please refer to "AI Beauty Effects" [Quick Start - Import Resources and Models](/ai-effects-android-java/quick-starts/import-resources-and-models).


2. Create Effects object.

<Tabs>
<Tab title=" ZegoEffects SDK 2.1.0 and above">
Pass the AppID and AppSign applied for in [Prerequisites](#prerequisites) directly into the [create](https://doc-zh.zego.im/article/api?doc=effects-sdk_API~java_android~class~ZegoEffects#create-1) interface. After internal authentication by the SDK, create the Effects object and return the relevant [error codes](/ai-effects-android-java/error-codes).
```java
ZegoEffects mEffects;
long appid = *******;
String appSign = "*******";
ZegoEffects.create(appid, appSign, applicationContext, (effects, errorCode) -> {
    mEffects = effects;
    //Execute custom logic
});
```
</Tab>
<Tab title="ZegoEffects SDK below 2.1.0">
Call the [create](https://doc-zh.zego.im/article/api?doc=effects-sdk_API~java_android~class~ZegoEffects#create) interface and pass in the authentication file obtained in [Prerequisites](#prerequisites) to create the Effects object.

```java
// Please refer to the actually obtained file for authentication content
ZegoEffects effects = ZegoEffects.create("ABCDEFG", getApplication());
```
</Tab>
</Tabs>


3. Initialize Effects object.

    Call the [initEnv](https://doc-zh.zego.im/article/api?doc=Effects_SDK_API~java_android~class~ZegoEffects#init-env) interface to initialize the Effects object. You need to pass in the width and height of the video image data to be processed.

    Taking processing 1280 Ã— 720 video images as an example:

    ```java
    // Initialize Effects object, pass in the width and height of the original image to be processed, need to initialize in onStart callback of custom video preprocessing, express is the Express engine object created later
    express.setCustomVideoProcessHandler(new IZegoCustomVideoProcessHandler() {
        public void onStart(ZegoPublishChannel channel) {
            effects.initEnv(1280,720);  // After SDK 1.4.7, this interface can be omitted. If you want to call it, please open preview first then turn on the camera
        }
    }
    ```


#### Initialize ZEGO Express SDK

Call the [createEngine](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-zego-express-engine#create-engine) interface to initialize ZEGO Express SDK.

```java
// Define SDK engine object
ZegoExpressEngine express;

ZegoEngineProfile profile = new ZegoEngineProfile();
// Please obtain through official website registration, format is 123456789L
profile.appID = appID;
// Please obtain through official website registration, format is: "0123456789012345678901234567890123456789012345678901234567890123" (64 characters in total)
profile.appSign = appSign;
// General scenario access
profile.scenario = ZegoScenario.DEFAULT;
// Set app's application object
profile.application = getApplication();
// Create engine
express = ZegoExpressEngine.createEngine(profile, null);
```

### Obtain Original Video Data

ZEGO Express SDK can obtain original video data through two methods: [Custom Video Preprocessing](/real-time-video-android-java/best-practice/integration-with-zego-effects-sdk) and [Custom Video Capture](/real-time-video-android-java/best-practice/integration-with-zego-effects-sdk).

The difference between the two acquisition methods is as follows. Developers can choose as needed:

<table>

  <tbody><tr>
    <th>Data acquisition method</th>
    <th>Video data acquisition method</th>
    <th>Advantage</th>
  </tr>
  <tr>
    <td>Custom video preprocessing</td>
    <td>ZEGO Express SDK internally captures video data, and original video data is obtained through callbacks.</td>
    <td>Extremely simple integration of ZEGO Express SDK and ZEGO Effects SDK. Developers do not need to manage device input sources, only need to operate on the original data thrown by ZEGO Express SDK and then pass it back to ZEGO Express SDK.</td>
  </tr>
  <tr>
    <td>Custom video capture</td>
    <td>Developers capture video data themselves and provide it to ZEGO Express SDK.</td>
    <td>When integrating multiple manufacturers, business implementation is more flexible, and there is more room for performance optimization.</td>
  </tr>
</tbody></table>

<a id="Customvideopreprocessing"></a>

- **Method 1: Custom Video Preprocessing**

    Taking obtaining [GL_TEXTURE_2D](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~java_android~enum~ZegoVideoBufferType#zego-video-buffer-type-gl-texture2-d) type original video data as an example.

    Developers call the [enableCustomVideoProcessing](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-zego-express-engine#enable-custom-video-processing) interface to enable custom video preprocessing; after enabling, ZEGO Express SDK will internally capture video data; after capture is complete, the captured original video data can be obtained through the [onCapturedUnprocessedTextureData](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-callback-i-zego-custom-video-process-handler#on-captured-unprocessed-texture-data) callback interface.

    ```java
    ZegoCustomVideoProcessConfig config = new ZegoCustomVideoProcessConfig();
    // Select GL_TEXTURE_2D type video frame data
    config.bufferType = ZegoVideoBufferType.GL_TEXTURE_2D;

    // Enable custom preprocessing
    express.enableCustomVideoProcessing(true, config, ZegoPublishChannel.MAIN);
    ```

    For the specific principle, please refer to "Real-time Audio and Video" [Custom Video Preprocessing](/real-time-video-android-java/video/custom-video-preprocessing).

<a id="CustomCollection"></a>

- **Method 2: Custom Video Capture**

    For custom video capture, developers mainly need to capture video data themselves. For specific methods, please refer to "Real-time Audio and Video" [Custom Video Capture](/real-time-video-android-java/video/custom-video-capture).

### Perform AI Beauty Processing

After obtaining the original video data, pass the data to ZEGO Effects SDK to start AI beauty processing (such as: beauty effects, makeup, background segmentation, etc.) on the video.

- **Method 1: Custom Video Preprocessing**

    In the [onCapturedUnprocessedTextureData](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-callback-i-zego-custom-video-process-handler#on-captured-unprocessed-texture-data) callback, after obtaining the original video data, call the relevant interfaces of ZEGO Effects SDK to perform AI beauty processing (please refer to [Beauty Effects](/ai-effects-android-java/guides/face-beautification), [Shape Retouch](/ai-effects-android-java/guides/shape-retouch), [Background Segmentation](/ai-effects-android-java/guides/background-segmentation), [Face Detection](/ai-effects-android-java/guides/face-detection), [Stickers](https://doc-zh.zego.im/faq/AIEffect_Stickers?product=Effects&platform=android), [Filters](/ai-effects-android-java/guides/filters)), and return the processed data to ZEGO Express SDK.

    ```java
    // Custom preprocessing as an example
    // Callback method to obtain original data
    // Callback processing
    // Effect initialization and de-initialization in Express video preprocessing start/stop callbacks
    express.setCustomVideoProcessHandler(new IZegoCustomVideoProcessHandler() {
        @Override
        public void onStart(ZegoPublishChannel channel) {
            effects.initEnv(720, 1280);
        }

        // Must de-initialize, otherwise it will cause memory leak
        @Override
        public void onStop(ZegoPublishChannel channel) {
            effects.uninitEnv();
        }

        // Callback method to obtain original data texture
        @Override
        public void onCapturedUnprocessedTextureData(int textureID, int width, int height, long referenceTimeMillisecond, ZegoPublishChannel channel) {

            ZegoEffectsVideoFrameParam param = new ZegoEffectsVideoFrameParam();
            param.format = ZegoEffectsVideoFrameFormat.RGBA32;
            param.width = width;
            param.height = height;

            // Custom preprocessing: Use ZEGO Effects SDK here
            int processedTextureID = effects.processTexture(textureID, param);

            // Pass the processed buffer back to ZEGO Express SDK
            express.sendCustomVideoProcessedTextureData(processedTextureID, width, height, referenceTimeMillisecond);
        }
    }
    ```

- **Method 2: Custom Video Capture**

    After receiving the custom capture [onStart](@onStart) callback, developers obtain video data through custom capture, then call the relevant interfaces of ZEGO Effects SDK to perform AI beauty processing (please refer to [Beauty Effects](/ai-effects-android-java/guides/face-beautification), [Shape Retouch](/ai-effects-android-java/guides/shape-retouch), [Background Segmentation](/ai-effects-android-java/guides/background-segmentation), [Face Detection](/ai-effects-android-java/guides/face-detection), [Stickers](https://doc-zh.zego.im/faq/AIEffect_Stickers?product=Effects&platform=android), [Filters](/ai-effects-android-java/guides/filters)), and return the processed data to ZEGO Express SDK (can refer to [Custom Video Capture](/real-time-video-android-java/video/custom-video-capture#3-send-video-frame-data-to-sdk) in "Send video frame data to SDK").

### Publish Processed Data

After processing by ZEGO Effects SDK is completed, return the processed data to ZEGO Express SDK.

ZEGO Express SDK calls the [startPublishingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-zego-express-engine#start-publishing-stream) interface, passes in the processed data stream streamID, starts publishing, and sends it to the cloud server.

```java
// Start publishing stream
express.startPublishingStream("streamID");
```

### Pull and Play Processed Data

After ZEGO Express SDK starts publishing, remote users can call the [startPlayingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~Java_android~class~im-zego-zegoexpress-zego-express-engine#start-playing-stream) interface, pass in the processed data stream streamID, pull the video data, and play it.

```java
/**
 *  Start playing stream, set remote playing stream rendering view, view mode uses SDK default mode, proportional scaling fills the entire View
 *  The following play_view is a SurfaceView/TextureView/SurfaceTexture object on the UI interface
 */
express.startPlayingStream("streamID", new ZegoCanvas(play_view));
```

At this point, developers can completely achieve real-time adjustment of AI beauty effects while publishing and playing audio and video streams.
