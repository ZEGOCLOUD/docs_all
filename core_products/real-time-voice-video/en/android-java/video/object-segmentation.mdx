---
articleID: 16333
date: "2024-09-06"
---
# Object Segmentation

- - -

## Feature Overview


Object segmentation is a value-added capability provided by Express SDK. It uses AI algorithms to identify content in video frames and sets `transparency information` for each pixel. Among them, pixels in the subject part are set to "opaque", while pixels outside the subject part are set to "transparent". Developers can use the transparency information of these pixels to perform different processing on the subject and non-subject parts in the image, thereby achieving different functions.

<Warning title="Attention">
- The current official website SDK does not include "object segmentation" related functions. If needed, please contact ZEGO Technical Support for special packaging and provide your AppID to activate relevant permissions.
- "Object segmentation" is a paid feature. If you need to apply for a trial or inquire about formal pricing, please contact ZEGO business personnel.
</Warning>

### Object Segmentation Objects

For users in different environments, ZEGO provides two segmentation capabilities: "green screen background segmentation" and "arbitrary background segmentation".

<table>

<tbody><tr>
<th>Segmentation Type</th>
<th>Green Screen Background Segmentation</th>
<th>Arbitrary Background Segmentation</th>
</tr>
<tr>
<th>Capability Description</th>
<td><p>When users set up a green screen themselves, the subject in the non-green screen area can be retained.</p><p>Suitable for e-commerce live streaming, online exams, and other scenarios.</p></td>
<td><p>Most users do not have the conditions to set up a green screen. Through the arbitrary background segmentation capability provided by ZEGO, they can identify the subject in the image without a green screen.</p><p>Suitable for online education, video conferencing, and other scenarios.</p></td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_greenscreen.png" /></Frame></td>
<td><Frame width="auto" height="256" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/people_with_realenvironment.jpg" /></Frame></td>
</tr>
</tbody></table>

### Feature Scenarios

Based on the object segmentation capability, developers can implement business scenarios such as background blurring, virtual background, presenter mode, and multi-person real-time co-stage interaction, creating more diverse interactive experiences.

<table>

<tbody><tr>
<th>Feature Point</th>
<th>Background Blur</th>
<th>Virtual Background</th>
<th>Background Transparency</th>
<th>Subject Segmentation and Transmission</th>
</tr>
<tr>
<th>Feature Description</th>
<td>Blur the image outside the subject.</td>
<td>Replace the image outside the subject with custom images, videos, or colors.</td>
<td><p>Render the subject's image on other video content locally.</p><p>For example, implement presenter mode and other functions on screen sharing or playing video content.</p></td>
<td>Combine with the Alpha channel data transmission capability provided by Express SDK to transmit the segmented subject in the image to the play stream end, and render the subject at the play stream end, achieving the visual effect of multiple people in different locations being in the same scene in real time</td>
</tr>
<tr>
<th>Illustration</th>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/6364d2bc42.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/de1e9cf26f.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://media-resource.spreading.io/docuo/workspace740/af061ebc6eaf0f12ae9e7f72235bd04e/5bc5b6b70d.png" /></Frame></td>
<td><Frame width="auto" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/multiplayer.jpeg" /></Frame></td>
</tr>
</tbody></table>


### Hardware Compatibility

<table>

<tbody><tr>
<th>Platform</th>
<th>Hardware Requirements</th>
</tr>
<tr>
<td>Android</td>
<td><ul><li><p>Snapdragon chips:</p><ul><li>Snapdragon 6 series: Snapdragon 675 and above</li><li>Snapdragon 7 series: Snapdragon 730 and above</li><li>Snapdragon 8 series: Snapdragon 835 and above</li></ul></li><li><p>HiSilicon Kirin chips:</p><ul><li>Kirin 8 series: Kirin 820 and above</li><li>Kirin 9 series: Kirin 980 and above</li></ul></li><li><p>MediaTek chips:</p><ul><li>Helio P series: Helio P60 and above</li><li>Dimensity series: Dimensity 820 and above</li></ul></li><li>Samsung chips: Exynos 1080 and above</li></ul></td>
</tr>
<tr>
<td>iOS</td>
<td>A series chips: Apple A9 and above, for example iPhone 6s</td>
</tr>
<tr>
<td>macOS</td>
<td>M series chips: Apple M1 and above</td>
</tr>
<tr>
<td>Windows</td>
<td>Intel Core i5 and above</td>
</tr>
</tbody></table>

## Example Source Code

Please refer to [Download Example Source Code](/real-time-video-android-java/client-sdk/download-demo) to get the source code.

For related source code, please check the files in the "/ZegoExpressExample/Others/src/main/java/com/example/others/videoobjectsegmentation" directory.

## Prerequisites

Before using the object segmentation feature, please ensure:

- You have contacted ZEGO Technical Support for special packaging.

- You have created a project in the [ZEGO Console](https://console.zego.im) and applied for a valid AppID and AppSign. For details, please refer to [Console - Project Information](/console/project-info).
- You have integrated ZEGO Express SDK in your project and implemented basic audio and video streaming functionality. For details, please refer to [Quick Start - Integration](/real-time-video-android-java/quick-start/integrating-sdk) and [Quick Start - Implementation](/real-time-video-android-java/quick-start/implementing-video-call).



## Implementation Flow

<Warning title="Attention">
- Enabling the object segmentation feature will consume additional system resources. To ensure user experience, currently only supports enabling object segmentation for one channel's published stream image.
- For Android 12 and above versions, you need to add the following configuration in AndroidManifest.xml. For details, please refer to [Android Developers related instructions](https://developer.android.google.cn/guide/topics/manifest/uses-native-library-element?hl=zh-cn)ã€‚<br />
`<uses-native-library android:name="libOpenCL.so" android:required="false" />`<br />
  `<uses-native-library android:name="libOpenCL-pixel.so" android:required="false" />`
- If there are third-party filters that have undergone custom preprocessing, you need to ensure that the third-party filters support Alpha channel pass-through functionality.
</Warning>

<Frame width="512" height="auto" caption=""><img src="https://doc-media.zego.im/sdk-doc/Pics/subject_segmentation/subject_segmentation_android.png" /></Frame>

Please note that developers can choose whether to implement the **(Optional)** steps in the above figure according to their business scenario needs. If implementation is needed, please refer to the specific instructions below.

### 1 Initialize and login to Room

For the specific process of initialization and logging in to Room, please refer to "[Create Engine](/real-time-video-android-java/quick-start/implementing-video-call)" and "[Login to Room](/real-time-video-android-java/quick-start/implementing-video-call)" in the implementing video call documentation.

### 2 Make special settings for view

Before enabling object segmentation, you need to set the view for rendering in advance. Currently, both TextureView and SurfaceView are supported.

- If the view is of TextureView type, you need to call `setOpaque` to set the `opaque` attribute to `false`.

```java
TextureView playerView;//View for playing
playerView.setOpaque(false);
```

- If the view is of SurfaceView type, you need to call `setFormat` to set the `PixelFormat` attribute to `TRANSLUCENT`, and you need to place the view at the topmost layer of the display window.

```java
SurfaceView playerView;//View for playing
playerView.getHolder().setFormat(PixelFormat.TRANSLUCENT);
playerView.setZOrderOnTop(true)//Place SurfaceView at the topmost layer of the display window
```


### 3 (Optional) Implement custom rendering class

<Accordion title="Implement custom rendering class" defaultOpen="false">
<Note title="Note">


Through the following method, the performance of custom rendering is relatively low. ZEGO recommends that you use OpenGL ES for rendering to improve rendering performance. For details, please refer to [Run Example Source Code](/real-time-video-android-java/client-sdk/download-demo) implementation.
</Note>

Developers can perform custom rendering according to actual conditions. It should be noted that the video raw data contains an Alpha channel, and the raw data has not undergone Alpha premultiplication processing. Taking drawing Bitmap to render play stream data as an example:

1. Listen to custom rendering data callback and cache rendering frame data.

    <Warning title="Attention">
    Do not render directly in the callback, as it will block the callback thread and cause rendering abnormalities.
    </Warning>

    ```java
    @Override
    public void onRemoteVideoFrameRawData(ByteBuffer[] data, int[] dataLength, ZegoVideoFrameParam param, String streamID) {
        super.onRemoteVideoFrameRawData(data, dataLength, param, streamID);

        if(param.format == ZegoVideoFrameFormat.RGBA32)
        {
            RenderConfig renderConfig = new RenderConfig();
            renderConfig.frameParam = param;
            renderConfig.buffer = new byte[data[0].capacity()];
            data[0].get(renderConfig.buffer,0,data[0].capacity());
            // Cache playStream1 play stream data
            if(streamID.equals(playStream1)){
                dataQueuePlay1.offer(renderConfig);
            }
            // Cache playStream2 play stream data
            if(streamID.equals(playStream2)){
                dataQueuePlay2.offer(renderConfig);
            }
        }
    }
    ```

2. Process the original video frame data byte by byte and convert it to ARGB_8888 type data in 4-byte units.

    ```java
    int[] array = new int[renderFrame.buffer.length/4];

    for(int i=0;i<renderFrame.buffer.length/4;i++){
        b =  renderFrame.buffer[i*4];
        g =  renderFrame.buffer[i*4+1];
        r =  renderFrame.buffer[i*4+2];
        a =  renderFrame.buffer[i*4+3];

        int dd = (a&0xff)<<24 | (b&0xff)<<16 | (g&0xff)<<8 | (r&0xff);
        array[i] = (dd);
    }

    Bitmap bmp = Bitmap.createBitmap(array, renderFrame.frameParam.width, renderFrame.frameParam.height, Bitmap.Config.ARGB_8888);
    ```

3. Periodically draw the bitmap to the rendering view.

    ```java
    Canvas canvas = playView1.lockCanvas();
    if(canvas != null){
        // Clear screen
        paintPlayView1.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.CLEAR));
        canvas.drawPaint(paintPlayView1);

        //Off-screen drawing
        int layerID = canvas.saveLayer(0,0,canvas.getWidth(),canvas.getHeight(), null,Canvas.ALL_SAVE_FLAG);
        //Select SRC mode
        paintPlayView1.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.SRC));
        canvas.drawBitmap(bmpFinal, 0,0, paintPlayView1);
        paintPlayView1.setXfermode(null);
        canvas.restoreToCount(layerID);
    }
    playView1.unlockCanvasAndPost(canvas);
    ```
</Accordion>

### 4 (Optional) Enable custom rendering

<Accordion title="Enable custom rendering" defaultOpen="false">
Call the [enableCustomVideoRender](@enableCustomVideoRender) interface to set advanced engine configuration and enable custom rendering, and call the [setCustomVideoRenderHandler](@setCustomVideoRenderHandler) interface to set custom video rendering callbacks. For details, please refer to [Custom Video Rendering](/real-time-video-android-java/video/custom-video-rendering).

<Warning title="Attention">


When using custom rendering for object segmentation, [bufferType|\_blank](@bufferType-ZegoCustomVideoRenderConfig) only supports the `ZegoVideoBufferType.RAW_DATA` type.
</Warning>


```java
videoRenderer = new CustomVideoRender();//Custom video rendering class
videoRenderer.setPreviewView(previewView);//Preview view
videoRenderer.setPlayView1(playView1);//Play stream view1
videoRenderer.setPlayView2(playView2);//Play stream view2
ZegoCustomVideoRenderConfig config = new ZegoCustomVideoRenderConfig();//Custom rendering configuration
config.bufferType = ZegoVideoBufferType.RAW_DATA;//Select RAW_DATA type video frame data
config.frameFormatSeries = ZegoVideoFrameFormatSeries.RGB;//Select RGB color series data format
engine.enableCustomVideoRender(true, config);//Start custom video rendering
engine.setCustomVideoRenderHandler(videoRenderer);//Set custom video rendering callback
```
</Accordion>

### 5 Listen to object segmentation state callback

Call the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) interface to listen to object segmentation state callbacks.

<Warning title="Attention">

The object segmentation state callback depends on enabling preview or publishing stream. That is, if you need to listen to the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback, you need to call preview [startPreview](@startPreview) or publishing stream [startPublishingStream](@startPublishingStream).
</Warning>

```java
@Override
public void onVideoObjectSegmentationStateChanged(ZegoObjectSegmentationState state, ZegoPublishChannel channel, int errorCode) {
    super.onVideoObjectSegmentationStateChanged(state, channel, errorCode);

    if(state == ZegoObjectSegmentationState.ON){
        //Object segmentation enabled
    }else{
        //Object segmentation disabled
        //Abnormal shutdown, please check the error code
    }
}
```


### 6 Use object segmentation to implement different business functions

<Warning title="Attention">


If developers need to update the object segmentation type or background processing type, they need to modify the configuration of [ZegoObjectSegmentationConfig](@-ZegoObjectSegmentationConfig) and call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface again to enable object segmentation to update the object segmentation effect; the update result will be notified to developers through the [onVideoObjectSegmentationStateChanged](@onVideoObjectSegmentationStateChanged) callback.
</Warning>

#### Background Blur

<Accordion title="Use object segmentation to implement background blur" defaultOpen="false">
Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "blur".

```java
ZegoObjectSegmentationConfig config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.ANY_BACKGROUND;//Select the object segmentation type to enable according to the actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessType.BLUR;//Set background processing mode to blur
config.backgroundConfig.blurLevel = ZegoBackgroundBlurLevel.MEDIUM;//Set background blur level to medium
engine.enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.MAIN);//Enable object segmentation
```
</Accordion>

#### Virtual Background

<Accordion title="Use object segmentation to implement virtual background" defaultOpen="false">
Virtual background supports two types of materials:

- Images.
  Currently supports "PNG" and "JPEG" image formats, that is, image files with ".png", ".jpg", and ".jpeg" extensions.
- Videos, with the following restrictions:
    - Video format: MP4, FLV, MKV, AVI.
    - Video source: Local video.
    - Video playback mode: Loop playback.
    - Resolution: Maximum not exceeding 4096 px, recommended within 1920 px.
    - Video duration: Maximum not exceeding 30 seconds, recommended within 15 seconds.
    - Video size: Maximum not exceeding 50 MB, recommended within 10 MB.


<Warning title="Attention">


When developers use this feature, please pay attention to the aspect ratio of custom images and video materials, otherwise parts exceeding the view will be cropped.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "image" or "video".

```java
ZegoObjectSegmentationConfig config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.ANY_BACKGROUND;//Select the object segmentation type to enable according to the actual situation

//Set background processing mode to image
config.backgroundConfig.processType = ZegoBackgroundProcessType.IMAGE;
config.backgroundConfig.imageURL = "<image_path>";//Set background image path
engine.enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.MAIN);//Enable object segmentation

//Set background processing mode to video
config.backgroundConfig.processType = ZegoBackgroundProcessType.VIDEO;
config.backgroundConfig.videoURL = "<video_path>";//Set background video path
engine.enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.MAIN);//Enable object segmentation
```
</Accordion>

#### Transparent Background

<a name="enableAlphaChannelVideoEncoder"></a>

<Accordion title="Use object segmentation to implement transparent background" defaultOpen="false">
<Warning title="Attention">


If developers need to implement business functions similar to "presenter mode", they need to mix the "subject image" and "video source content to be mixed" into one video stream on the business side.
</Warning>

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation__1) interface to enable object segmentation and set the background processing type to "transparent".

```java
ZegoObjectSegmentationConfig config = new ZegoObjectSegmentationConfig();
config.objectSegmentationType = ZegoObjectSegmentationType.ANY_BACKGROUND;//Select the object segmentation type to enable according to the actual situation
config.backgroundConfig.processType = ZegoBackgroundProcessType.TRANSPARENT;//Set background processing mode to transparent
engine.enableVideoObjectSegmentation(enable, config, ZegoPublishChannel.MAIN);//Enable object segmentation
```
</Accordion>

### 7 (Optional) Use Alpha channel to transmit segmented subject

<Accordion title="Use Alpha channel to transmit segmented subject" defaultOpen="false">
If the publishing end needs to transmit the segmented subject image to the play stream end through the Alpha channel and render the subject at the play stream end, you need to first call the [enableAlphaChannelVideoEncoder](@enableAlphaChannelVideoEncoder) interface to set the encoder to support transparent channel, then call the [startPublishingStream](@startPublishingStream) interface to publish stream, so that it can be smoothly transmitted to the play stream end.

<Warning title="Attention">
Currently only supports transparent channel data arranged below RGB or YUV data.
</Warning>

- Enable Alpha channel data transmission:

    ```java
    ZegoAlphaLayoutType layoutType = ZegoAlphaLayoutType.BOTTOM; // Transparent channel data arranged below RGB or YUV data
    engine.enableAlphaChannelVideoEncoder(true, layoutType, ZegoPublishChannel.MAIN); // Enable encoder to support transparent channel
    ```

- Disable Alpha channel data transmission:

    ```java
    ZegoAlphaLayoutType layoutType = ZegoAlphaLayoutType.BOTTOM; // Transparent channel data arranged below RGB or YUV data
    engine.enableAlphaChannelVideoEncoder(false, layoutType, ZegoPublishChannel.MAIN); // Disable encoder to support transparent channel
    ```
</Accordion>

### 8 Start preview and publishing stream

After enabling the object segmentation feature through the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface, you can preview.

<Note title="Note">
Developers can also enable preview first, then enable object segmentation. This article takes enabling object segmentation first, then previewing as an example for introduction.
</Note>

- **Method 1**: Use internal rendering

    If using internal rendering, please set [alphaBlend](@alphaBlend-ZegoCanvas) to true before starting preview.

    ```java
    ZegoCanvas canvas = new ZegoCanvas(previewView);
    canvas.alphaBlend = true;//Enable internal rendering Alpha blending. After enabling, it supports Alpha blending between the segmented subject and the background layer
    engine.startPreview(canvas);
    engine.startPublishingStream(streamID);
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly preview and publish stream.
    ```java
    engine.startPreview();
    engine.startPublishingStream(streamID);
    ```

### 9 (Optional) Set Alpha channel rendering at play stream end and play stream

<Accordion title="Set Alpha channel rendering at play stream end and enable play stream" defaultOpen="false">
<Warning title="Attention">


Only when the publishing end has enabled Alpha channel transmission is it necessary to enable Alpha channel rendering at the play stream end.
</Warning>

- **Method 1**: Use internal rendering

    If using internal rendering, before calling the [startPlayingStream](@startPlayingStream) interface to start playing stream at the play stream end, you need to set the [alphaBlend](@alphaBlend-ZegoCanvas) attribute of [ZegoCanvas](@-ZegoCanvas) to true.

    ```java
    ZegoCanvas canvas = new ZegoCanvas(playView);
    canvas.alphaBlend = true;//Enable internal rendering Alpha blending. After enabling, it supports Alpha blending between the segmented subject and the background layer
    engine.startPlayingStream(streamID, canvas);
    ```

- **Method 2**: Use custom rendering

    If using custom rendering, you can directly play stream.

    ```java
    engine.startPlayingStream(streamID, null);
    ```
</Accordion>

### 10 Disable object segmentation

Call the [enableVideoObjectSegmentation](@enableVideoObjectSegmentation) interface to disable object segmentation.

```java
ZegoObjectSegmentationType objectType = ZegoObjectSegmentationType.ANY_BACKGROUND;//Select the object segmentation type to disable according to the actual situation
engine.enableVideoObjectSegmentation(false, objectType, ZegoPublishChannel.MAIN);//Disable object segmentation
```

### 11 Destroy Engine

Call the [destroyEngine](@destroyEngine) interface to destroy the Engine.

```java
ZegoExpressEngine.destroyEngine(null);
```
