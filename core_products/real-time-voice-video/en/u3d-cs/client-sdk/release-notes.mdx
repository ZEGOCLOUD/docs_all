---
articleID: 12554
date: "2025-06-23"
---



# Release Notes

- - -

## Version 3.21.0 <a id="3.21.0"></a>

**Release Date: 2025-06-23**

**New Features**


1. Support for SEI type configuration, capability detection, and log level setting in Web projects

    For related APIs, please refer to [SetSEIConfig](@SetSEIConfig), [CheckSystemRequirements](@CheckSystemRequirements), [SetLogConfig](@SetLogConfig)

2. Support for listening to local device exception notifications and device state change event callbacks in Web projects

    For related APIs, please refer to [OnLocalDeviceExceptionOccurred](@OnLocalDeviceExceptionOccurred), [OnVideoDeviceStateChanged](@OnVideoDeviceStateChanged), [OnAudioDeviceStateChanged](OnAudioDeviceStateChanged).

3. Support for Karaoke scenario configuration in Web projects

    Support for using audio and video configuration suitable for Karaoke scenarios [Karaoke](@ZegoScenarioKaraoke-ZegoScenario) in Web projects, suitable for real-time ensemble singing and online K-song scenarios. Optimizations have been made for latency, sound quality, ear return, and echo cancellation, while ensuring precise alignment and ultra-low latency for multi-person ensemble singing. For details, please refer to [Scenario-based Audio and Video Configuration](../quick-start/scenario-based-audio-video-configuration.mdx).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

**Improvements and Optimizations**

1. Updated integration of Express Native SDK to version 3.21.0.
2. Updated integration of Express Web SDK to version 3.9.0.

**Bug Fixes**

<Note title="Note">

The following bug fixes only apply to Web platform interfaces.
</Note>

1. Fixed compilation errors after integrating the SDK
2. Fixed other known issues in Unity WebGL.


## Version 3.19.0 <a id="3.19.0"></a>

**Release Date: 2025-02-14**

**New Features**

1. Support for enabling voice changer effects for media player audio output

    The media player adds the [EnableVoiceChanger] interface, supporting the enabling of voice changer effects for audio output by the media player, while allowing the selection of desired voice changing effects.

    For related APIs, please refer to [ZegoMediaPlayer > EnableVoiceChanger](@EnableVoiceChanger-ZegoMediaPlayer)

2. Support for adding the mixed output stream to a target room

    The stream mixing feature supports adding the mixed output stream to a specified room, that is, setting the target room information ([targetRoom](@targetRoom)) for the output stream. Each output stream can only join one room, and once added, the room cannot be dynamically updated during the mixing process. To use the server-side interface to implement this feature, please refer to the [Start Mixing](/real-time-video-server/api-reference/stream-mixing/start-mix) documentation.

**Improvements and Optimizations**

1. Updated integration of Express Native SDK to version 3.19.0.


---

## Version 3.16.2 <a id="3.16.2"></a>

**Release Date: 2024-08-19**

**New Features**

1. Support for initiating mixing tasks even when image resource validation fails

    ZegoMixerTask adds a new parameter mixImageCheckMode to control whether mixing tasks can be initiated normally when image resources such as background images (backgroundImageURL), input stream placeholder images (inputList.imageInfo.url), and watermark images (watermark.imageURL) fail validation.

    This feature is disabled by default (mixImageCheckMode defaults to 0), indicating strict image validation, meaning that mixing tasks can only be initiated when rules such as "supported protocols and formats," "image size," and "successful image resource requests" are met.

    The ZEGO server API mixing interface already supports this feature. For details, please refer to the CheckImageMode parameter in [Start Mixing](/real-time-video-server/api-reference/stream-mixing/start-mix).

    For related APIs, please refer to [StartMixerTask](@StartMixerTask)

2. Added electronic sound effects

    Electronic sound effects refer to the effect of making a person's speaking or singing voice sound electronic after processing. This feature is commonly used in KTV and audio chat room scenarios.

    Before initializing the SDK with [CreateEngine], call the [SetElectronicEffects] interface to enable electronic sound effects, and set different modes of electronic tonality and corresponding starting pitch for each mode as needed. When this interface is not called, electronic sound effects are disabled by default.

    Developers can also use the [SetVoiceChangerPreset] interface to preset common electronic sound effects. Currently supports presetting C major electronic sound effects, A minor electronic sound effects, and harmonic minor electronic sound effects.

    For related APIs, please refer to [SetElectronicEffects](@SetElectronicEffects)

3. Added audio equalizer (EQ)

    Support for adjusting the gain values of 10 frequency bands to achieve tone adjustment.

    For related APIs, please refer to [SetAudioEqualizerGain](@SetAudioEqualizerGain)

4. Added support for setting and getting audio device volume

    Note: Only Windows, macOS, and Linux support this feature.

    Support for setting the capture volume of audio devices (speakers or microphones) through the [SetAudioDeviceVolume] interface before publishing and playing streams. However, due to system limitations, this interface call may fail. It is recommended to directly use the [SetCaptureVolume] and [SetPlayVolume] interfaces to adjust publish and play stream volume.

    For related APIs, please refer to [SetAudioDeviceVolume](@SetAudioDeviceVolume), [GetAudioDeviceVolume](@GetAudioDeviceVolume), [SetCaptureVolume](@SetCaptureVolume), [SetPlayVolume](@SetPlayVolume)

5. Support for monitoring audio device volume

    Note: Only Windows and macOS platforms support this feature.

    Can monitor the volume of audio input or output devices.

    For related APIs, please refer to [StartAudioDeviceVolumeMonitor](@StartAudioDeviceVolumeMonitor), [StopAudioDeviceVolumeMonitor](@StopAudioDeviceVolumeMonitor)

6. Support for muting or unmuting audio devices

    Note: Only Windows, macOS, and Linux platforms support this feature.

    Can mute or unmute audio input or output devices as needed.

    For related APIs, please refer to [MuteAudioDevice](@MuteAudioDevice), [IsAudioDeviceMuted](@IsAudioDeviceMuted)

7. Support for getting currently used audio device information

    Note: Only Windows and macOS platforms support this feature.

    Call the [GetCurrentAudioDevice] interface to get information about the currently used audio device, including device ID and device name, reducing development workload.

    For related APIs, please refer to [GetCurrentAudioDevice](@GetCurrentAudioDevice)

8. Support for pushing static images when camera is disabled

    When the camera is disabled, support for continuously pushing static images in JPEG/JPG, BMP, and HEIF formats. For example, when a host goes to the background, they will actively disable the camera, and at this time, the audience side needs to display an image indicating the host is temporarily away.

    After initializing the SDK and before disabling the camera, use the [SetDummyCaptureImagePath] interface to set the path of the static image to be pushed. After starting normal publishing stream, calling the [EnableCamera] interface to disable the camera will start pushing the static image, and calling the [EnableCamera] interface to enable the camera will end pushing the static image.

    For related APIs, please refer to [SetDummyCaptureImagePath](@SetDummyCaptureImagePath)

9. Support for throwing [SetDummyCaptureImagePath] exception callback

    For related APIs, please refer to [OnPublisherDummyCaptureImagePathError](@OnPublisherDummyCaptureImagePathError)


10. Media player supports caching network resources locally

    Support for caching network resources locally. When playing the same network resource, cached data will be used preferentially, improving user experience.

    For related APIs, please refer to [EnableLocalCache](@EnableLocalCache)

11. During publishing stream, can control whether the stream is allowed for content moderation

    Note: If a stream is set to allow moderation, it will not be submitted for moderation unless the developer initiates a moderation task.

    When calling the moderation interface, by default all streams in the room will be moderated. If the client needs to control that a certain stream cannot be submitted for moderation, when calling the [StartPublishingStream] interface to start publishing stream, set the moderation flag [streamCensorFlag] parameter to 1 (not allowed).

    For related APIs, please refer to [StartPublishingStream](@StartPublishingStream), [ZegoPublisherConfig > StreamCensorFlag](@StreamCensorFlag-ZegoPublisherConfig)


12. H.265 client encoding automatic compatibility strategy adds user-level negotiation range

    Note: To use this feature, please contact ZEGO Technical Support.

    Control the local client encoding compatibility range to all publishing users or all users in the room. That is, when users within the specified range do not support H.265, the local client encoding dynamically falls back.

    For related APIs, please refer to [LoginRoom](@LoginRoom), [StartPublishingStream](@StartPublishingStream), [ZegoPublisherConfig > codecNegotiationType](@codecNegotiationType-ZegoPublisherConfig), [ZegoRoomConfig > capabilityNegotiationTypes](@capabilityNegotiationTypes-ZegoRoomConfig)



**Improvements and Optimizations**

1. Optimized basic AI Effects functionality

    ZEGO provides a brand-new basic AI Effects feature, presenting good skin condition for users and creating natural beauty effects. Developers need to call the [StartEffectsEnv] interface to initialize the beauty environment before publishing stream, then call the [EnableEffectsBeauty] interface to enable the beauty feature. Through the [SetEffectsBeautyParam] interface, you can adjust the degree of whitening, smoothing, sharpening, and reddening as needed to achieve basic beauty capabilities.

    This feature is commonly used in scenarios such as video calls and live streaming.

    For related APIs, please refer to [StartEffectsEnv](@StartEffectsEnv), [StopEffectsEnv](@StopEffectsEnv), [EnableEffectsBeauty](@EnableEffectsBeauty), [SetEffectsBeautyParam](@SetEffectsBeautyParam)

2. Optimized Android platform video rendering functionality

    Android platform video rendering prioritizes using SurfaceTexure for rendering.


**Deprecations and Deletions**

1. Deprecated CDN Plus configuration in the playing stream interface

    Discontinued the live streaming concept and deprecated CDN Plus live streaming related interfaces. To implement live streaming functionality, it is recommended to use ZEGO's self-developed [Ultra-low Latency Live Streaming Product](/real-time-video-android-java/introduction/overview) to achieve higher quality live streaming experiences.

    For related APIs, please refer to [ZegoStreamResourceModeCDNPlus](@ZegoStreamResourceModeCDNPlus)


---


## Version 3.14.5 <a id="3.14.5"></a>

**Release Date: 2024-05-07**

**New Features**

1. Mobile development supports iOS 17.0

    Note: From this version onwards, iOS 11.0 and earlier versions are no longer supported.

    Starting from 2024-04-29, all apps submitted to the App Store must support iOS 17.0. For details, please refer to [Apple Developer Website Official Announcement](https://developer.apple.com/news/upcoming-requirements/?id=04292024a).

**Improvements and Optimizations**

1. Updated privacy manifest file `PrivacyInfo.xcprivacy` in iOS SDK

    Note: If customers have integrated SDK version earlier than 3.13.2 and wish to publish to the App Store, they need to download the latest version of the SDK and copy the PrivacyInfo.xcprivacy file to the corresponding location of the old SDK.

    Please upgrade the privacy manifest file `PrivacyInfo.xcprivacy` in the iOS SDK to the new version. For details, please refer to "PrivacyInfo.xcprivacy" in the "ZegoExpressEngine.framework" folder in the SDK package.


---

## Version 3.12.4 <a id="3.12.4"></a>

**Release Date: 2024-01-18**

**New Features**

1. Support for copyrighted music plugin

<Warning title="Warning">
- To use this feature, please contact ZEGO Technical Support.
- The copyrighted music plugin package cannot be used alone and must be used in conjunction with Express SDK.
</Warning>

  Support for copyrighted music feature as a plugin. When developers' business scenarios only need to update copyrighted music-related code, they can integrate the plugin package separately without updating the Express SDK for smooth migration.

**Bug Fixes**

1. Fixed UI stuttering issues with very low probability when network is abnormal during network switching


---

## Version 3.12.3 <a id="3.12.3"></a>

**Release Date: 2024-01-08**

**Bug Fixes**

1. Fixed occasional crash issues when calling [EnableAudioCaptureDevice] interface on iOS platform


---

## Version 3.12.2 <a id="3.12.2"></a>

**Release Date: 2024-01-04**

**Bug Fixes**

1. Fixed potential issues


---

## Version 3.11.0 <a id="3.11.0"></a>

**Release Date: 2023-12-13**

**New Features**

1. Added enable or disable playing stream alignment feature

    This feature is commonly used in KTV and other scenarios that require mixing alignment. When playing streams, through the [SetPlayStreamsAlignmentProperty](@SetPlayStreamsAlignmentProperty) interface, control whether the played real-time audio and video streams need precise alignment. If alignment is needed, all pulled streams containing precise alignment parameters will be aligned; if not needed, all streams will not be aligned.

    For related APIs, please refer to [SetPlayStreamsAlignmentProperty](@SetPlayStreamsAlignmentProperty)

2. Publish stream video supports color enhancement

    For situations where screens captured by cameras and other devices have grayish colors or low saturation, support for enhancing video colors while protecting skin tones, making them more vivid and bright, and more in line with the human eye's true visual perception. For details, please refer to [Publish Stream Video Enhancement](/real-time-video-u3d-cs/video/publish-video-enhancement).

    For related APIs, please refer to [EnableColorEnhancement](@EnableColorEnhancement)

3. All network requests support IPv6 protocol

4. Support for MJPEG format hardware decoding acceleration

    Note: This feature only supports pre-processing for screenshots, not other processing (such as rotation, watermarks, etc.).

    When the video format output by the capture device is MJPEG, hardware decoding acceleration is enabled by default to prevent issues such as insufficient frame rate caused by insufficient device performance.

    This feature is mainly suitable for use on 4K resolution capture devices.

5. Stream mixing supports inputting live protocol streams

    Added support for using live streams as input streams for stream mixing processing. Live input stream URLs support both RTMP and HTTP-FLV protocols. This feature is suitable for scenarios such as game or sports live streaming commentary, mixing the host's co-hosting RTC video stream with cloud sports live streams or game live video streams.

**Improvements and Optimizations**

1. Optimized server-side stream mixing and single stream transcoding capabilities

    Optimized server-side stream mixing and single stream transcoding capabilities, improving encoding efficiency and enhancing subjective and objective video quality by more than 5% at the same bitrate.

2. Optimized AEC (Acoustic Echo Cancellation) algorithm for better AEC performance

3. Optimized network connection strategy to improve audio and video call experience

4. Optimized Android platform foreground/background switching strategy, resolving issues with采集静音 in certain specific scenarios or device models

5. Optimized multi-device login logic

    After a user successfully logs in on device A, device A loses network connection; then uses the same userID to successfully log in on device B. At this time, if device A's network recovers, reconnection will fail and error code 1002086 will be thrown, indicating that this userID has already logged in on another device.

**Bug Fixes**

1. Fixed crashes caused by hardware encoding and decoding in certain situations on iOS platform

2. Fixed missing state notifications after camera recovery on iOS platform

3. Fixed crashes caused by decoding in certain situations on Android platform

4. Fixed crashes when exiting hardware decoding on NVIDIA cards on Windows platform in certain situations

5. Fixed camera restart strategy issues on Windows platform


---

## Version 3.10.2 <a id="3.10.2"></a>

**Release Date: 2023-11-20**

**Bug Fixes**

1. Fixed false positives in mobile sleep detection module affecting room re-login and publish/play stream retry logic


---

## Version 3.10.1 <a id="3.10.1"></a>

**Release Date: 2023-11-09**

**Bug Fixes**

1. Fixed black screen issue after enabling low light enhancement



---

## Version 3.8.1 <a id="3.8.1"></a>

**Release Date: 2023-08-17**

**New Features**

1. Added support for "Smart Cloud Proxy" mode

    Note: To use this feature, please contact ZEGO Technical Support.

    After developers set the "Smart Cloud Proxy" mode, during RTC or L3 playing stream, the system will first attempt to use direct connection mode. If direct connection is unavailable and the current network is cellular, it will continue to retry in direct connection mode; if direct connection is unavailable and the current network is non-cellular, it will switch to cloud proxy mode. For details, please refer to [Cloud Proxy](/real-time-video-u3d-cs/communication/cloud-proxy).

2. Custom video pre-processing feature supports dual output

    Custom video pre-processing feature supports "dual output," that is, supporting output of both "memory data" and "2D texture data." Developers can use this data to implement third-party beauty features and perform face detection and beauty enhancement with higher performance.

    For related APIs, please refer to [OnCapturedUnprocessedRawData](@OnCapturedUnprocessedRawData), [ZegoVideoBufferTypeGLTexture2DAndRawData](@ZegoVideoBufferTypeGLTexture2DAndRawData)

3. Media player supports setting Http Headers for network resources

    Media player supports setting Http Headers for network resources. Based on this configuration, developers can customize restrictions on access to network resources and strengthen resource security protection.

    For related APIs, please refer to [SetHttpHeader](@SetHttpHeader)

4. Support for multi-source capture capability

    For interactive scenarios with rich and diverse audio and video sources such as online KTV, watching movies together, watching matches, video conferencing, and online education, multi-source capture provides flexible and easy-to-use audio and video capture source and channel management capabilities, significantly reducing developer development and maintenance costs.

    Multi-source capture capability shortens and optimizes the implementation paths for common capabilities such as screen sharing and audio mixing, and provides unified design. After version 3.8.0, you no longer need to implement the above complex capabilities through custom capture. For details, please refer to [Multi-Source Capture](/real-time-video-u3d-cs/communication/multi-source-capture).

    Main capability features:

1. Publish stream channels support setting or switching multiple audio and video sources.

2. Support for common capabilities such as screen sharing and audio mixing.

**Improvements and Optimizations**

1. Optimized iOS platform video rendering effects


---

## Version 3.7.0 <a id="3.7.0"></a>

**Release Date: 2023-07-18**

**New Features**

1. After enabling video large and small stream encoding, in addition to large stream video parameters, added support for setting small stream video parameters

    Note:

1. Before using this feature, you need to call the [SetVideoConfig](@SetVideoConfig) interface and specify the video encoding format codecID as "ZegoVideoCodecIDH264DualStream (large and small stream encoding)."

2. The "ratio" of the resolution settings for large and small streams needs to remain consistent, otherwise calling the interface will result in an error.

    When the encoding format is specified as "large and small stream encoding," support for separately setting resolution, frame rate, and bitrate for large and small streams. For details, please refer to [Video Large and Small Streams and Layered Encoding](/real-time-video-u3d-cs/video/small-large-video-stream-and-layered-encoding).

    For related APIs, please refer to [SetVideoConfig](@SetVideoConfig), [SetPublishDualStreamConfig](@SetPublishDualStreamConfig)

2. Support for dynamically modifying AudioDeviceMode

    Added [SetAudioDeviceMode](@SetAudioDeviceMode) interface for dynamically modifying device audio mode. This configuration determines device volume mode, pre-processing mode, and Mic occupation logic. You can choose according to specific scenarios. For details, please refer to [How to Set Audio Device Mode ZegoAudioDeviceMode?](http://doc-zh.zego.im/faq/AudioDeviceMod?product=ExpressVideo&platform=unity3d)

    For related APIs, please refer to [SetAudioDeviceMode](@SetAudioDeviceMode)

3. Large-scale range audio and video, game voice support configuring 3D audio effect distance attenuation range

    In large-scale range audio and video and game voice scenarios, support for setting the attenuation range interval [min, max] for 3D audio effect distance. When the distance is less than min, volume will not attenuate as distance increases; when the distance is greater than max, the other party's sound cannot be heard.

    For related APIs, please refer to [SetReceiveRange](@SetReceiveRange), [SetAudioReceiveRange](@SetAudioReceiveRange)

4. Express Unity3D SDK adds support for running in WebGL environment

    Unity projects running in WebGL environment now support using some features and interfaces of ZEGO RTC services, including audio and video calls, device management, etc.

    Please refer to [Feature Overview](https://doc-zh.zego.im/article/14271) to view specific feature and interface support, and refer to [Run Example Source Code](/real-time-video-u3d-cs/quick-start/run-example-code) and [Integrate SDK](/real-time-video-u3d-cs/quick-start/integrating-sdk) for integration.

**Improvements and Optimizations**

1. Support for generating log upload tasks after calling [DestroyEngine] interface

    For related APIs, please refer to [SubmitLog](@SubmitLog)


---


## Version 3.4.2 <a id="3.4.2"></a>

**Release Date: 2023-04-25**

**New Features**

1. Support for enabling camera adaptive frame rate

    Note: When the frame rate set by [SetVideoConfig](@SetVideoConfig) is less than the minimum expected frame rate of [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS), the frame rate value set by [SetVideoConfig](@SetVideoConfig) will be used. Due to different hardware and algorithm strategies of different phone manufacturers, the effects of this interface vary across different device models or front and rear cameras of the same device model.

    When the publishing stream user sets a higher frame rate but the ambient lighting is too low to display or identify the subject normally, you can call the [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS) interface to automatically reduce the frame rate within a certain range to increase exposure time, thereby improving video screen brightness. This feature is commonly used in live streaming scenarios with high exposure requirements. The [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS) interface needs to be called after calling the [CreateEngine](@CreateEngine) interface to initialize the engine and before starting the camera.

    For related APIs, please refer to [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS)

2. Support for setting low light enhancement

    Note: Need to call the [SetLowlightEnhancement](@SetLowlightEnhancement) interface after calling the [CreateEngine](@CreateEngine) interface to create the engine.

    When the publishing stream user's surrounding environment is dark or the camera frame rate setting is high, resulting in a dark live stream screen that cannot display or identify the subject normally, you can call the [SetLowlightEnhancement](@SetLowlightEnhancement) interface to set low light enhancement and improve video screen brightness. Low light enhancement feature includes three modes: 1: Do not enable low light enhancement (default), 2: Enable low light enhancement, 3: Automatically enable/disable low light enhancement.

    Developers can choose different low light enhancement modes based on business scenarios: when you want to judge whether low light enhancement is needed yourself, you can control by switching between mode 1 and mode 2; when you want the SDK to automatically enhance, you can use mode 3, and the SDK will automatically determine the user's lighting environment and enable or disable low light enhancement. For details, please refer to [Low Light Enhancement](/real-time-video-u3d-cs/video/publish-video-enhancement).

    For related APIs, please refer to [SetLowlightEnhancement](@SetLowlightEnhancement)

3. Support for enabling system sound card capture

    After enabling sound card capture, system playing sounds such as browser sounds and third-party player software sounds can be mixed into the publish stream, and supports setting capture volume through [SetMixSystemPlayoutVolume](@SetMixSystemPlayoutVolume).

    For related APIs, please refer to [EnableMixSystemPlayout](@EnableMixSystemPlayout), [SetMixSystemPlayoutVolume](@SetMixSystemPlayoutVolume)

**Bug Fixes**

1. Fixed possible crashes when exiting the application

**Deprecations and Deletions**

1. Starting from version 3.4.2, deprecated support for iOS versions earlier than iOS 11.0, iOS Deployment Target (minimum support version) raised to iOS 11.0

    For specific details, please refer to [App Store submission requirement starts April 25](https://developer.apple.com/news/?id=jd9wcyov) and [Xcode 14 Release Notes](https://developer.apple.com/documentation/xcode-release-notes/xcode-14-release-notes#Build-System).

2. Starting from version 3.4.2, iOS SDK no longer supports 32-bit armv7 architecture

    For specific details, please refer to [Xcode 14 Release Notes](https://developer.apple.com/documentation/xcode-release-notes/xcode-14-release-notes#Build-System).



---

## Version 3.3.0 <a id="3.3.0"></a>

**Release Date: 2023-03-24**


**New Features**

1. Scenario-based audio and video configuration adds `StandardVoiceCall` standard voice call scenario
    Scenario-based audio and video configuration adds `StandardVoiceCall` standard voice call scenario, suitable for 1v1 pure voice call scenarios. For details, please refer to [Scenario-based Audio and Video Configuration](/real-time-video-u3d-cs/quick-start/scenario-based-audio-video-configuration).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

2. Support for setting minimum values for video frame rate and video resolution

    Added [SetMinVideoFpsForTrafficControl](@SetMinVideoFpsForTrafficControl) and [SetMinVideoResolutionForTrafficControl](@SetMinVideoResolutionForTrafficControl) interfaces. When the user's network is poor and traffic control is enabled, you can set the minimum video frame rate and resolution by calling these interfaces to help users comprehensively control video display effects.


    For related APIs, please refer to [SetMinVideoFpsForTrafficControl](@SetMinVideoFpsForTrafficControl), [SetMinVideoResolutionForTrafficControl](@SetMinVideoResolutionForTrafficControl)


---

## Version 3.2.0 <a id="3.2.0"></a>

**Release Date: 2023-02-01**


**Improvements and Optimizations**

1. Custom signaling configuration supports extension to 4KB

    Note: The default size for custom signaling configuration is 1KB. To extend to 4KB, please contact ZEGO Technical Support for processing.


**Bug Fixes**

1. Fixed null pointer crash issue when restarting after hardware decoding failure


2. Fixed crash issue when accessing non-existent APIs after starting engine on iOS 14

3. Fixed network time module retry failure issue



---

## Version 3.1.0 <a id="3.1.0"></a>

**Release Date: 2022-12-13**


**New Features**

1. "Large-scale Range Audio and Video" and "Multi-person Real-time State Synchronization" features support using scenario templates

    Note: To use this feature, please contact ZEGO Technical Support.

    In virtual scenarios, because each scenario has different map sizes, audio and video interaction gameplay and scales, customization is required for each scenario. After version 3.1.0, "Large-scale Range Audio and Video" and "Multi-person Real-time State Synchronization" support specifying scenarios through SDK interfaces using template IDs. Configuration items corresponding to template IDs can only be configured through server APIs. For details, please refer to [Server API - Scenario Template Configuration](/real-time-video-server/api-reference/scene/set-scene-template).

    For related APIs, please refer to [templateID](@templateID)

2. "Large-scale Range Audio and Video" and "Multi-person Real-time State Synchronization" features support using Token basic authentication

    Note: To use this feature, please contact ZEGO Technical Support.

    When users log in to a scenario, they can carry a Token parameter to verify legitimacy.

    For related APIs, please refer to [ZegoSceneParam > token](@token-ZegoSceneParam), [ZegoRangeScene > RenewToken](@RenewToken-ZegoRangeScene)



3. SDK supports setting cloud proxy

    Note: To use this feature, please contact ZEGO Technical Support.

    By setting the SDK's cloud proxy interface, all traffic corresponding to the SDK is forwarded through cloud proxy servers to communicate with RTC. For details, please refer to [Cloud Proxy](/real-time-video-u3d-cs/communication/cloud-proxy).

    For related APIs, please refer to [SetCloudProxyConfig](@SetCloudProxyConfig)




---

## Version 3.0.3 <a id="3.0.3"></a>

**Release Date: 2022-11-29**

**New Features**

1. Support for Linux platform

    Express Unity3D SDK now supports Linux x86_64 architecture. For development environment requirements, please refer to [Integrate SDK](/real-time-video-u3d-cs/quick-start/integrating-sdk).

**Bug Fixes**


1. Fixed possible hardware decoding crashes on iOS, macOS, and Windows platforms

2. Fixed issue where others in the room could not receive stream deletion notifications when stopping publish stream in multi-room mode



---

## Version 3.0.0 <a id="3.0.0"></a>

**Release Date: 2022.11.01**

<Warning title="Warning">


This update includes incompatible changes. For details, please refer to [v3.0.0 Upgrade Guide](/real-time-video-u3d-cs/introduction/upgrade-guide/upgrade-guide4).

</Warning>



**New Features**

1. Added video first frame callback based on camera activation

    Supports callback after SDK plays and renders the first frame of remote camera video data each time a remote camera is enabled. Developers can use this callback to track first frame rendering time or update playing stream UI components.

    For related APIs, please refer to [OnPlayerRenderCameraVideoFirstFrame](@OnPlayerRenderCameraVideoFirstFrame)

2. Support for querying current SDK feature capabilities

    Since SDK supports feature cropping, some features may have been cropped. This function can be used to quickly determine whether the current SDK supports specified feature capabilities.

    For related APIs, please refer to [IsFeatureSupported](@IsFeatureSupported)

3. Added room-level Scenario

    To help developers quickly integrate and reduce the integration threshold, the SDK provides multiple preset scenarios. Developers can choose corresponding room modes [ZegoScenario](@-ZegoScenario) based on their needs, and the SDK will automatically apply audio and video codecs, audio and video parameters, flow control strategies, and other configurations suitable for that scenario, thereby quickly achieving the best results in that scenario.

    Currently supported scenarios include show live streaming, KTV, standard 1v1 audio and video calls, high-quality 1v1 audio and video calls, standard audio chat rooms, high-quality audio chat rooms. For details, please refer to [Scenario-based Audio and Video Configuration](/real-time-video-u3d-cs/quick-start/scenario-based-audio-video-configuration).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

4. Added debugging assistant feature

    Note: This feature is only used during the development phase. Do not enable this feature in release versions.

    Added [EnableDebugAssistant](@EnableDebugAssistant) interface. When developers call this interface to enable the debugging assistant feature, the SDK will print logs to the console, and when exceptions occur in calling other SDK interfaces, the UI will pop up error prompts.

    For related APIs, please refer to [EnableDebugAssistant](@EnableDebugAssistant)


**Bug Fixes**

1. Fixed low-probability crashes when exiting the App

**Deprecations and Deletions**

1. Deprecated three old version scenarios of [ZegoScenario](@-ZegoScenario)

    Deprecated [General], [Communication], [Live] scenarios in the [ZegoScenario](@-ZegoScenario) scenario enumeration. For details, please refer to [Scenario-based Audio and Video Configuration](/real-time-video-u3d-cs/quick-start/scenario-based-audio-video-configuration).

2. Deleted interfaces such as [SetDebugVerbose], [SetPlayStreamVideoLayer], [EnableAudioDataCallback], etc. For details, please refer to [Version 3.0.0 Upgrade Guide](/real-time-video-u3d-cs/introduction/upgrade-guide/upgrade-guide4).



---

## Version 2.23.0 <a id="2.23.0"></a>

**Release Date: 2022.09.13**



**Bug Fixes**


1. Fixed issue in range voice feature where after leaving a team, voices of original team members could still be heard when beyond range distance



---



## Version 2.21.2 <a id="2.21.2"></a>

**Release Date: 2022.08.02**

**New Features**

1. Added feature to get video rendering Texture2D

    Note: In Unity, texture2D coordinates start from the bottom-left corner, while image coordinates start from the top-left corner, so the Y-axis of the Texture2D default rendered image appears flipped.

    In the parent class IVideoSurface of [ZegoExpressEngine](@-ZegoExpressEngine), added interface GetNativeTexture2D for copying a Texture2D of the SDK's current rendered image for external use.


---

## Version 2.21.1 <a id="2.21.1"></a>

**Release Date: 2022.07.15**

**New Features**

1. Stream mixing supports setting video borders to rounded corners

    When calling the [StartMixerTask](@StartMixerTask) interface for stream mixing, developers can set "cornerRadius" (video image rounded corner radius) through the "ZegoMixerInput" type parameter to set video borders to rounded corners. The unit for "cornerRadius" is px, and the value cannot exceed half of the shorter of the video image width and height.

    For related APIs, please refer to [StartMixerTask](@StartMixerTask)

2. Playing stream interface adds CDN Plus playing stream configuration

    Note: If you want to control the playing stream method from the cloud through more dimensions such as region and users, please contact ZEGO Technical Support for related configuration.

    Playing stream interface adds CDN_PLUS stream resource mode ([ZegoStreamResourceMode](@-ZegoStreamResourceMode)). Developers can enable CDN_PLUS playing stream on a per-stream basis. CDN Plus playing stream is a cost-effective playing stream method with higher live streaming quality than CDN playing stream but similar price. For details, please refer to [CDN Plus Playing Stream](/live-streaming-android/introduction/overview).

    For related APIs, please refer to [StartPlayingStream](@StartPlayingStream)

**Bug Fixes**

1. Fixed issue where [DestroyEngine](@DestroyEngine) could cause Unity Editor to crash

2. Fixed issue where triggering SDK callbacks during app exit could cause crashes


---

## Version 2.20.3 <a id="2.20.3"></a>

**Release Date: 2022.07.01**

**New Features**

1. Added audio data monitoring feature

    When developers need to get remote user audio data or need to get locally captured microphone data for other uses (such as pure audio recording, pure audio third-party monitoring, pure audio real-time analysis), they can call the [StartAudioDataObserver](@StartAudioDataObserver) interface to enable real-time audio data monitoring.

    For related APIs, please refer to [StartAudioDataObserver](@StartAudioDataObserver), [StopAudioDataObserver](@StopAudioDataObserver), [OnCapturedAudioData](@OnCapturedAudioData), [OnPlayerAudioData](@OnPlayerAudioData), [OnPlaybackAudioData](@OnPlaybackAudioData), [OnMixedAudioData](@OnMixedAudioData)


---

## Version 2.20.2 <a id="2.20.2"></a>

**Release Date: 2022.06.20**

**Bug Fixes**

1. Fixed a probabilistic playing stream failure issue

2. Fixed issue where setting audio device mode before initializing SDK did not take effect


---

## Version 2.20.0 <a id="2.20.0"></a>

**Release Date: 2022-06-13**

**New Features**

1. Support for setting stream-level audio and video automatic content moderation

    Note: To use this feature, please contact ZEGO Technical Support to enable the backend service.

    When calling the [StartPublishingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2) interface to start publishing stream, developers can set the [ZegoStreamCensorshipMode](@-ZegoStreamCensorshipMode) parameter for stream-level audio and video automatic content moderation, including moderation types such as pornography and politics, thereby reducing developer integration difficulty and business maintenance costs.

    For related APIs, please refer to [StartPublishingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2)

**Improvements and Optimizations**

1. Optimized stream mixing precise alignment interface call logic

    Call the [StartPublishingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2) interface and set the [forceSynchronousNetworkTime](@forceSynchronousNetworkTime-ZegoPublisherConfig) value in [ZegoPublisherConfig](@-ZegoPublisherConfig) to 1. The SDK will wait for the [OnNetworkTimeSynchronized](@OnNetworkTimeSynchronized) callback notification that NTP network time synchronization is complete before publishing stream, then call the [SetStreamAlignmentProperty](@SetStreamAlignmentProperty) interface to enable stream mixing precise alignment feature.

    For related APIs, please refer to [StartPublishingStream](https://doc-zh.zego.im/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2), [SetStreamAlignmentProperty](@SetStreamAlignmentProperty), [OnNetworkTimeSynchronized](@OnNetworkTimeSynchronized)

**Bug Fixes**

1. Fixed interface errors on some 32-bit Android phones

    Related interfaces: [LoadResourceFromMediaData](@LoadResourceFromMediaData-ZegoMediaPlayer), [LoadResourceWithPosition](@LoadResourceWithPosition-ZegoMediaPlayer), [LoadCopyrightedMusicResourceWithPosition](@LoadCopyrightedMusicResourceWithPosition-ZegoMediaPlayer)


---


## Version 2.19.0 <a id="2.19.0"></a>

**Release Date: 2022-05-18**

**New Features**

1. Support for returning login room and logout room results

    [loginRoom] interface adds "callback" parameter, supporting returning login room results from "callback".

    [logoutRoom] interface adds "callback" parameter, supporting returning logout room results from "callback".

    For related APIs, please refer to [LoginRoom](@LoginRoom), [LogoutRoom](@LogoutRoom)

2. Added room state change notification [onRoomStateChanged]

    [onRoomStateChanged] callback is triggered when the room's connection state changes, providing more detailed connection states and state change reasons through the "ZegoRoomStateChangedReason" parameter.

    For related APIs, please refer to [OnRoomStateChanged](@OnRoomStateChanged)


3. Added enable voice activity detection feature and voice sound level callback

    When monitoring sound level callbacks, developers often only care about the human voice part. They can call the [StartSoundLevelMonitor](@StartSoundLevelMonitor) interface and pass in "ZegoSoundLevelConfig" to enable VAD human voice detection.

    The SDK also adds parameters for whether human voice detection is included in the local capture sound level callback [OnCapturedSoundLevelInfoUpdate](@OnCapturedSoundLevelInfoUpdate) and remote audio sound level callback [OnRemoteSoundLevelInfoUpdate](@OnRemoteSoundLevelInfoUpdate).

    For related APIs, please refer to [StartSoundLevelMonitor](@StartSoundLevelMonitor), [OnCapturedSoundLevelInfoUpdate](@OnCapturedSoundLevelInfoUpdate), [OnRemoteSoundLevelInfoUpdate](@OnRemoteSoundLevelInfoUpdate)

4. Support for getting local and remote uplink and downlink network quality

    Added local and remote user uplink and downlink network quality callbacks [OnNetworkQuality](@OnNetworkQuality), defaulting to once every two seconds for local and each remote user's network status (including unknown, excellent, good, fair, poor, network disconnected). When developers want to analyze network conditions on the link or understand local and remote user network status, they can use this feature.

    For related APIs, please refer to [OnNetworkQuality](@OnNetworkQuality)


5. Support for setting trigger factors for traffic control

    When traffic control is enabled for a specified publish stream channel through the [EnableTrafficControl](@EnableTrafficControl) interface, you can use the [SetTrafficControlFocusOn](@SetTrafficControlFocusOn) interface to control whether to start traffic control due to poor remote network conditions.

    For related APIs, please refer to [SetTrafficControlFocusOn](@SetTrafficControlFocusOn)

6. Streams directly published to CDN support playing through L3

    When directly publishing to CDN, without changing the publishing method, the SDK pulls streams from the customer's CDN origin and distributes audio and video content to the audience through L3, controlling origin resources through [ZegoResourceType](@-ZegoResourceType). This feature is commonly used in live streaming scenarios.

    For related APIs, please refer to [StartPlayingStream](@StartPlayingStream)

**Bug Fixes**

1. Fixed issue with playing stream failure from CDN



---


## Version 2.18.0 <a id="2.18.0"></a>

**Release Date: 2022-04-19**

**New Features**

1. Added media player feature

    Media player component provides the ability to play audio and video media files and supports pushing the audio and video data of played media files.

    For related APIs, please refer to [CreateMediaPlayer](@CreateMediaPlayer), [DestroyMediaPlayer](@DestroyMediaPlayer)


2. Added automatic stream mixing feature

    The SDK can specify a room, and the ZEGO real-time audio and video server automatically mixes all audio streams in the room (currently only supports mixing audio streams), commonly used in pure audio chat scenarios.

    You can call the [StartAutoMixerTask|\_blank](@StartAutoMixerTask) interface to enable automatic stream mixing, and call the [StopAutoMixerTask|\_blank](@StopAutoMixerTask) interface to disable automatic stream mixing.

    For related APIs, please refer to [StartAutoMixerTask|\_blank](@StartAutoMixerTask), [StopAutoMixerTask|\_blank](@StopAutoMixerTask)

3. Support for getting synchronized network time information

    Call the [GetNetworkTimeInfo|\_blank](@GetNetworkTimeInfo) interface to get the current network time (NTP), including the current network time timestamp and maximum error. When synchronizing multi-device behavior, you need to get synchronized network time to calibrate the current time.

    For related APIs, please refer to [GetNetworkTimeInfo|\_blank](@GetNetworkTimeInfo)

4. Support for stream mixing precise alignment feature

    Call the [SetStreamAlignmentProperty|\_blank](@SetStreamAlignmentProperty) interface to enable or disable stream mixing precise alignment feature, commonly used in KTV and other scenarios that require stream mixing alignment.

    For related APIs, please refer to [SetStreamAlignmentProperty|\_blank](@SetStreamAlignmentProperty)

**Bug Fixes**

1. Fixed issue with abnormal log file collection during log reporting

2. Fixed echo cancellation issues on some Android phones


---

## Version 2.17.1 <a id="2.17.1"></a>

**Release Date: 2022-03-30**
**Bug Fixes**

1. Fixed issue where iOS platform SDK library packaging format was incompatible with Plugins, causing XCode project export errors

    Changed iOS platform SDK library format to Plugins-compatible framework format.


---

## Version 2.17.0 <a id="2.17.0"></a>

**Release Date: 2022-03-18**

**Improvements and Optimizations**

1. Optimized authentication method

    For version 2.17.0 and above, pass AppSign as null or do not pass it when creating the engine, and must pass Token when logging in to the room. After authentication passes, you can use real-time audio and video features. For details, please refer to [Using Token Authentication](/real-time-video-u3d-cs/communication/using-token-authentication).

    For versions before 2.17.0, pass AppSign when creating the engine. After authentication passes, you can use real-time audio and video features.

    For related APIs, please refer to [CreateEngine](@CreateEngine), [LoginRoom](@LoginRoom)

**Bug Fixes**

1. Fixed crash issue caused by switching rooms in game voice

    Fixed crash issue when calling [SwitchRoom](@SwitchRoom) interface after enabling game voice.


---

## Version 2.16.0 <a id="2.16.0"></a>

**Release Date: 2022-02-25**

**New Features**

1. Added login room and user in-room publishing stream authentication features

    User permission control refers to the ZEGO server determining whether users have corresponding permissions based on the Token parameter carried when users log in to the room or perform publish/play stream operations in the room, avoiding risk issues caused by missing or improper permission control. Currently only supports verification of two permissions: user login room and user in-room publishing stream.

    For related APIs, please refer to [LoginRoom](@LoginRoom), [RenewToken](@RenewToken), [onRoomTokenWillExpire](@onRoomTokenWillExpire)

2. Support for setting playing stream video type

    When the publishing side sets "codecID" to "SVC" through [SetVideoConfig] (can be set before or after playing stream), the playing side can dynamically choose to use different stream types (small resolution is half of the standard layer). In situations of poor network or smaller rendered UI windows, you can choose to use small resolution video to save bandwidth.

    For related APIs, please refer to [SetPlayStreamVideoType](@SetPlayStreamVideoType)

3. Added reverb advanced parameters and reverb/voice changer presets

    Through reverb advanced parameters, you can adjust more fine-tuned reverb effects as needed, and added effects such as recording studio, KTV, rock, and concert to the original preset reverb, and added magnetic male and fresh female voice effects to preset voice changers, increasing real-time voice interest and adapting to more scenarios.

    For related APIs, please refer to [SetVoiceChangerParam](@SetVoiceChangerParam), [SetReverbPreset](@SetReverbPreset), [SetVoiceChangerPreset](@SetVoiceChangerPreset), [SetVoiceChangerParam](@SetVoiceChangerParam)

4. Support for setting reverb echo parameters

    Users can set reverb echo parameters as needed, allowing up to 7 echoes (delay), and support for individually setting each echo's delay and attenuation, as well as overall input and output gain values. Can also be combined with voice changer and reverb to achieve various custom sound effects.

    For related APIs, please refer to [SetReverbEchoParam](@SetReverbEchoParam)

5. Added spatial audio capability

    Spatial audio can perceive sound positions in 360° within a space. Developers can use spatial audio features to create more realistic "seat" effects in audio and video rooms. Users can perceive the source direction of sound through spatial audio, restoring offline scenarios. Suitable for audio chat rooms, murder mystery games, and online meeting scenarios.

    For related APIs, please refer to [EnablePlayStreamVirtualStereo](@EnablePlayStreamVirtualStereo)

6. Support for all-around virtual stereo

    Added support for all-around virtual stereo, processing mono sound through algorithms to simulate stereo sound. This feature is commonly used in KTV scenarios, making singing sounds more three-dimensional.

    When calling the [EnableVirtualStereo] interface and setting the angle parameter to -1, it indicates stereo effect is all-around stereo.

    For related APIs, please refer to [EnableVirtualStereo](@EnableVirtualStereo)

7. Set playing stream priority weight

    When developers need to prioritize quality for a certain stream, they can use the [SetPlayStreamFocusOn] interface. For example: in a classroom scenario, students play multiple streams, and teacher stream can be set to high priority.

    For related APIs, please refer to [SetPlayStreamFocusOn](@SetPlayStreamFocusOn)

8. Support for getting current audio route

    Audio route refers to the audio output device used when the App plays audio. Common audio routes include: speaker, receiver (earpiece), headphones, Bluetooth devices, etc. Developers can call the [GetAudioRouteType] interface to get the current audio route.

    For related APIs, please refer to [GetAudioRouteType](@GetAudioRouteType)

9. Audio effect player adds support for setting voice changer effects

    By changing the user's pitch, the output sound is perceived differently from the original sound, achieving effects such as male to female voice.

    For related APIs, please refer to [SetVoiceChangerParam](@SetVoiceChangerParam)

10. Support for callback of remote speaker device state

    After successful co-hosting with a remote user, when the remote speaker device state changes, such as enabling/disabling speaker, it can be monitored through the [OnRemoteSpeakerStateUpdate] callback.

    For related APIs, please refer to [OnRemoteSpeakerStateUpdate](@OnRemoteSpeakerStateUpdate)

11. Added audio device route change notification callback [OnLocalDeviceExceptionOccurred]

    This callback is thrown when audio routes change, such as headphone plug/unplug, speaker and receiver switching.

    For related APIs, please refer to [OnAudioRouteChange](@OnAudioRouteChange)

12. Added local device exception callback [OnLocalDeviceExceptionOccurred]

    Through the [OnLocalDeviceExceptionOccurred] callback, you can set device types to detect, such as cameras, speakers, microphones, etc. Developers can handle accordingly based on error callbacks for different device types.

    For related APIs, please refer to [OnLocalDeviceExceptionOccurred](@OnLocalDeviceExceptionOccurred)

13. Support for setting audio route to speaker

    Through [SetAudioRouteToSpeaker], you can set the audio route to speaker. When choosing not to use the built-in speaker to play sound (set to "false"), the SDK will select the currently highest-priority audio output device based on system scheduling to play sound.

    For related APIs, please refer to [SetAudioRouteToSpeaker](@SetAudioRouteToSpeaker)

14. Support for setting playing stream cache interval range

    This feature is used to specify the adaptive adjustment range for playing cache. Developers can set it according to scenarios.

    For related APIs, please refer to [SetPlayStreamBufferIntervalRange](@SetPlayStreamBufferIntervalRange)

15. Playing stream side provides feature to disable all audio or video

    When you need to disable all remote user audio or video streams at once during playing stream, you can use this feature.

    For related APIs, please refer to [MuteAllPlayStreamAudio](@MuteAllPlayStreamAudio), MuteAllPlayStreamVideo

16. Added feature to take screenshots of publishing or playing stream images

    Support for taking screenshots of images during publish/play stream, usable for content moderation scenarios.

    For related APIs, please refer to TakePublishStreamSnapshot, [OnPublisherTakeSnapshotResult](@OnPublisherTakeSnapshotResult), TakePlayStreamSnapshot, [OnPlayerTakeSnapshotResult](@OnPlayerTakeSnapshotResult)

17. Added local preview first frame rendering callback

    Callback [OnPublisherRenderVideoFirstFrame] is received after the first frame of video data is rendered.

    For related APIs, please refer to OnPublisherRenderVideoFirstFrame

18. Support for setting all playing stream sound volume

    Local users can control the playback volume of all audio streams through the [SetAllPlayStreamVolume] interface.

    For related APIs, please refer to [SetAllPlayStreamVolume](@SetAllPlayStreamVolume)

19. Support for getting detailed information about ZEGO SDK method execution results through [OnApiCalledResult] delegate function

    For related APIs, please refer to [OnApiCalledResult](@OnApiCalledResult)


**Deprecations and Deletions**

1. Deprecated old version basic beauty related interfaces

    The old beauty feature was relatively simple and did not meet developers' expectations. Therefore, in version 2.16.0 and above, [EnableBeautify] and [SetBeautifyOption] interfaces are deprecated.

    For related APIs, please refer to EnableBeautify, SetBeautifyOption

2. Deprecated [SetBuiltInSpeakerOn] interface

    Due to naming convention issues, in version 2.16.0 and above, [SetBuiltInSpeakerOn] interface is deprecated. Please use [SetAudioRouteToSpeaker] to implement the original functionality.

    For related APIs, please refer to [SetAudioRouteToSpeaker](@SetAudioRouteToSpeaker)

3. Deprecated [OnDeviceError] callback

    To help developers intuitively understand the device type with exceptions and specific exception situations, in version 2.16.0 and above, [OnDeviceError] callback is deprecated. Please use [OnLocalDeviceExceptionOccurred] callback instead.

    For related APIs, please refer to OnDeviceError,[OnLocalDeviceExceptionOccurred](@OnLocalDeviceExceptionOccurred)





---



## Version 2.15.3 <a id="2.15.3"></a>

**Release Date: 2022-02-18**

**New Features**

1. Game voice supports setting secret team mode

    [ZegoRangeAudioMode] enum adds secret team SecretTeam. Local users can, as needed, after initializing game voice [CreateRangeAudio], set secret team mode through the [SetRangeAudioMode] interface. In this team mode, team members can receive voice from users in world mode.

    For related APIs, please refer to[CreateRangeAudio](@CreateRangeAudio), [SetRangeAudioMode](@SetRangeAudioMode)



---


## Version 2.15.2 <a id="2.15.2"></a>

**Release Date: 2022-01-05**

**New Features**

1. Added experimental API

    Added [CallExperimentalAPI] interface, through which ZEGO provides some technical previews or special customized features in RTC business. To obtain feature usage or details, please consult ZEGO Technical Support.
    Added [onRecvExperimentalAPI] callback delegate for receiving experimental API JSON content.

    For related APIs, please refer to [CallExperimentalAPI](@CallExperimentalAPI), [onRecvExperimentalAPI](@onRecvExperimentalAPI)

---
## Version 2.15.1 <a id="2.15.1"></a>

**Release Date: 2021-12-24**

**New Features**

1. Game voice supports setting whether to receive specified user's audio data


    The game voice module adds [MuteUser] interface. Local users can, as needed, after initializing game voice [CreateRangeAudio], set whether to receive audio data from specified remote users through the [MuteUser] interface. When not receiving, hardware and network overhead can be reduced.

    This feature can be used when developers need to quickly disable or restore remote audio.

    For related APIs, please refer to [MuteUser](@MuteUser)

**Bug Fixes**

1. Fixed issue with engine advanced configuration setting failure

    Fixed issue where "advancedConfig" configuration in [SetEngineConfig] interface did not take effect.


---


## Version 2.15.0 <a id="2.15.0"></a>

**Release Date: 2021-12-17**

**New Features**

1. Support for game voice feature

    Added game voice feature module, providing features such as range voice, 3D audio effects, and team voice. Suitable for battle royale games and metaverse scenarios.

    Range voice: Listeners in the room have range limits on audio reception distance. If the distance between a speaker and themselves exceeds this range, they cannot hear the sound. To ensure voice clarity, when more than 20 people nearby are speaking, you can only hear the sounds of the 20 speakers closest to you.

    3D audio effects: Sound has 3D spatial sense and attenuates with distance.

    Team voice: Players can choose to join a team and support freely switching between "World" mode and "Team only" mode within the room.

    For related APIs, please refer to [CreateRangeAudio](@CreateRangeAudio), [DestroyRangeAudio](@DestroyRangeAudio), [SetAudioReceiveRange](@SetAudioReceiveRange), [UpdateSelfPosition](@UpdateSelfPosition), [UpdateAudioSource](@UpdateAudioSource), [EnableSpatializer](@EnableSpatializer), [EnableMicrophone](@EnableMicrophone), [EnableSpeaker](@EnableSpeaker), [SetRangeAudioMode](@SetRangeAudioMode), [SetTeamID](@SetTeamID)

**Improvements and Optimizations**

1. Support for setting audio configuration for specific channels

    Optimized [SetAudioConfig] interface, adding optional parameter "ZegoPublishChannel" to specify channel number for audio configuration.

    For related APIs, please refer to [SetAudioConfig](@SetAudioConfig)

2. Playing stream quality callback adds audio quality parameter

    [onPlayerQualityUpdate] callback adds mos parameter, indicating current audio quality status.

    For related APIs, please refer to [onPlayerQualityUpdate](@onPlayerQualityUpdate)

**Bug Fixes**

1. Fixed string copy errors in some interfaces



---


## Version 1.2.0 <a id="1.2.0"></a>

**Release Date: 2021-11-29**

**Bug Fixes**

1. Synchronized latest Native layer SDK interface definitions, fixing stream mixing parameter errors



