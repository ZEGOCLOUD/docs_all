



# Overview

---

<Note title="Note">
ZEGOCLOUD AI Agent has been fully upgraded and version 2.0 is now released, ZEGOCLOUD has developed a new generation of real-time interactive AI specifically designed for AI agents:

- The end-to-end AI voice processing capability has been comprehensively upgraded, achieving over 95% accuracy in recognition and interruption handling, especially in scenarios with double-talk or BGM;
- The interactive architecture has been fully optimized to support multi-user and multi-AI interaction scenarios;
- The integration experience and usability have been significantly improved.

For more details, please refer to the [Release Notes](./Release%20Notes.mdx).
</Note>

## What is ZEGOCLOUD AI Agent?

[ZEGOCLOUD AI Agent](https://www.zegocloud.com/solutions/conversational-ai) provides SDK and server APIs to help you **quickly achieve** **ultra-low latency IM text and image chatting**, **voice calls**, **digital human voice calls**, and other interactive features between users and AI agents, thereby fulfilling scenarios such as AI companionship, AI customer service, AI digital human live streaming, etc.

ZEGOCLOUD AI Agent supports custom settings for persona, timbre, appearance, etc., and is compatible with various large language models (LLMs) and text-to-speech services (TTS). It also supports long-term memory, external knowledge bases, and model fine-tuning, thereby delivering a more perfect AI agent.

## Why Choose ZEGOCLOUD AI Agent?

### Multi-modal Interactive Agent
- **Customizable Character**: You can define the personality and character of AI agents through prompts best practices, combined with RAG, LoRA, etc., to better match roles and meet exclusive needs.
- **Rich Timbres & Voice Cloning**: Over a hundred hyper-realistic timbres suitable for various scenarios such as emotional companionship, customer service, e-commerce, etc., with voice cloning capabilities.
- **Multi-modal Interaction**: Instant text messages, real-time voice calls, video calls, etc.
- **Extended Premium Photo Digital Human**: In as quickly as 200 ms, a single photo is all it takes to generate a real-time interactive AI avatar—complete with precise lip synchronization and lifelike facial rendering.

### Real-time Voice Call Capability
- **Response Delay Reduced to 1 Second Worldwide**. ZEGOCLOUD AI Agent adopts fully stream-based processing, leverages our global MSDN (Real-time Sequential Data Network), and achieves an as quick as 1s end-to-end response delay anywhere in the world.
- **Natural Voice Interruption in 500 ms**. ZEGOCLOUD AI Agent rapidly and accurately detects human speech, seamlessly halts its responses within 500 ms upon interruption, and ensures no cross talk even under successive interrupts.
- **Accurate Speaking-State Detection**. While maintaining low response latency, ZEGOCLOUD AI Agent prevents sentence fragments from being split, resulting in more precise AI replies.

### AI Audio Processing Capabilities for Agents
- **AI Noise Reduction (AI ANS)**. Eliminates environmental noise, music, distant environmental human voices, etc., supporting interactions in various environments such as offices, homes, cars, etc.
- **AI Voice Activity Detection (AI VAD)**. Accurately identifies effective human voices, filtering out soft responses like "um", "oh", as well as coughs and other noises resembling human sounds.
- **AI Echo Cancellation (AI AEC)**. Precisely eliminates AI voices and background music re-captured by microphones, preventing AI speech from interrupting itself, improving the accuracy of voice when interrupting AI. Also combines functions such as volume ducking and playback volume self-adaptation.

### Customized Integration
- **Easy Integration**: With fewer than 10 lines of code, you can embed the AI agent into instant messaging, real-time voice calls, or digital-human conversations in your app.
- **Flexible Selection of LLM and TTS Plugins**: ZEGOCLOUD AI Agent supports multiple vendors both domestic and international, such as ModelArk (Douyin), MiniMax, Volcengine, Alibaba Cloud, Stepfun, etc., and also supports open-source models.
- **Highly Available, Cost-Efficient Services**: By optimizing ASR, LLM, and TTS calls for concurrency and usage, ZEGOCLOUD minimizes end-to-end latency and reduces overall operational costs.

## What Can ZEGOCLOUD AI Agent Do?

<table>
<tbody><tr>
<th>Module</th>
<th>Function</th>
<th>Description</th>
</tr>
<tr>
<td rowspan="6">Voice Calls with AI Agents</td>
<td>[Create, Modify, Delete, Query AI Agents](/aiagent-server/quick-start)</td>
<td>Create an AI agent, including adjusting the basic information description of the AI agent virtual user, including persona (system prompt), timbre, etc., as well as parameters of LLM and TTS used by the agent.</td>
</tr>
<tr>
<td>[Initiate AI Agent Voice Call](./../Quick%20start.mdx)</td>
<td>Through creating an AI agent, achieve real-time voice calls with AI with a minimum delay of 1s.</td>
</tr>
<tr>
<td>Multi-user Interaction with AI Agent (Beta)</td>
<td>Achieve multi-user interaction with a single AI agent by creating group AI agent instances. <Note title="Note">Feature in beta testing, please contact ZEGOCLOUD business for details.</Note></td>
</tr>
<tr>
<td>AI Audio Processing Capability for AI Interaction</td>
<td>Automatically filters out user-side noise generated during conversations and removes far-field human voices, achieving more precise voice interruption effects and more accurate ASR speech recognition.</td>
</tr>
<tr>
<td>Natural Voice Interruption</td>
<td>During real-time voice calls, the AI agent intelligently identifies the user's intention to interrupt the conversation and stops its output.</td>
</tr>
<tr>
<td>Real-time Broadcast</td>
<td>The dialogue information between the AI agent and the user will be converted into text in real-time and displayed by the client.</td>
</tr>
<tr>
<td rowspan="10">Basic Capabilities</td>
<td>[Large Language Model (LLM) Management](/aiagent-server/guides/configuring-llm)</td>
<td>Adjust the large language model (LLM) applied by the AI agent. <ul><li>Commercial LLMs: OpenAI, MiniMax, Qwen, Volcano Ark, Stepfun, ERNIE.</li><li>Open-source LLMs compatible with [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat).</li></ul></td>
</tr>
<tr>
<td>Text-to-Speech (TTS) Management</td>
<td>Support for various TTS providers and related capabilities: <ul><li>Supported service providers: Volcengine (one-way & two-way streaming), Alibaba Cloud (CosyVoice), MiniMax;</li><li>Various models, public timbres, voice cloning from vendors, and support for speed and tone adjustments.</li></ul></td>
</tr>
<tr>
<td>Add/Delete/Modify AI Agent Instances</td>
<td>Create or delete an AI Agent instance to initiate voice or digital human interaction with the agent.</td>
</tr>
<tr>
<td>[Get AI Agent Status](/aiagent-server/guides/get-ai-agent-status)</td>
<td>Receive corresponding server callbacks to get the AI agent's start speaking and end speaking status; also can query AI agent status API to get states including idle, listening, thinking, speaking, etc.</td>
</tr>
<tr>
<td>[Memory (Context) Source](/aiagent-server/advanced/ai-short-term-memory#设置初始记忆)</td>
<td>The AI agent's memory (context) can be provided through external input or by binding historical records from In-app Chat (ZIM).</td>
</tr>
<tr>
<td>[Memory (Context) Update](/aiagent-server/advanced/ai-short-term-memory#重置智能体实例上下文列表)</td>
<td>During the lifecycle of this AI agent instance, record the content of each conversation and use it as subsequent context messages for the agent's memory. Memory can be cleared to restart the conversation.</td>
</tr>
<tr>
<td>[Memory (Context) Archiving](/aiagent-server/advanced/ai-short-term-memory#语音通话结束后归档记忆)</td>
<td>Convert the dialogue between users and AI agents into text information and store it</td>
</tr>
<tr>
<td>[Speech Recognition Hot Words](/aiagent-server/guides/configuring-asr-hot-word)</td>
<td>For specialized vocabulary such as role names, temporary hot words can be set to improve speech recognition accuracy.</td>
</tr>
<tr>
<td>[Proactive LLM Invocation](/aiagent-server/guides/proactive-invocation-of-llm-and-tts)</td>
<td>Simulate user questions by customizing messages sent to LLM, and after LLM responds, send voice to users via TTS. Can be used to implement context-based welcome messages and other scenarios.</td>
</tr>
<tr>
<td>[Proactive TTS Invocation](/aiagent-server/guides/proactive-invocation-of-llm-and-tts)</td>
<td>TTS can be invoked at any time to achieve AI's proactive broadcasting, thus satisfying scenarios such as AI welcome messages or user reminders. Also supports configuring whether to add to history records and context</td>
</tr>
<tr>
<td rowspan="3">Advanced Capabilities</td>
<td>[AI Agent Interruption Mode Control](/aiagent-server/guides/interrupt-agent-speech)</td>
<td>The form of interruption when the agent is speaking can include multiple options, and multiple selections are possible: <ul><li>Natural voice interruption: When the agent receives voice input, i.e., when the user speaks, it interrupts the agent's speech.</li><li>Manual interruption: Control interruption through server-side APIs to enable users to interrupt via buttons or business-side management.</li></ul></td>
</tr>
<tr>
<td>Filter LLM Output and TTS Input</td>
<td>Filtering based on certain rules, such as Chinese and English brackets, emoji expressions, etc., for more controllable AI behavior.</td>
</tr>
<tr>
<td>[Speech Recognition Segmentation Optimization](/aiagent-server/advanced/speech-segmentation-control)</td>
<td>Support for voice detection segmentation threshold settings and pause duration settings to achieve balance between delay and voice segmentation.</td>
</tr>
<tr>
<td rowspan="5">Best Practices</td>
<td>[Role-playing Prompt Optimization](/aiagent-server/best-practices/role-playing-system-prompt)</td>
<td>When using AI agents for role-playing, learn how to write system prompts to better showcase the effect.</td>
</tr>
<tr>
<td>Better Output with RAG</td>
<td>Support for AI external knowledge base to achieve more basic scripts, company information, and other content.</td>
</tr>
<tr>
<td>Memory Module</td>
<td>For longer time spans and where AI needs to remember more basic user information (e.g., age, place of birth, preferences), conduct regular summaries and conclusions to achieve smarter AI interactions.</td>
</tr>
<tr>
<td>LoRA, SFT Model Fine-tuning</td>
<td>When there are very high demands for the AI character, fine-tuning of the LLM can be performed. For example, in scenarios where a cloned host replaces a real person.</td>
</tr>
<tr>
<td>[AI Voice Chat with Cloned Voice](/aiagent-server/best-practices/clone-voice)</td>
<td>Apply the cloned voice in the voice call process to achieve communication with an AI agent of a specific voice.</td>
</tr>
</tbody></table>