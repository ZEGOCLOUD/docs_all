openapi: 3.0.0
info:
  title: AI Agent API - ÂÖ±‰∫´ÁªÑ‰ª∂
  version: 1.0.0

servers:
  - url: https://aigc-aiagent-api.zegotech.cn
    description: Unified access address (no regional distinction)
  - url: https://aigc-aiagent-api-sha.zegotech.cn
    description: Mainland China (Shanghai)
  - url: https://aigc-aiagent-api-hkg.zegotech.cn
    description: Hong Kong, Macao, and Taiwan (Hong Kong)
  - url: https://aigc-aiagent-api-fra.zegotech.cn
    description: Europe (Frankfurt)
  - url: https://aigc-aiagent-api-lax.zegotech.cn
    description: Western United States (California)
  - url: https://aigc-aiagent-api-bom.zegotech.cn
    description: Asia-Pacific (Mumbai)
  - url: https://aigc-aiagent-api-sgp.zegotech.cn
    description: Southeast Asia (Singapore)

components:
  # ÂÖ±‰∫´ÁöÑÂèÇÊï∞ÂÆö‰πâ
  parameters:
    # Re-export ZEGO global shared parameters for convenient local reference
    AppId:
      $ref: "../../../../../snippets/common/en/openapi/zego-shared-components.yaml#/components/parameters/AppId"
    SignatureNonce:
      name: SignatureNonce
      in: query
      description: üí°Public parameter. A 16-character hexadecimal random string (hex encoding of 8-byte random number). Refer to [Signature sample code](/aiagent-server/api-reference/accessing-server-apis#signature-sample-code) for how to generate.
      required: true
      schema:
        type: string

    Timestamp:
      name: Timestamp
      in: query
      description: üí°Public parameter. Current Unix timestamp, in seconds. Refer to [Signature sample code](/aiagent-server/api-reference/accessing-server-apis#signature-sample-code) for how to generate, with a maximum error of 10 minutes.
      required: true
      schema:
        type: integer
        format: int64
    SignatureVersion:
      $ref: "../../../../../snippets/common/en/openapi/zego-shared-components.yaml#/components/parameters/SignatureVersion"
    Signature:
      name: Signature
      in: query
      description: üí°Public parameter. Signature, used to verify the legitimacy of the request. Refer to [Signing the requests](/aiagent-server/api-reference/accessing-server-apis#signature-mechanism) for how to generate an API request signature.
      required: true
      schema:
        type: string

  schemas:
    RTC:
      type: object
      description: |
        <div>
          <p>RTC related information</p>
          <br/>
          <strong>üìå Important Note</strong>
          <p>All attribute character restrictions: only numbers, English characters, '_', '-', and '.' are supported.</p>
        </div>

      required:
        - RoomId
        - AgentStreamId
        - AgentUserId
        - UserStreamId
      properties:
        RoomId:
          type: string
          description: RTC room ID.
          maxLength: 128
          example: "room_1"
        AgentStreamId:
          type: string
          description: |
            The stream ID used by the AI agent instance for streaming.
            > **üìå Important Note**
            >
            > Ensure that multiple AI agent instances (even if they are not in the same RTC room) use different stream IDs, otherwise the streaming of the later created AI agent instance will fail.
          maxLength: 128
          example: "agent_stream_1"
        AgentUserId:
          type: string
          description: |
            The user ID of the AI agent instance.
            > **üìå Important Note**
            >
            > Ensure that multiple AI agent instances (even if they are not in the same RTC room) use different user IDs, otherwise the earlier created AI agent instance will be kicked out of the RTC room.
          maxLength: 32
          example: "agent_user_1"
        UserStreamId:
          type: string
          description: The stream ID used by the real user for streaming.
          maxLength: 128
          example: "user_stream_1"

    LLM:
      type: object
      required:
        - Url
        - Model
      properties:
        Vendor:
          type: string
          description: |
            The vendor type of the LLM interface.
            - OpenAIChat: OpenAI's Chat Completions interface type.
            - OpenAIResponses: OpenAI's Responses API interface type.
          default: OpenAIChat
          example: "OpenAIChat"
          enum:
            - OpenAIChat
            - OpenAIResponses
        Url:
          type: string
          description: |
            The endpoint that receives the request (can be your own service or any LLM service provider's service).
            If Vendor is OpenAIChat, it must be compatible with [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat).
            For example: `https://api.openai.com/v1/chat/completions`


            If Vendor is OpenAIResponses, it must be compatible with [OpenAI Responses API](https://platform.openai.com/docs/api-reference/responses).
            For example: `https://ark.cn-beijing.volces.com/api/v3/responses`

            > **üìå Important Note**
            >
            > If ApiKey is set to "zego_test", you must use one of the following Url addresses:
            > - MiniMaxÔºöhttps://api.minimax.chat/v1/text/chatcompletion_v2
            > - Volcano Engine (Doubao): https://ark.cn-beijing.volces.com/api/v3/chat/completions
            > - Aliyun Bailei (Tongyi Qianwen): https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
            > - Stepfun: https://api.stepfun.com/v1/chat/completions

          example: "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        ApiKey:
          type: string
          description: |
            The parameter used for authentication by the LLM service provider. It is empty by default, but must be provided in production environments.

            > **üìå Important Note**
            >
            > During the test period (within 2 weeks after the AI Agent service is enabled), you can set this parameter value to "zego_test" to use this service.
          example: "zego_test"
        Model:
          type: string
          description: |
            The LLM model. Different LLM service providers support different models, please refer to their official documentation to select the appropriate model.

            > **üìå Important Note**
            >
            > If ApiKey is set to "zego_test", you must use one of the following models:
            > - MiniMax:
            >   - *MiniMax-Text-01*
            > - Volcano Engine (Doubao):
            >   - *doubao-1-5-pro-32k-250115*
            >   - *doubao-1-5-lite-32k-250115*
            > - Aliyun Bailei (Tongyi Qianwen):
            >   - *qwen-plus*
            > - Stepfun:
            >   - *step-2-16k*
          example: "doubao-1-5-lite-32k-250115"
        SystemPrompt:
          type: string
          description: The system prompt of the AI agent. It is the predefined information that is added at the beginning when calling the LLM, used to control the output of the LLM. It can be role settings, prompts, and answer examples.
          example: "You are a friendly assistant"
        Temperature:
          type: number
          description: The higher the value, the more random the output; the lower the value, the more concentrated and determined the output.
          minimum: 0
          maximum: 2
          default: 0.7
          example: 0.7
        TopP:
          type: number
          description: The sampling method. The smaller the value, the stronger the determinism; the larger the value, the stronger the randomness.
          minimum: 0
          maximum: 1
          default: 0.9
          example: 0.9
        Params:
          type: object
          description: Other parameters supported by the LLM service provider, such as the maximum token limit. Different LLM providers support different parameters, please refer to their official documentation and fill in as needed.
          example: {"max_tokens": 16384}
        AddAgentInfo:
          type: boolean
          description: |
            If this value is true, the AI Agent server will include the AI agent information(agent_info) in the request parameters when requesting the LLM service. The example of the AI agent information is as follows: [Using Custom LLM](/aiagent-server/guides/configuring-llm#use-custom-llm).
            You can use this parameter to execute additional business logic in your custom LLM service.

            The structure of agent_info is as follows:
            - room_id: RTC room ID
            - user_id: User ID
            - agent_instance_id: AI agent instance ID

            **üìå Important Note: Only effective when Vendor is "OpenAIChat".**
          default: false
          example: false
        AgentExtraInfo:
          type: object
          description: |
            Agent extra information, the server will pass this parameter in the request parameters when requesting the LLM service. The example of the extra information is as follows: [Using Custom LLM](/aiagent-server/guides/configuring-llm#use-custom-llm).
            You can use this parameter to execute additional business logic in your custom LLM service.

            **üìå Important Note: Only effective when Vendor is "OpenAIChat".**
          properties:
            key:
              type: string
              description: Extra information key.
            value:
              description: Extra information value, can be of any type.
          example: {
            "user_custom_key1": "value1",
            "user_custom_key2": "value2"
          }

    TTS:
      type: object
      required:
        - Vendor
        - Params
      properties:
        Vendor:
          type: string
          description: The TTS service provider. Please refer to [Configuring TTS > TTS Parameters](/aiagent-server/guides/configuring-tts#tts-params) for details.
          enum: ["Aliyun", "ByteDance","ByteDanceV3", "ByteDanceFlowing", "MiniMax", "CosyVoice"]
          example: "ByteDance"
        Params:
          type: object
          description: TTS configuration parameters, in JSON object format. Contains app parameters (for authentication) and other parameters (for adjusting TTS effects). Please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.

          required:
            - app
          properties:
            app:
              type: object
              description: Used for TTS service authentication, the structure of the app parameter required by different Vendor values is different, please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.
            other_params:
              type: string
              description: |

                > **üìå Important Note**
                >
                > other_params is not a valid parameter, it is only to explain how to pass the vendor parameters.
                > Except for the app parameter, other parameters are directly passed to the vendor parameters. Please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.
          example: {
            "app": {
              "appid": "zego_test",
              "token": "zego_test",
              "cluster": "volcano_tts"
            },
            "audio": {
              "voice_type": "zh_female_qingxinnvsheng_mars_bigtts",
              "loudness_ratio": 1.0,
              "speed_ratio": 1.0
            }
          }
        FilterText:
          type: array
          description: |
            Filters out the text enclosed by specified punctuation marks from the input content to TTS (usually the content returned by LLM or the Text parameter of the SendAgentInstanceTTS API), and then performs speech synthesis. For example, in ‚Äú(happily said) Welcome to ZEGOCLOUD!‚Äù, the content within the parentheses is filtered out before synthesis.

            <Note title="Note">
              - Typically, you guide the LLM via prompts in LLM > SystemPrompt to specify which parts of the content should be enclosed within particular punctuation.<br/>
              - This parameter cannot be updated when updating an agent instance.
            </Note>
          items:
            type: object
            required:
              - BeginCharacters
              - EndCharacters
            properties:
              BeginCharacters:
                type: string
                description: The start punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to (.
                example: "("
              EndCharacters:
                type: string
                description: The end punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to ).
                example: ")"
          example: [
            {
              "BeginCharacters": "(",
              "EndCharacters": ")"
            }
          ]
        TerminatorText:
          type: string
          maxLength: 4
          example: "#-#"
          description: |
            Can be used to set the termination text for TTS. If the input to TTS (usually the content returned by LLM or the Text parameter of the SendAgentInstanceTTS API) contains the TerminatorText string, then the content from the TerminatorText string (inclusive) onward will no longer be synthesized in this TTS round.
            > **üìå Important Note**
            >
            > - For bidirectional streaming, only one character can be set.
            >
            > - Typically, the LLM is guided via prompts in LLM > SystemPrompt to specify which parts of the content should be enclosed with special punctuation.
            > - This parameter cannot be updated when updating an agent instance.
            >
        CharacterFilter:
          type: array
          description: |
            The specified strings in the content input to TTS (usually the content returned by LLM or the Text parameter of the SendAgentInstanceTTS API) will not be involved in speech synthesis. Each string in the array indicates a string to be filtered out, and each string can have up to 2 characters.
          items:
            type: string
          example: ["#", "##", "-"]

    ASR:
      type: object
      properties:
        Vendor:
          type: string
          description: ASR provider. Please refer to [Configuring ASR > ASR Parameters](/aiagent-server/guides/configuring-asr#asr-params) for details.
          enum: [Tencent, AliyunParaformer, AliyunGummy, Microsoft]
          default: Tencent
          example: "Tencent"
        Params:
          type: object
          description: Vendor parameters, please refer to [Configuring ASR > Params Parameters](/aiagent-server/guides/configuring-asr#params) for details.
          example: {"engine_model_type": "16k_en", "hotword_list": "zego|10"}
        VADSilenceSegmentation:
          type: number
          description: |
            Set the number of seconds after which two sentences are no longer considered as one.
            Unit is ms, range [200, 2000], default is 500.
            Please refer to [Speech Segmentation Control](/aiagent-server/advanced/speech-segmentation-control) for details.

            > **üìå Important Note**
            >
            > When Vendor is "Tencent" (default), the maximum value is 1500.
          minimum: 200
          maximum: 2000
          default: 500
          example: 500
        PauseInterval:
          type: number
          description: |
            Set the number of seconds within which two sentences are considered as one, i.e., ASR multi-sentence concatenation.
            Unit is ms, range [200, 2000].
            Only when this value is greater than VADSilenceSegmentation, ASR multi-sentence concatenation will be enabled.
            Please refer to [Speech Segmentation Control](/aiagent-server/advanced/speech-segmentation-control) for details.
          minimum: 200
          maximum: 2000
          example: 800
        VADSensitiveLevel:
          type: number
          format: int
          description: |
            VAD sensitivity, 0: medium sensitivity, default value; 1: low sensitivity; 2: high sensitivity; 3: custom mode, needs to be used in combination with VADMinSpeechDur and VADEnergyThreshold. Please refer to [Voice Interruption Sensitivity Adjustment](/aiagent-server/advanced/voice-interruption-sensitivity-adjustment) for details.
          default: 0
          enum: [0, 1, 2, 3]
          example: 0
        VADMinSpeechDur:
          type: number
          format: int
          description: |
            VAD minimum speech duration, unit ms, the larger the value, the less likely it is to be detected, but it may cause some short speech to be missed, the value range is [0, 1000].
          minimum: 0
          maximum: 1000
          example: 100
        VADEnergyThreshold:
          type: number
          format: float
          description: |
            VAD energy threshold, the smaller the value, the higher the sensitivity, the value range is [0, 1].
          minimum: 0
          maximum: 1
          example: 0
        HotWord:
          type: string
          deprecated: true
          description: This parameter has been deprecated. Please set it through the Params vendor parameters.

    MessageHistory:
      type: object
      description: Configuration of the history messages used by the AI agent instance
      properties:
        SyncMode:
          type: integer
          description: |
            Message synchronization mode:
            - 0: Synchronize from the In-app Chat (ZIM)
            - 1: Synchronize through the Messages parameter
          enum: [0, 1]
          default: 0
          example: 0
        Messages:
          type: array
          description: Message list
          maxItems: 100
          items:
            $ref: "#/components/schemas/Message"
        WindowSize:
          type: integer
          format: Int
          description: The number of recent history messages used when calling the LLM service. It affects the LLM context understanding ability, and it is recommended to set it to 10-30.
          minimum: 0
          maximum: 500
          default: 20
          example: 20
        ZIM:
          $ref: "#/components/schemas/ZIM"

    Message:
      type: object
      required:
        - Role
        - Content
      properties:
        Role:
          type: string
          description: |
            The role of the message sender:
            - user: User
            - assistant: AI agent
          enum: [user, assistant]
          example: "user"
        Content:
          type: string
          description: Message content
          example: "Hello, I want to know about the product information"

    ZIM:
      type: object
      description: |
        ZIM-related information.
        <div>
        <br/>
        <strong>üìå Important Note</strong>
        <p>- Only effective when MessageHistory.SyncMode is 0.</p>
        <p>- Please ensure that your project has enabled the ZIM service.</p>
        <p>- Please ensure that you have called the ZIM robot registration interface, and set the returned UserInfo.UserId as the RobotId.</p>
        <p>- It is recommended to register the robot in advance to improve the user information settings and enhance the efficiency of creating AI agent instances.</p>
        </div>
      properties:
        RobotId:
          type: string
          description: ZIM robot ID. That is, the UserInfo.UserId returned by calling the ZIM [register robot](/zim-server/bot/register-bots#request-parameters) interface. It is used to load the chat context between the user and the ZIM robot, and synchronize the messages generated during the conversation to ZIM. If this parameter is empty, the real-time interactive AI Agent backend will randomly generate one.
          example: "@RBT#robot_123"
        LoadMessageCount:
          type: integer
          description: The number of messages to be fetched from the ZIM service as context when creating an AI agent instance. The default is the value of WindowSize (the upper limit).
          minimum: 0
          maximum: 500
          example: 20

    CallbackConfig:
      type: object
      description: |
        Server-side callback configuration

        <div>
        <br/>
        <strong>üìå Important Note</strong>
        <p>Before configuring the following parameters, you need to set the callback address according to [Receiving Callback](/aiagent-server/callbacks/receiving-callback), and understand the specific field descriptions.</p>
        </div>

      properties:
        ASRResult:
          type: integer
          description: Whether to enable server-side callback for ASR results.
          enum: [0, 1]
          default: 0
        LLMResult:
          type: integer
          description: Whether to enable server-side callback for LLM results. If enabled, the ZEGOCLOUD server will return the LLM output result for each sentence.
          enum: [0, 1]
          default: 0
        Interrupted:
          type: integer
          description: Whether to enable server-side callback for the AI agent being interrupted.
          enum: [0, 1]
          default: 0
        UserSpeakAction:
          type: integer
          description: Whether to enable server-side callback for user speech.
          enum: [0, 1]
          default: 0
        AgentInstanceStatus:
          type: integer
          description: Whether to enable server-side callback for the AI agent instance status.
          enum: [0, 1]
          default: 0
        UserAudioData:
          type: integer
          description: Whether to enable server-side callback for user speech audio data.
          enum: [0, 1]
          default: 0

    AdvancedConfig:
      type: object
      properties:
        InterruptMode:
          type: integer
          description: |
            The mode of interrupting the AI agent when the user speaks:
            - 0: Interrupt immediately. If the user speaks while the AI is speaking, the AI will be immediately interrupted and stop speaking.
            - 1: Do not interrupt. If the user speaks while the AI is speaking, the AI will not be affected until the content is finished.
          enum: [0, 1]
          default: 0
          example: 0
        MaxIdleTime:
          type: integer
          description: The automatic destruction time of the AI agent instance. If the user (UserId) of the conversation exceeds the MaxIdleTime and is not in the room, the AI agent instance will be automatically deleted by the background and the 1202 exception callback event will be triggered. MaxIdleTime defaults to 120s, with a value range of [10, 1800].
          minimum: 10
          maximum: 1800
          default: 120
          example: 120
        DisableTTS:
          type: boolean
          description: |
            Whether to disable the TTS function. If set to true, the AI agent instance will not perform speech synthesis.
            > **üìå Important Note**
            >
            > When DisableTTS is true, the [Create Digital Human Agent Instance](/aiagent-server/api-reference/agent-instance-management/create-digital-human-agent-instance) and [Trigger TTS](/aiagent-server/api-reference/agent-instance-control/send-agent-instance-tts) interfaces will report errors.
          default: false
          example: false
        LLMMetaInfo:
          type: object
          description: |
            Used to control extracting metadata from the LLM output text as additional control parameters. The metadata should be a JSON object, usually controlled by the `LLM.SystemPrompt` parameter to guide the LLM to output content in a specified format. The exact JSON object format of the metadata will vary depending on feature requirements.
            For usage examples and more details, see [Controlling Voice Emotions of the Agent](/aiagent-server/advanced/controlling-tts-effects).
          properties:
            BeginCharacters:
              type: string
              description: The starting symbol for marking metadata in the text. The content between this symbol and the EndCharacters is treated as metadata. Cannot be empty or only whitespace. Avoid using common characters and sentence delimiters.
              example: "[["
            EndCharacters:
              type: string
              description: The ending symbol for marking metadata in the text. The content between BeginCharacters and this symbol is treated as metadata. Cannot be empty or only whitespace. Avoid using common characters and sentence delimiters.
              example: "]]"
          required: []
          example:
            BeginCharacters: "[["
            EndCharacters: "]]"

    DigitalHuman:
      type: object
      properties:
        DigitalHumanId:
          type: string
          description: Digital human ID
          example: "xiaozhi"
        ConfigId:
          type: string
          description: Digital human configuration ID
          enum: [mobile, web]
          example: "mobile"
        EncodeCode:
          type: string
          description: Digital human video encoding format
          enum: [H264]
          default: "H264"
          example: "H264"

    ErrorResponse:
      type: object
      properties:
        Code:
          type: integer
          description: Error code
          example: 400
        Message:
          type: string
          description: Error message
          example: "Invalid request parameters"
        RequestId:
          type: string
          description: Request ID
          example: "3151527792559699733"