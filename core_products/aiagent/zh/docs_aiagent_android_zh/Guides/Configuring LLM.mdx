# 配置大语言模型

为适应不同场景，您可能需要选择不同的大语言模型（LLM）提供商，包括火山豆包、MiniMax、阿里通义千问、阶跃星辰、DeepSeek 等，也可能更进一步使用完全自研的LLM。本文说明常见大语言模型厂商如何配置及相关注意事项。

## 使用第三方 LLM

<Note title="说明">
请先联系 ZEGO 技术支持开通第三方 LLM 服务，获取接入 Url 和 API Key。

第三方 LLM 需要兼容 OpenAI 协议。
</Note>

您可以在注册Agent智能体（[RegisterAgent](/aiagent-server/agent-configuration-management/register-agent)）或创建Agent实例（[CreateAgentInstance](/aiagent-server/agent-instance-management/create-agent-instance)）时设置 LLM 参数。常用参数如下：

| 参数 | 类型 | 是否必填 | 描述 |
| --- | --- | --- | --- |
| Url | String | 是 | LLM 回调地址，要求与 OpenAI 协议兼容。 |
| ApiKey | String | 否 | LLM 校验 api key。默认为空，生产环境中务必启用 api key。 |
| Model | String | 是 | 调用的模型。不同的 LLM 供应商支持的配置不同，请参考对应文档填入。 |
| SystemPrompt | String | 否 | 系统提示词。可以是角色设定、提示词和回答样例等。 |
| Temperature | Float | 否 | 较高的值将使输出更加随机，而较低的值将使输出更加集中和确定。 |
| TopP | Float | 否 | 采样方法，数值越小结果确定性越强；数值越大，结果越随机。 |
| Params | Object | 否 | 其他 LLM 参数，例如使用的最大 Token 数限制等。不同的 LLM 供应商支持的配置不同，请参考对应文档按需填入。<Note title="说明">参数名与各厂商 LLM 的参数名保持一致。</Note> |

以下是常见 LLM 厂商的配置示例：

<Tabs>
<Tab title="火山方舟">
[火山方舟大模型服务平台](https://www.volcengine.com/docs/82379/1298454)模型使用说明文档。
```json
"LLM": {
    "Url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "ep-xxxxxxxxxx",    // 您在火山方舟大模型平台创建的推理接入点
    "SystemPrompt": "你是小智，成年女性，是**即构科技创造的陪伴助手**，上知天文下知地理，聪明睿智、热情友善。\n对话要求：1、按照人设要求与用户对话。\n2、不能超过100字。",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 1024
    }
}
```
</Tab>
<Tab title="阿里云百炼">
[通义千问 API 的输入输出参数](https://bailian.console.aliyun.com/?tab=api#/api/?type=model&url=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2712576.html)模型使用说明文档。
```json
"LLM": {
    "Url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "qwen-plus",
    "SystemPrompt": "你是小智，成年女性，是**即构科技创造的陪伴助手**，上知天文下知地理，聪明睿智、热情友善。\n对话要求：1、按照人设要求与用户对话。\n2、不能超过100字。",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 1024
    }
}
```
</Tab>
<Tab title="Minimax">
[Minimax](https://platform.minimaxi.com/document/ChatCompletion%20v2?key=66701d281d57f38758d581d0#QklxsNSbaf6kM4j6wjO5eEek)模型使用说明文档。
```json
"LLM": {
    "Url": "https://api.minimax.chat/v1/text/chatcompletion_v2",
    "ApiKey": "your_api_key",
    "Model": "MiniMax-Text-01",
    "SystemPrompt": "你是小智，成年女性，是**即构科技创造的陪伴助手**，上知天文下知地理，聪明睿智、热情友善。\n对话要求：1、按照人设要求与用户对话。\n2、不能超过100字。",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 1024
    }
}
```
</Tab>
</Tabs>

## 使用自定义 LLM

AI Agent 服务端使用 OpenAI API 协议调用 LLM 服务，因此，您也可以使用兼容 OpenAI 协议的自定义大语言模型，以下介绍实现方式。

<Steps>
<Step title="创建符合 OpenAI API 协议的服务">
提供一个兼容 [platform.openai.com](https://platform.openai.com/docs/api-reference/chat) 的接口。关键点如下：

- 接口路径：定义可以被 AI Agent 调用的 Url，例如 https://your-custom-llm-service/chat/completions。
- 请求格式：接受兼容 OpenAI 协议的请求参数。
- 响应格式：返回与 OpenAI 协议兼容、且符合 SSE 规范的流式响应数据。
</Step>
<Step title="配置自定义 LLM">
在注册 Agent 智能体（[RegisterAgent](/aiagent-server/agent-configuration-management/register-agent)）或创建 Agent 实例（[CreateAgentInstance](/aiagent-server/agent-instance-management/create-agent-instance)）时，设置自定义 LLM 的配置。

```json
"LLM": {
    "Url": "https://your-custom-llm-service/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "your_model",
    "SystemPrompt": "你是小智，成年女性，是**即构科技创造的陪伴助手**，上知天文下知地理，聪明睿智、热情友善。\n对话要求：1、按照人设要求与用户对话。\n2、不能超过100字。",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 1024
    }
}

```
</Step>
</Steps>

