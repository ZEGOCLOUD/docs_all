import LLMValidator from '../LLMValidator.jsx';

# é…ç½®å¤§è¯­è¨€æ¨¡å‹

ä¸ºé€‚åº”ä¸åŒåœºæ™¯ï¼Œæ‚¨å¯èƒ½éœ€è¦é€‰æ‹©ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å•†ï¼ŒåŒ…æ‹¬ç«å±±è±†åŒ…ã€MiniMaxã€é˜¿é‡Œé€šä¹‰åƒé—®ã€é˜¶è·ƒæ˜Ÿè¾°ã€DeepSeek ç­‰ï¼Œä¹Ÿå¯èƒ½æ›´è¿›ä¸€æ­¥ä½¿ç”¨å®Œå…¨è‡ªç ”çš„LLMã€‚æœ¬æ–‡è¯´æ˜å¸¸è§å¤§è¯­è¨€æ¨¡å‹å‚å•†å¦‚ä½•é…ç½®åŠç›¸å…³æ³¨æ„äº‹é¡¹ã€‚


## LLM å‚æ•°è¯´æ˜

ä½¿ç”¨ç¬¬ä¸‰æ–¹ LLM æœåŠ¡æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰çš„ LLM æœåŠ¡æ—¶ï¼Œéœ€è¦é…ç½® LLM å‚æ•°ã€‚

| å‚æ•°         | ç±»å‹   | æ˜¯å¦å¿…å¡« | æè¿°                                                                                                                                                                     |
| ------------ | ------ | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Vendor       | String | å¦       | LLM æ¥å£çš„ä¾›åº”å•†ç±»åˆ«ã€‚<ul><li>OpenAIChatï¼šOpenAI çš„ Chat Completions æ¥å£ç±»å‹ï¼ˆé»˜è®¤å€¼ï¼‰ã€‚</li><li>OpenAIResponsesï¼šOpenAI çš„ Responses API æ¥å£ç±»å‹ã€‚</li></ul>                                                                                                                                                       |
| Url          | String | æ˜¯       | LLM å›è°ƒåœ°å€ï¼Œå¿…é¡»ä¸ OpenAI åè®®å…¼å®¹ã€‚<ul><li>å¦‚æœ Vendor ä¸º "OpenAIChat" ï¼Œåˆ™å¿…é¡»å…¼å®¹ [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat)ã€‚</li><li>å¦‚æœ Vendor ä¸º "OpenAIResponses" ï¼Œåˆ™å¿…é¡»å…¼å®¹ [OpenAI Responses API](https://platform.openai.com/docs/api-reference/responses)ã€‚</li></ul>                                                                                                                                   |
| ApiKey       | String | å¦       | è®¿é—® LLM æä¾›çš„å„ç±»æ¨¡å‹åŠç›¸å…³æœåŠ¡çš„èº«ä»½éªŒè¯å‡­è¯ã€‚                                                                                                                        |
| Model        | String | æ˜¯       | è°ƒç”¨çš„æ¨¡å‹ã€‚ä¸åŒçš„ LLM æœåŠ¡æä¾›å•†æ”¯æŒçš„é…ç½®ä¸åŒï¼Œè¯·å‚è€ƒå¯¹åº”æ–‡æ¡£å¡«å…¥ã€‚                                                                                                    |
| SystemPrompt | String | å¦       | ç³»ç»Ÿæç¤ºè¯ã€‚å¯ä»¥æ˜¯è§’è‰²è®¾å®šã€æç¤ºè¯å’Œå›ç­”æ ·ä¾‹ç­‰ã€‚                                                                                                                         |
| Temperature  | Float  | å¦       | è¾ƒé«˜çš„å€¼å°†ä½¿è¾“å‡ºæ›´åŠ éšæœºï¼Œè€Œè¾ƒä½çš„å€¼å°†ä½¿è¾“å‡ºæ›´åŠ é›†ä¸­å’Œç¡®å®šã€‚                                                                                                             |
| TopP         | Float  | å¦       | é‡‡æ ·æ–¹æ³•ï¼Œæ•°å€¼è¶Šå°ç»“æœç¡®å®šæ€§è¶Šå¼ºï¼›æ•°å€¼è¶Šå¤§ï¼Œç»“æœè¶Šéšæœºã€‚                                                                                                                 |
| Params       | Object | å¦       | å…¶ä»– LLM å‚æ•°ï¼Œä¾‹å¦‚ä½¿ç”¨çš„æœ€å¤§ Token æ•°é™åˆ¶ç­‰ã€‚ä¸åŒçš„ LLM ä¾›åº”å•†æ”¯æŒçš„é…ç½®ä¸åŒï¼Œè¯·å‚è€ƒå¯¹åº”æ–‡æ¡£æŒ‰éœ€å¡«å…¥ã€‚<Note title="è¯´æ˜">å‚æ•°åä¸å„å‚å•† LLM çš„å‚æ•°åä¿æŒä¸€è‡´ã€‚</Note>   |
| AddAgentInfo | Bool   | å¦       | å¦‚æœè¯¥å€¼ä¸º true ï¼Œåœ¨ AI Agent åå°å‘è‡ªå®šä¹‰ LLM æœåŠ¡å‘èµ·è¯·æ±‚æ—¶ï¼Œè¯·æ±‚å‚æ•°ä¸­ä¼šåŒ…å«æ™ºèƒ½ä½“ä¿¡æ¯ `agent_info`ã€‚è¯¥å€¼é»˜è®¤ä¸º falseã€‚åœ¨ä½¿ç”¨è‡ªå®šä¹‰ LLM æ—¶å¯æ ¹æ®æ­¤å‚æ•°å†…å®¹åšé¢å¤–çš„ä¸šåŠ¡é€»è¾‘ã€‚<Note title="è¯´æ˜">ä»…åœ¨ Vendor ä¸º "OpenAIChat" æ—¶æœ‰æ•ˆã€‚</Note> |
| AgentExtraInfo | Object   | å¦       | Agent æ‰©å±•ä¿¡æ¯ï¼ŒæœåŠ¡å™¨åœ¨è¯·æ±‚ LLM æœåŠ¡æ—¶ä¼šåœ¨è¯·æ±‚å‚æ•°ä¸­é€ä¼ è¯¥å‚æ•°ã€‚é€ä¼ å‚æ•°ç¤ºä¾‹è¯·å‚è€ƒ[ä½¿ç”¨è‡ªå®šä¹‰ LLM](#use-custom-llm)ã€‚æ‚¨å¯ä»¥ä½¿ç”¨æ­¤å‚æ•°åœ¨è‡ªå®šä¹‰ LLM æœåŠ¡ä¸­æ‰§è¡Œé¢å¤–çš„ä¸šåŠ¡é€»è¾‘ã€‚<Note title="è¯´æ˜">ä»…åœ¨ Vendor ä¸º "OpenAIChat" æ—¶æœ‰æ•ˆã€‚</Note> |


## ä½¿ç”¨ç¬¬ä¸‰æ–¹ LLM

<Note title="è¯´æ˜">
ç¬¬ä¸‰æ–¹ LLM éœ€è¦å…¼å®¹ OpenAI åè®®ã€‚
</Note>
<Warning title="æ³¨æ„">
ä¸åŒå‚å•†ä¸åŒæ¨¡å‹çš„ max_tokens å‚æ•°æœ€å¤§å€¼ä¸åŒï¼Œè¯·æ ¹æ®å®é™…éœ€æ±‚è®¾ç½®åˆç†çš„å€¼ã€‚å¦‚æœä¸äº†è§£è¯¥å‚æ•°å«ä¹‰ï¼Œå¯ä»¥ä¸è®¾ç½®è¯¥å‚æ•°ï¼Œè¿™ä¼šä½¿ç”¨é»˜è®¤å€¼ã€‚
- å¦‚æœ max_tokens è¶…è¿‡æ¨¡å‹é™åˆ¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¯·æ±‚å¤±è´¥ã€‚
- å¦‚æœ max_tokens è®¾ç½®è¿‡å°ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¾“å‡ºä¸å®Œæ•´ï¼Œç­”æ¡ˆè¢«æˆªæ–­ã€‚
</Warning>

æ‚¨å¯ä»¥åœ¨æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆ[RegisterAgent](./../api-reference/agent-configuration-management/register-agent.mdx)ï¼‰æˆ–åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹ï¼ˆ[CreateAgentInstance](./../api-reference/agent-instance-management/create-agent-instance.mdx)ï¼‰æ—¶è®¾ç½® LLM å‚æ•°ã€‚

ä»¥ä¸‹æ˜¯å¸¸è§ LLM å‚å•†çš„é…ç½®ç¤ºä¾‹ï¼š

<Tabs>
<Tab title="ç«å±±æ–¹èˆŸ">

ç«å±±æ–¹èˆŸå¤§æ¨¡å‹æ”¯æŒ OpenAI Chat Completions API åè®®ï¼Œ éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ Doubao-Seed ç³»åˆ—ï¼‰æ”¯æŒ OpenAI Responses API åè®®ã€‚è¯·æŒ‰å®é™…éœ€æ±‚é…ç½®ï¼š

[Chat Completions API](https://www.volcengine.com/docs/82379/1298454)æ¨¡å‹ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚
```json
// !mark(2)
"LLM": {
    "Url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
    "ApiKey": "zego_test", // your api key (zego_test åœ¨æ¥å…¥æµ‹è¯•æœŸé—´(AI Agent æœåŠ¡å¼€é€š 2 å‘¨å†…)å¯ä½¿ç”¨ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å¿«é€Ÿå¼€å§‹è¯´æ˜)
    "Model": "doubao-1-5-pro-32k-250115",    // æ‚¨åœ¨ç«å±±æ–¹èˆŸå¤§æ¨¡å‹å¹³å°åˆ›å»ºçš„æ¨ç†æ¥å…¥ç‚¹
    "SystemPrompt": "ä½ æ˜¯å°æ™ºï¼Œæˆå¹´å¥³æ€§ï¼Œæ˜¯**å³æ„ç§‘æŠ€åˆ›é€ çš„é™ªä¼´åŠ©æ‰‹**ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œèªæ˜ç¿æ™ºã€çƒ­æƒ…å‹å–„ã€‚\nå¯¹è¯è¦æ±‚ï¼š1ã€æŒ‰ç…§äººè®¾è¦æ±‚ä¸ç”¨æˆ·å¯¹è¯ã€‚\n2ã€ä¸èƒ½è¶…è¿‡100å­—ã€‚",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 4096
    }
}
```
[Responses API](https://www.volcengine.com/docs/82379/1585128?lang=zh)æ¨¡å‹ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚
```json
// !mark(2:3)
"LLM": {
    "Vendor": "OpenAIResponses",
    "Url": "https://ark.cn-beijing.volces.com/api/v3/responses",
    "ApiKey": "zego_test", // your api key (zego_test åœ¨æ¥å…¥æµ‹è¯•æœŸé—´(AI Agent æœåŠ¡å¼€é€š 2 å‘¨å†…)å¯ä½¿ç”¨ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å¿«é€Ÿå¼€å§‹è¯´æ˜)
    "Model": "doubao-seed-1-6-flash-250828",    // æ‚¨åœ¨ç«å±±æ–¹èˆŸå¤§æ¨¡å‹å¹³å°åˆ›å»ºçš„æ¨ç†æ¥å…¥ç‚¹
    "SystemPrompt": "ä½ æ˜¯å°æ™ºï¼Œæˆå¹´å¥³æ€§ï¼Œæ˜¯**å³æ„ç§‘æŠ€åˆ›é€ çš„é™ªä¼´åŠ©æ‰‹**ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œèªæ˜ç¿æ™ºã€çƒ­æƒ…å‹å–„ã€‚\nå¯¹è¯è¦æ±‚ï¼š1ã€æŒ‰ç…§äººè®¾è¦æ±‚ä¸ç”¨æˆ·å¯¹è¯ã€‚\n2ã€ä¸èƒ½è¶…è¿‡100å­—ã€‚",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
    }
}
```
</Tab>
<Tab title="é˜¿é‡Œäº‘ç™¾ç‚¼">

ä»…æ”¯æŒ OpenAI Chat Completions API åè®®ã€‚è¯·æŒ‰å®é™…éœ€æ±‚é…ç½®ï¼š

[é€šä¹‰åƒé—® API çš„è¾“å…¥è¾“å‡ºå‚æ•°](https://bailian.console.aliyun.com/?tab=api#/api/?type=model&url=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2712576.html)æ¨¡å‹ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚
```json
"LLM": {
    "Url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
    "ApiKey": "zego_test", // your api key (zego_test åœ¨æ¥å…¥æµ‹è¯•æœŸé—´(AI Agent æœåŠ¡å¼€é€š 2 å‘¨å†…)å¯ä½¿ç”¨ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å¿«é€Ÿå¼€å§‹è¯´æ˜)
    "Model": "qwen-plus",
    "SystemPrompt": "ä½ æ˜¯å°æ™ºï¼Œæˆå¹´å¥³æ€§ï¼Œæ˜¯**å³æ„ç§‘æŠ€åˆ›é€ çš„é™ªä¼´åŠ©æ‰‹**ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œèªæ˜ç¿æ™ºã€çƒ­æƒ…å‹å–„ã€‚\nå¯¹è¯è¦æ±‚ï¼š1ã€æŒ‰ç…§äººè®¾è¦æ±‚ä¸ç”¨æˆ·å¯¹è¯ã€‚\n2ã€ä¸èƒ½è¶…è¿‡100å­—ã€‚",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 4096
    }
}
```
</Tab>
<Tab title="MiniMax">

ä»…æ”¯æŒ OpenAI Chat Completions API åè®®ã€‚è¯·æŒ‰å®é™…éœ€æ±‚é…ç½®ï¼š

[MiniMax](https://platform.minimaxi.com/document/ChatCompletion%20v2?key=66701d281d57f38758d581d0#QklxsNSbaf6kM4j6wjO5eEek)æ¨¡å‹ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚
```json
"LLM": {
    "Url": "https://api.minimax.chat/v1/text/chatcompletion_v2",
    "ApiKey": "zego_test", // your api key (zego_test åœ¨æ¥å…¥æµ‹è¯•æœŸé—´(AI Agent æœåŠ¡å¼€é€š 2 å‘¨å†…)å¯ä½¿ç”¨ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å¿«é€Ÿå¼€å§‹è¯´æ˜)
    "Model": "MiniMax-Text-01",
    "SystemPrompt": "ä½ æ˜¯å°æ™ºï¼Œæˆå¹´å¥³æ€§ï¼Œæ˜¯**å³æ„ç§‘æŠ€åˆ›é€ çš„é™ªä¼´åŠ©æ‰‹**ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œèªæ˜ç¿æ™ºã€çƒ­æƒ…å‹å–„ã€‚\nå¯¹è¯è¦æ±‚ï¼š1ã€æŒ‰ç…§äººè®¾è¦æ±‚ä¸ç”¨æˆ·å¯¹è¯ã€‚\n2ã€ä¸èƒ½è¶…è¿‡100å­—ã€‚",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 4096
    }
}
```
</Tab>
</Tabs>

## ä½¿ç”¨è‡ªå®šä¹‰ LLM <a id="use-custom-llm" />

AI Agent åå°ä½¿ç”¨ OpenAI API åè®®è°ƒç”¨ LLM æœåŠ¡ã€‚å› æ­¤ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ä»»ä½•å…¼å®¹ OpenAI åè®®çš„è‡ªå®šä¹‰ LLMã€‚è¿™é‡Œçš„è‡ªå®šä¹‰ LLM ç”šè‡³å¯ä»¥åœ¨åº•å±‚å®ç°çš„æ—¶å€™è°ƒç”¨å¤šä¸ªå­ LLM æ¨¡å‹æˆ–è€…è¿›è¡Œ RAG æœç´¢ã€è”ç½‘æœç´¢åå†è¿›è¡Œæ•´åˆè¾“å‡ºã€‚

<Steps titleSite="h3">
<Step title="å®ç°è‡ªå®šä¹‰LLM" titleSize="h3">

åˆ›å»ºç¬¦åˆ OpenAI Chat Completions API åè®®çš„æ¥å£ã€‚

<Tabs>
<Tab title="æ¥å£å…³é”®ç‚¹è¯´æ˜">
æä¾›ä¸€ä¸ªå…¼å®¹ [platform.openai.com](https://platform.openai.com/docs/api-reference/chat) çš„ `chat/completions` æ¥å£ã€‚å…³é”®ç‚¹å¦‚ä¸‹ï¼š

- æ¥å£è·¯å¾„ï¼šå¯ä»¥è¢« AI Agent è°ƒç”¨çš„ Urlï¼Œä¾‹å¦‚ `https://your-custom-llm-service/chat/completions`ã€‚
- è¯·æ±‚æ ¼å¼ï¼šæ¥å—å…¼å®¹ OpenAI åè®®çš„è¯·æ±‚å¤´å’Œè¯·æ±‚ä½“ã€‚
- å“åº”æ ¼å¼ï¼šè¿”å›ä¸ OpenAI åè®®å…¼å®¹ã€ä¸”ç¬¦åˆ SSE è§„èŒƒçš„æµå¼å“åº”æ•°æ®ã€‚


<Accordion title="AI Agent åå°å‘ chat/completions æ¥å£å‘èµ·è¯·æ±‚çš„è¯·æ±‚ä½“ç¤ºä¾‹" defaultOpen="false">
```json
{
    "model": "your model name", // å¯¹åº” LLM.Model å‚æ•°
    "temperature": 1, // å¯¹åº” LLM.Temperature å‚æ•°
    "top_p": 0.7, // å¯¹åº” LLM.TopP å‚æ•°
    "max_tokens": 4096, // å¯¹åº” LLM.Params.max_tokens å‚æ•°
    "messages":[
        {
            "role": "system",
            "content": "è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„çŸ¥è¯†åº“å†…å®¹ç”¨å‹å¥½çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸åœ¨çŸ¥è¯†åº“ä¸­ï¼Œè¯·ç¤¼è²Œçš„å‘Šè¯‰ç”¨æˆ·æˆ‘ä»¬æ²¡æœ‰ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ã€‚" // å¯¹åº” LLM.SystemPrompt å‚æ•°
        },
        ... // å…¶ä»–æ¶ˆæ¯
    ],
    ... // å…¶ä»–å‚æ•°
    // å¦‚æœ LLM.AddAgentInfo å‚æ•°ä¸º trueï¼Œåˆ™ä¼šåŒ…å« agent_info ä¿¡æ¯
    "agent_info": {
        "room_id": "æ‰€åœ¨roomid",
        "agent_instance_id" : "æ™ºèƒ½ä½“å®ä¾‹ id",
        "agent_user_id" : "æ™ºèƒ½ä½“çš„user id",
        "user_id": "ç”¨æˆ·çš„user id",
        "round_id": 1, //è½®æ¬¡id
        "time_stamp": 193243200 //æ¯«ç§’çº§åˆ«æ—¶é—´æˆ³
    },
    // å¦‚æœ LLM.AgentExtraInfo å‚æ•°æœ‰é…ç½®å€¼ï¼Œåˆ™ä¼šåŒ…å« agent_extra_info ä¿¡æ¯
    "agent_extra_info":{
        "user_custom_key1" : "value1",
        "user_custom_key2" : "value2",
    }
}
```
</Accordion>

<Accordion title="Chat Completion æµå¼å“åº”å¯¹è±¡å—ç¤ºä¾‹" defaultOpen="false">
```json
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"æ‚¨"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":1,"total_tokens":84}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"å¥½"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":2,"total_tokens":85}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"ï¼"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":3,"total_tokens":86}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"å³"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":4,"total_tokens":87}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"æ„"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":5,"total_tokens":88}}
...
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"æ›´å¤šçš„"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":147,"total_tokens":230}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"ä»·å€¼"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":148,"total_tokens":231}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":"ã€‚"},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":149,"total_tokens":232}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":""},"finish_reason":""}],"usage":{"prompt_tokens":83,"completion_tokens":150,"total_tokens":233}}
data: {"id":"d7ae7c4a-1524-4fe5-9d58-e4d59b89d8f0","object":"chat.completion.chunk","created":1709899323,"model":"step-1-8k","choices":[{"index":0,"delta":{"role":"","content":""},"finish_reason":"stop"}],"usage":{"prompt_tokens":83,"completion_tokens":150,"total_tokens":233}}
data: [DONE]
```
</Accordion>
<Warning title="æ³¨æ„">
è‡ªå®šä¹‰ LLM æµå¼æ•°æ®æ ¼å¼æ³¨æ„äº‹é¡¹å¦‚ä¸‹ï¼š
- æ¯æ¡æ•°æ®å¿…é¡»ä»¥ `data: ` å¼€å¤´ï¼ˆæ³¨æ„å†’å·åæœ‰ç©ºæ ¼ï¼‰ã€‚
- æ¯æ¡æ•°æ®ä¸ºå•ç‹¬ä¸€è¡Œæˆ–è€…è¡Œå°¾æœ‰æ¢è¡Œç¬¦ã€‚
- æœ€åä¸€ä¸ªæœ‰æ•ˆæ•°æ®å¿…é¡»åŒ…å« `"finish_reason":"stop"`ã€‚
- é™¤æœ€åä¸€ä¸ªæœ‰æ•ˆæ•°æ®å¯åŒ…å« `"finish_reason":"stop"`ï¼Œå…¶ä»–æ•°æ®å¿…é¡»æŠŠ `finish_reason` è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²æˆ–è€…ä¸è®¾ç½® `finish_reason` å­—æ®µï¼Œå¦åˆ™ä¼šå¯¼è‡´æ™ºèƒ½ä½“ä¸è¾“å‡ºå†…å®¹ã€‚
- æœ€åå¿…é¡»å‘é€ä¸€æ¡ç»“æŸæ•°æ®ï¼š`data: [DONE]`ã€‚

å¦‚æœæ ¼å¼ä¸æ­£ç¡®å¯èƒ½ä¼šå¯¼è‡´æ™ºèƒ½ä½“ä¸è¾“å‡ºæˆ–è€…è¾“å‡ºä¸å®Œæ•´ã€‚
</Warning>
</Tab>
<Tab title="æ¥å£å®ç°æµç¨‹åŠç¤ºä¾‹">

<Note title="è¯´æ˜">è¿™é‡Œä»¥å¸¸è§çš„çŸ¥è¯†åº“æŸ¥è¯¢ä¸ºä¾‹è¯´æ¼”ç¤ºå®šä¹‰ LLM çš„å®ç°æµç¨‹ã€‚æ‚¨å¯ä»¥æ ¹æ®å®é™…ä¸šåŠ¡éœ€æ±‚ä¿®æ”¹å®ç°é€»è¾‘ã€‚</Note>

<Steps titleSite="p">
<Step title="è§£æè¯·æ±‚å‚æ•°">
è§£æè¯·æ±‚å‚æ•°å¹¶è·å–å¿…è¦ä¿¡æ¯ã€‚
```js
export async function POST(request: NextRequest) {
    try {
        // !mark
        const requestData: ChatCompletionCreateParams = await request.json();
        console.log("requestData", requestData);
        // æ£€æŸ¥å¿…éœ€å­—æ®µ
        if (!requestData.messages || requestData.messages.length === 0) {
            return NextResponse.json(
                { error: 'Messages are required' },
                { status: 400 }
            );
        }
        // è¯»å–æœ€æ–°ä¸€æ¡ User Messageï¼ˆæœ€æ–°çš„åœ¨æ•°ç»„æœ€åï¼‰
        // AIAgent åœ¨å‘ä½ çš„æ¥å£å‘èµ·è¯·æ±‚æ—¶ï¼Œä¼šå¸¦ä¸Š Messages å‚æ•°ã€‚è¿™ä¸ªå‚æ•°ä¹ŸåŒ…æ‹¬ SystemPromptã€‚
        // !mark
        const latestUserMessage = [...requestData.messages].reverse().find(message => message.role === 'user');

        // ... å…¶ä»–ä»£ç 
    } catch (error) {
        // ... å…¶ä»–ä»£ç 
    }
}
```
</Step>
<Step title="æŸ¥è¯¢çŸ¥è¯†åº“">
æ ¹æ®æœ€æ–°ä¸€æ¡ User Message æŸ¥è¯¢çŸ¥è¯†åº“ã€‚
```js
let kbContent = "";
// è°ƒç”¨çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£ï¼Œè·å–çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ
if (process.env.KB_TYPE === "ragflow") {
    console.log("è°ƒç”¨ Ragflow çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
    // !mark
    const ragflowResponse = await retrieveFromRagflow({ question: latestUserMessage?.content as string });
    kbContent = ragflowResponse.kbContent;
} else if (process.env.KB_TYPE === "bailian") {
    console.log("è°ƒç”¨ Bailian çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
    // !mark
    const bailianResponse = await retrieveFromBailian({ query: latestUserMessage?.content as string });
    kbContent = bailianResponse.kbContent;
}
```
<Note title="å°æç¤º">
é€šå¸¸åœ¨æŸ¥è¯¢çŸ¥è¯†åº“ä¹‹å‰ä¼šé…åˆæ„å›¾è¯†åˆ«å’Œé—®é¢˜å¢å¼ºæé«˜å›ç­”è´¨é‡ã€‚
- æ„å›¾è¯†åˆ«ï¼šè¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œå¦‚æœä¸éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“çš„åˆ™ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¦åˆ™ç»§ç»­ã€‚æ¯”å¦‚ï¼šç”¨æˆ·è¯´â€œä½ å¥½â€ã€‚
- é—®é¢˜å¢å¼ºï¼šæ ¹æ®å†å²å¯¹è¯åŠé¢„è®¾æ¡ä»¶ï¼Œå¯¹ç”¨æˆ·æœ€æ–°çš„é—®é¢˜è¿›è¡Œè¡¥å……å¢å¼ºã€‚æ¯”å¦‚ï¼šç”¨æˆ·é—®â€œ2024å¹´å‘¢ï¼Ÿâ€ï¼Œåˆ™å¢å¼ºä¸ºâ€œ2024å¹´å…¬å¸å‡€åˆ©æ¶¦æ˜¯å¤šå°‘ï¼Ÿâ€ã€‚
</Note>
</Step>
<Step title="å°†ç”¨æˆ·æœ€æ–°é—®é¢˜åŠçŸ¥è¯†åº“ç‰‡æ®µåˆå¹¶åè°ƒç”¨ LLM è¿›è¡Œå›ç­”">

<Note title="å°æç¤º">éƒ¨åˆ†å‚å•†çš„æ¨¡å‹æä¾›ä¸Šä¸‹æ–‡ç¡¬ç›˜ç¼“å­˜èƒ½åŠ›ï¼Œæ‰€ä»¥è®¡ç®—ä»·æ ¼æ—¶æœ‰ç¼“å­˜çš„è®¡ä»·ä¼šä¾¿å®œå¾ˆå¤šã€‚ä¿æŒ SystemPrompt ä¸å˜ï¼Œåªæ›¿æ¢ User Message å¯æœ‰æ•ˆæå‡ç¼“å­˜å‘½ä¸­æ¦‚ç‡ä»è€Œé™ä½æˆæœ¬å¹¶ä¸”ç¼©çŸ­æ¨ç†æ—¶é—´ã€‚</Note>
```js
// !mark(1:4)
requestData.messages[requestData.messages.length - 1] = {
    role: 'user',
    content: `${latestUserMessage?.content}\nä»¥ä¸‹æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ:\n${kbContent}`,
};
// è°ƒç”¨ LLM è¿›è¡Œå›ç­”ï¼ˆä½¿ç”¨ OpenAI çš„ SDKï¼‰
// LLM_BASE_URL_REAL æ˜¯çœŸå® LLM æœåŠ¡çš„ URL
const openai = new OpenAI({
    apiKey: apiKey,
    baseURL: process.env.LLM_BASE_URL_REAL
});
// å¤„ç†æµå¼å“åº”
const completion = await openai.chat.completions.create({
    model: model,
    stream: true,
    messages: requestData.messages
});
console.log("completion created successfully");
// åˆ›å»ºæµå¼å“åº”
const stream = new TransformStream();
const writer = stream.writable.getWriter();
const encoder = new TextEncoder();
for await (const chunk of completion) {
    // æ³¨æ„âš ï¸ï¼šAIAgent è¦æ±‚æœ€åä¸€ä¸ªæœ‰æ•ˆæ•°æ®å¿…é¡»åŒ…å« "finish_reason":"stop"ä¸”æœ€åå¿…é¡»å‘é€ä¸€æ¡ç»“æŸæ•°æ®ï¼šdata: [DONE]ï¼Œå¦‚æœä¸å‘é€å¯èƒ½ä¼šå¯¼è‡´æ™ºèƒ½ä½“ä¸å›ç­”æˆ–è€…å›ç­”ä¸å®Œæ•´ã€‚
    // æŸäº›æ¨¡å‹ä¸ä¼šåœ¨æµå¼å“åº”ä¸­è¿”å› finish_reasonï¼Œè¿™ç§æƒ…å†µéœ€è¦è‡ªå·±æ ¹æ®ä¿®æ”¹ä¸€ä¸‹chunkå†…å®¹å†ä¼ å›ç»™ AIAgentã€‚
    const ssePart = `data: ${JSON.stringify(chunk)}\n`;
    // æŒç»­å†™å…¥æµå¼å“åº”æ•°æ®ï¼Œç›´åˆ°æµå¼æ•°æ®ç»“æŸ
    // !mark
    writer.write(encoder.encode(ssePart));
}
// å‘é€ç»“æŸæ ‡è®°
// !mark
writer.write(encoder.encode('data: [DONE]\n\n'));
writer.close();
```
</Step>
</Steps>
<Accordion title="chat/completions æ¥å£çš„å®Œæ•´ç¤ºä¾‹ä»£ç " defaultOpen="false">
```json title="Node.js(Next.js)"
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { retrieveFromRagflow } from '@/lib/rag/ragflow';
import OpenAI from 'openai';
import type { ChatCompletionCreateParams } from 'openai/resources/chat';
import { retrieveFromBailian } from '@/lib/rag/bailian';


export async function POST(request: NextRequest) {
    // è®¤è¯æ£€æŸ¥
    const authHeader = request.headers.get('authorization');
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
        return NextResponse.json(
            { error: 'Unauthorized' },
            { status: 401 }
        );
    }

    try {
        const requestData: ChatCompletionCreateParams = await request.json();
        console.log("requestData", requestData);
        console.log("requestData", JSON.stringify(requestData));

        // è¯»å–APIå¯†é’¥ï¼Œå³åœ¨ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¯·æ±‚æ—¶å¸¦ä¸Šçš„ apiKey çš„å€¼ã€‚AIAgent æœåŠ¡ç«¯ä¹Ÿä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¯·æ±‚ã€‚
        // const openai = new OpenAI({
        //     apiKey: "xxx",
        //     baseURL: "xxx"
        // });
        // æ‚¨åœ¨è¯»å–åˆ° apiKey åï¼Œå¯ä»¥åšå¿…è¦çš„ä¸šåŠ¡æ ¡éªŒã€‚å®ƒä¸ä¸€å®šæ˜¯ LLM çš„ apiKeyï¼Œå› ä¸ºæ˜¯é€ä¼ çš„ï¼Œæ‰€ä»¥ä½ å¯ä»¥ä¼ ä»»æ„å†…å®¹ã€‚
        // !mark
        const apiKey = authHeader.split(' ')[1];

        // æ£€æŸ¥å¿…éœ€å­—æ®µ
        if (!requestData.messages || requestData.messages.length === 0) {
            return NextResponse.json(
                { error: 'Messages are required' },
                { status: 400 }
            );
        }

        // æ£€æŸ¥æ˜¯å¦è¦æ±‚æµå¼å“åº”
        if (requestData.stream) {
            // è¯»å– Model
            // ç”±äºåœ¨æ³¨å†Œ AIAgent æˆ–è€…åˆ›å»º AIAgent å®ä¾‹æ—¶ï¼Œä¼šä¼ å…¥å›ºå®šçš„ Model æ‰€ä»¥ è¿™é‡Œå¯ä»¥ä¼ ä¸€ä¸ªæ™®é€šç»™ LLM çš„ Modelã€‚
            // åŒæ—¶ä½ ä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸ªå€¼ä¼ é€’ä¸€äº›é¢å¤–çš„ä¸šåŠ¡ä¿¡æ¯ã€‚æ¯”å¦‚ è¿™ä¸ª Model å®é™…æ˜¯ä¸šåŠ¡æ ‡å¿—ï¼Œæ ‡è¯†æ˜¯ç›´æ’­/è¯­èŠæˆ¿ç­‰ç­‰ã€‚
            // !mark
            const model = requestData.model;

            // è¯»å– SystemPrompt
            // ç”±äºåœ¨æ³¨å†Œ AIAgent æˆ–è€…åˆ›å»º AIAgent å®ä¾‹æ—¶ï¼Œä¼šä¼ å…¥å›ºå®šçš„ SystemPrompt æ‰€ä»¥ è¿™é‡Œå¯ä»¥ä¼ ä¸€ä¸ªæ™®é€šç»™ LLM çš„ SystemPromptã€‚
            // åŒæ—¶ä½ ä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸ªå€¼ä¼ é€’ä¸€äº›é¢å¤–çš„ä¸šåŠ¡ä¿¡æ¯ã€‚æ¯”å¦‚å¸¦ä¸Šç”¨æˆ·çš„ä¿¡æ¯ã€ç­‰çº§ã€åå¥½ç­‰ç­‰ã€‚ç„¶åä¾æ­¤å†è°ƒç”¨ LLM æ—¶é’ˆå¯¹æ€§çš„ä¿®æ”¹å®é™…ç»™ LLM çš„ SystemPromptã€‚
            // !mark
            const systemMessage = requestData.messages.find(message => message.role === 'system');

            // è¯»å–æœ€æ–°ä¸€æ¡ User Messageï¼ˆæœ€æ–°çš„åœ¨æ•°ç»„æœ€åï¼‰
            // AIAgent åœ¨å‘ä½ çš„æ¥å£å‘èµ·è¯·æ±‚æ—¶ï¼Œä¼šå¸¦ä¸Š Messages å‚æ•°ã€‚è¿™ä¸ªå‚æ•°ä¹ŸåŒ…æ‹¬ SystemPromptã€‚
            // !mark
            const latestUserMessage = [...requestData.messages].reverse().find(message => message.role === 'user');

            // è¯»å–å…¶ä»–ç¬¦åˆ OpenAI åè®®çš„ LLM å‚æ•°ç±»ä¼¼ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚

            // åˆ›å»ºæµå¼å“åº”
            // !mark(1:3)
            const stream = new TransformStream();
            const writer = stream.writable.getWriter();
            const encoder = new TextEncoder();
            try {
                let kbContent = "";
                // è°ƒç”¨çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£ï¼Œè·å–çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ
                // !mark(1:11)
                if (process.env.KB_TYPE === "ragflow") {
                    console.log("è°ƒç”¨ Ragflow çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
                    const ragflowResponse = await retrieveFromRagflow({
                        question: latestUserMessage?.content as string,
                    });
                    kbContent = ragflowResponse.kbContent;
                } else if (process.env.KB_TYPE === "bailian") {
                    console.log("è°ƒç”¨ Bailian çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
                    const bailianResponse = await retrieveFromBailian({ query: latestUserMessage?.content as string });
                    kbContent = bailianResponse.kbContent;
                }

                // å°†ç”¨æˆ·æœ€æ–°ä¸€æ¡ User Message å’ŒçŸ¥è¯†åº“æŸ¥è¯¢ç»“æœè¿›è¡Œåˆå¹¶ï¼Œåœ¨æ›¿æ¢ messages æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œç„¶åè°ƒç”¨ LLM è¿›è¡Œå›ç­”
                // å°æç¤ºğŸ””ï¼šéƒ¨åˆ†å‚å•†çš„æ¨¡å‹æ˜¯æä¾›ä¸Šä¸‹æ–‡ç¡¬ç›˜ç¼“å­˜çš„ï¼Œæ‰€ä»¥è®¡ç®—ä»·æ ¼æ—¶æœ‰ç¼“å­˜çš„è®¡ä»·ä¼šä¾¿å®œå¾ˆå¤šã€‚ä¿æŒ SystemPrompt ä¸å˜ï¼Œåªæ›¿æ¢ User Message å¯æœ‰æ•ˆæå‡ç¼“å­˜å‘½ä¸­æ¦‚ç‡ä»è€Œé™ä½æˆæœ¬å¹¶ä¸”ç¼©çŸ­æ¨ç†æ—¶é—´ã€‚
                // !mark(1:4)
                requestData.messages[requestData.messages.length - 1] = {
                    role: 'user',
                    content: `${latestUserMessage?.content}\nä»¥ä¸‹æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ:\n${kbContent}`,
                };

                // è°ƒç”¨ LLM è¿›è¡Œå›ç­”ï¼ˆä½¿ç”¨ OpenAI çš„ SDKï¼‰
                const openai = new OpenAI({
                    apiKey: apiKey,
                    baseURL: process.env.LLM_BASE_URL_REAL
                });
                // å¤„ç†æµå¼å“åº”
                const completion = await openai.chat.completions.create({
                    model: model,
                    stream: true,
                    messages: requestData.messages
                });
                console.log("completion created successfully");
                for await (const chunk of completion) {
                    // æ³¨æ„âš ï¸ï¼šAIAgent è¦æ±‚æœ€åä¸€ä¸ªæœ‰æ•ˆæ•°æ®å¿…é¡»åŒ…å« "finish_reason":"stop"ä¸”æœ€åå¿…é¡»å‘é€ä¸€æ¡ç»“æŸæ•°æ®ï¼šdata: [DONE]ï¼Œå¦‚æœä¸å‘é€å¯èƒ½ä¼šå¯¼è‡´æ™ºèƒ½ä½“ä¸å›ç­”æˆ–è€…å›ç­”ä¸å®Œæ•´ã€‚
                    // æŸäº›æ¨¡å‹ä¸ä¼šåœ¨æµå¼å“åº”ä¸­è¿”å› finish_reasonï¼Œè¿™ç§æƒ…å†µéœ€è¦è‡ªå·±æ ¹æ®ä¿®æ”¹ä¸€ä¸‹chunkå†…å®¹å†ä¼ å›ç»™ AIAgentã€‚
                    const ssePart = `data: ${JSON.stringify(chunk)}\n`;
                    // æŒç»­å†™å…¥æµå¼å“åº”æ•°æ®ï¼Œç›´åˆ°æµå¼æ•°æ®ç»“æŸ
                    // !mark
                    writer.write(encoder.encode(ssePart));
                }

            } catch (error) {
                console.error('Stream processing error:', error);
            } finally {
                // å‘é€ç»“æŸæ ‡è®°
                // !mark
                writer.write(encoder.encode('data: [DONE]\n\n'));
                writer.close();
                console.log("writer closed");
            }


            return new Response(stream.readable, {
                headers: {
                    'Content-Type': 'text/event-stream',
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'Access-Control-Allow-Origin': '*',
                },
            });
        } else {
            // AIAgent ä¸æ”¯æŒéæµå¼å“åº”ï¼Œç›´æ¥è¿”å›é”™è¯¯ç 
            return NextResponse.json(
                { error: 'Streaming is required' },
                { status: 400 }
            );
        }
    } catch (error) {
        console.error('Error processing request:', error);
        return NextResponse.json(
            { error: 'Internal server error' },
            { status: 500 }
        );
    }
}

// æ·»åŠ OPTIONSæ–¹æ³•æ”¯æŒCORSé¢„æ£€
export async function OPTIONS() {
    return NextResponse.json({}, {
        headers: {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'POST, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type, Authorization',
        },
    });
}
```

</Accordion>
</Tab>

</Tabs>

</Step>
<Step title="ä½¿ç”¨è‡ªå®šä¹‰LLM" titleSize="h3">


åœ¨æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆ[RegisterAgent](./../api-reference/agent-configuration-management/register-agent.mdx)ï¼‰æ—¶ï¼Œè®¾ç½®ä½¿ç”¨è‡ªå®šä¹‰ LLM URLï¼Œå¹¶åœ¨ `SystemPrompt` ä¸­è¦æ±‚ LLM æ ¹æ®çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

```javascript æ³¨å†Œæ™ºèƒ½ä½“è°ƒç”¨ç¤ºä¾‹
// è¯·å°†ä»¥ä¸‹ç¤ºä¾‹ä¸­çš„ LLM å’Œ TTS çš„ ApiKeyã€appidã€token ç­‰é‰´æƒå‚æ•°æ¢æˆä½ å®é™…çš„é‰´æƒå‚æ•°ã€‚
async registerAgent(agentId: string, agentName: string) {
    // è¯·æ±‚æ¥å£ï¼šhttps://aigc-aiagent-api.zegotech.cn?Action=RegisterAgent
    const action = 'RegisterAgent';
    // !mark(4:9)
    const body = {
        AgentId: agentId,
        Name: agentName,
        LLM: {
            Url: "https://your-custom-llm-service/chat/completions",
            ApiKey: "your_api_key",
            Model: "your_model",
            SystemPrompt: "è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„çŸ¥è¯†åº“å†…å®¹ç”¨å‹å¥½çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸åœ¨çŸ¥è¯†åº“ä¸­ï¼Œè¯·ç¤¼è²Œçš„å‘Šè¯‰ç”¨æˆ·æˆ‘ä»¬æ²¡æœ‰ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ã€‚"
        },
        TTS: {
            Vendor: "ByteDance",
            Params: {
                "app": {
                    "appid": "zego_test",
                    "token": "zego_test",
                    "cluster": "volcano_tts"
                },
                "audio": {
                    "voice_type": "zh_female_wanwanxiaohe_moon_bigtts"
                }
            }
        }
    };
    // sendRequest æ–¹æ³•å°è£…äº†è¯·æ±‚çš„ URL å’Œå…¬å…±å‚æ•°ã€‚è¯¦æƒ…å‚è€ƒï¼šhttps://doc-zh.zego.im/aiagent-server/api-reference/accessing-server-apis
    return this.sendRequest<any>(action, body);
}
```

</Step>
</Steps>

è‡³æ­¤æ‚¨å°±å¯ä»¥ä¸è‡ªå®šä¹‰ LLM è¿›è¡Œå¯¹è¯äº†ã€‚

### æœ€ä½³å®è·µ

è¯¦ç»†ä½¿ç”¨æ¡ˆä¾‹è¯·å‚è€ƒ [ç»“åˆ RAG ä½¿ç”¨ AI Agent](./../best-practices/use-ai-agent-with-rag.mdx)ã€‚

## å¦‚ä½•é…ç½®å¤šæ¨¡æ€ LLM - é…ç½®æ–‡å­—è¾“å…¥è¯­éŸ³è¾“å‡ºçš„ LLM <a id="configure-multimodal-llm" />
ç›¸æ¯”çº¯æ–‡æœ¬è¾“å…¥è¾“å‡ºçš„ LLM è¯·æ±‚ï¼Œè¾“å‡ºä¸ºéŸ³é¢‘çš„è¯·æ±‚ä½“ä¸­å¤šäº†æŒ‡å®šè¾“å‡ºæ¨¡æ€çš„ `modalities` å­—æ®µå’ŒæŒ‡å®šè¾“å‡ºéŸ³è‰²å’Œæ ¼å¼çš„ `audio` å­—æ®µï¼Œè¿™äº›å­—æ®µåœ¨ `LLM.Params` å‚æ•°ä¸­æŒ‡å®šã€‚

<Note title="è¯´æ˜">
è¯·åœ¨è°ƒç”¨ [CreateAgentInstance](./../api-reference/agent-instance-management/create-agent-instance.mdx) æˆ– [CreateDigitalHumanAgentInstance](./../api-reference/agent-instance-management/create-digital-human-agent-instance.mdx) æ¥å£çš„æ—¶å€™ï¼Œåœ¨ `AdvancedConfig` ä¸­ æŒ‡å®š `DisableTTS:true` æ¥ç¦ç”¨ TTS åŠŸèƒ½ã€‚
</Note>

ä»¥ä¸‹ä¸º LLM è¾“å‡ºéŸ³é¢‘çš„å‚æ•°é…ç½®ç¤ºä¾‹ï¼š
```json
"LLM": {
    "Url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
    "ApiKey": "your_api_key",
    "Model": "qwen3-omni-flash",
    "SystemPrompt": "ä½ æ˜¯å°æ™ºï¼Œæˆå¹´å¥³æ€§ï¼Œæ˜¯**å³æ„ç§‘æŠ€åˆ›é€ çš„é™ªä¼´åŠ©æ‰‹**ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œèªæ˜ç¿æ™ºã€çƒ­æƒ…å‹å–„ã€‚\nå¯¹è¯è¦æ±‚ï¼š1ã€æŒ‰ç…§äººè®¾è¦æ±‚ä¸ç”¨æˆ·å¯¹è¯ã€‚\n2ã€ä¸èƒ½è¶…è¿‡100å­—ã€‚",
    "Temperature": 1,
    "TopP": 0.7,
    "Params": {
        "max_tokens": 1024,
        "stream":true,
        "stream_options":{"include_usage":true},
        "modalities":["text","audio"],
        "audio":{"voice":"Cherry","format":"pcm"}
    }
}
```

## æ ¡éªŒ LLM å‚æ•°

å¦‚æœæ‚¨åœ¨é…ç½® LLM å‚æ•°æ—¶ï¼Œä¸ç¡®å®šå‚æ•°æ˜¯å¦æ­£ç¡®ï¼Œå¯ä»¥ä½¿ç”¨ LLM å‚æ•°æ ¡éªŒå™¨è¿›è¡Œæ ¡éªŒã€‚

- é€‰æ‹©åˆé€‚çš„ LLM å‚å•†ã€é€‰æ‹©å¼€å‘è¯­è¨€ã€å¡«å†™ LLM å‚æ•°åå³å¯ç‚¹å‡»æ ¡éªŒæŒ‰é’®è¿›è¡Œæ ¡éªŒã€‚
- ç”¨æˆ·æ¶ˆæ¯å¯ä»¥å¡«å†™ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ç”¨äºæµ‹è¯• LLM æ˜¯å¦èƒ½æ­£ç¡®ç†è§£ç”¨æˆ·æ„å›¾å¹¶è¿”å›æ­£ç¡®çš„å“åº”ã€‚å¦‚æœä¸å¡«å†™ï¼Œé»˜è®¤ä½¿ç”¨â€œä½ å¥½,è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±â€ä½œä¸ºç”¨æˆ·æ¶ˆæ¯ã€‚
- â€œç¤ºä¾‹ä»£ç â€ Tab ä¸ºå¯¹åº”è¯­è¨€çš„ç¤ºä¾‹ä»£ç ã€‚
- â€œå®é™…è¯·æ±‚LLMå‚æ•°â€ ä¸ºå®é™…å‘é€ç»™ LLM çš„å‚æ•°ï¼Œæ‚¨å¯ä»¥æ ¹æ®å¯¹æ¯”æ‰€é€‰å‚å•†çš„å®˜æ–¹æ–‡æ¡£ï¼Œç¡®ä¿å‚æ•°å¡«å†™æ­£ç¡®ã€‚

<LLMValidator lang="zh" />