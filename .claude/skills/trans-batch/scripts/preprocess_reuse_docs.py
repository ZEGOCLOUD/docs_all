#!/usr/bin/env python3
"""
é¢„å¤„ç†å…¨å¤ç”¨æ–‡æ¡£ï¼Œå°è¯•æ›¿æ¢å¼•ç”¨è·¯å¾„

å…¨å¤ç”¨æ–‡æ¡£ç‰¹å¾ï¼š
- é™¤äº† frontmatter å¤–åªæœ‰ä¸¤è¡Œéç©ºå†…å®¹
- ä¸€è¡Œä»¥ import Content from å¼€å¤´
- å¦ä¸€è¡Œä»¥ <Content å¼€å¤´

å¤„ç†é€»è¾‘ï¼š
1. æå– import è·¯å¾„
2. å°†è·¯å¾„ä¸­çš„ /zh/ æ›¿æ¢ä¸º /en/
3. æ£€æŸ¥å¯¹åº”çš„è‹±æ–‡æ–‡æ¡£æ˜¯å¦å­˜åœ¨
4. å¦‚æœå­˜åœ¨ï¼šæ›¿æ¢è·¯å¾„å¹¶ä¿å­˜ï¼Œæ ‡è®°ä¸º"å·²è§£å†³"
5. å¦‚æœä¸å­˜åœ¨ï¼šæ ‡è®°ä¸º"éœ€è¦ç¿»è¯‘"

IMPORTANT: æ­¤è„šæœ¬å¿…é¡»åœ¨ workspace æ ¹ç›®å½•ä¸‹è¿è¡Œã€‚
"""

import sys
import json
import re
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional


def get_workspace_root() -> Path:
    """
    Find the workspace root directory by looking for marker files.

    Marker files (in order of priority):
    - docuo.config.json or docuo.config.en.json (DOCUO project)
    - .git (Git repository)
    - package.json (Node.js project)

    Returns:
        Path: workspace root directory

    Note:
        Falls back to current directory if no markers found.
    """
    current = Path.cwd().resolve()

    # Search up to 10 levels up
    for _ in range(10):
        markers = [
            'docuo.config.json',
            'docuo.config.en.json',
            '.git',
            'package.json'
        ]

        for marker in markers:
            if (current / marker).exists():
                return current

        parent = current.parent
        if parent == current:  # Reached root
            break
        current = parent

    # Fallback to current directory if no markers found
    return Path.cwd()


def extract_import_path(content: str) -> str:
    """
    æå– import è·¯å¾„

    Args:
        content: æ–‡ä»¶å†…å®¹

    Returns:
        str: import è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    # åŒ¹é… import Content from "..."; æˆ– import Content from '...';
    match = re.search(r'import Content from ["\'](.+?)["\']', content)
    if match:
        return match.group(1)
    return None


def replace_import_path(content: str, old_path: str, new_path: str) -> str:
    """
    æ›¿æ¢ import è·¯å¾„

    Args:
        content: æ–‡ä»¶å†…å®¹
        old_path: åŸå§‹è·¯å¾„
        new_path: æ–°è·¯å¾„

    Returns:
        str: æ›¿æ¢åçš„å†…å®¹
    """
    return content.replace(old_path, new_path)


def process_reuse_doc(file_path: Path, target_path: Path) -> Dict[str, Any]:
    """
    å¤„ç†å•ä¸ªå…¨å¤ç”¨æ–‡æ¡£

    Args:
        file_path: æºæ–‡ä»¶è·¯å¾„
        target_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„

    Returns:
        dict: å¤„ç†ç»“æœ
    """
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå– import è·¯å¾„
        import_path = extract_import_path(content)
        if not import_path:
            return {
                'source': str(file_path),
                'target': str(target_path),
                'status': 'failed',
                'reason': 'no_import_found',
                'line_count': len(content.splitlines())
            }

        # æ›¿æ¢è·¯å¾„ä¸­çš„ /zh/ ä¸º /en/
        new_import_path = import_path.replace('/zh/', '/en/')

        # è®¡ç®—è‹±æ–‡æ–‡æ¡£çš„ç»å¯¹è·¯å¾„
        # import è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„ï¼ˆä»¥ / å¼€å¤´ï¼‰ï¼Œéœ€è¦ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
        if import_path.startswith('/'):
            # ç»å¯¹è·¯å¾„ï¼šç›¸å¯¹äºå·¥ä½œç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
            project_root = get_workspace_root()
            new_import_path_abs = project_root / new_import_path.lstrip('/')
        else:
            # ç›¸å¯¹è·¯å¾„ï¼šç›¸å¯¹äºæ–‡ä»¶æ‰€åœ¨ç›®å½•
            source_dir = file_path.parent
            new_import_path_abs = (source_dir / new_import_path).resolve()

        # æ£€æŸ¥è‹±æ–‡æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        if not new_import_path_abs.exists():
            return {
                'source': str(file_path),
                'target': str(target_path),
                'status': 'need_translate',
                'original_import_path': import_path,
                'new_import_path': new_import_path,
                'reason': 'en_doc_not_found',
                'line_count': len(content.splitlines())
            }

        # æ›¿æ¢è·¯å¾„å¹¶ä¿å­˜
        new_content = replace_import_path(content, import_path, new_import_path)

        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        target_path.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥ç›®æ ‡æ–‡ä»¶
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return {
            'source': str(file_path),
            'target': str(target_path),
            'status': 'resolved',
            'original_import_path': import_path,
            'new_import_path': new_import_path,
            'resolved_to': str(new_import_path_abs),
            'line_count': len(content.splitlines())
        }

    except Exception as e:
        return {
            'source': str(file_path),
            'target': str(target_path),
            'status': 'failed',
            'reason': str(e),
            'line_count': 0
        }


def preprocess_reuse_docs(reuse_docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡é¢„å¤„ç†å…¨å¤ç”¨æ–‡æ¡£

    Args:
        reuse_docs: å…¨å¤ç”¨æ–‡æ¡£åˆ—è¡¨

    Returns:
        list: å¤„ç†ç»“æœåˆ—è¡¨
    """
    results = []

    for file_info in reuse_docs:
        file_path = Path(file_info['path'])
        target_path = Path(file_info['target_path'])

        result = process_reuse_doc(file_path, target_path)
        results.append(result)

    return results


def main():
    parser = argparse.ArgumentParser(
        description='é¢„å¤„ç†å…¨å¤ç”¨æ–‡æ¡£ï¼Œå°è¯•æ›¿æ¢å¼•ç”¨è·¯å¾„',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹ï¼š
  %(prog)s scan_result.json
  %(prog)s scan_result.json --output-dir core_products/real-time-voice-video/en/flutter
  %(prog)s scan_result.json --output-file custom/path/preprocess.json
        '''
    )

    parser.add_argument('scan_result', help='æ‰«æç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆscan_result.jsonï¼‰')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä» scan_result.json çš„ target_directory å­—æ®µè¯»å–ï¼‰')
    parser.add_argument('--output-file', default='preprocess_result.json', help='è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼špreprocess_result.jsonï¼‰')
    parser.add_argument('--stdout', action='store_true', help='è¾“å‡ºåˆ° stdout è€Œä¸æ˜¯æ–‡ä»¶ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰')

    args = parser.parse_args()

    scan_result_file = args.scan_result

    # è¯»å–æ‰«æç»“æœ
    try:
        with open(scan_result_file, 'r', encoding='utf-8') as f:
            scan_result = json.load(f)
    except Exception as e:
        print(f"Error: Failed to read scan result file: {e}", file=sys.stderr)
        sys.exit(1)

    # è®¡ç®—è¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        # ä» scan_result.json ä¸­è¯»å– target_directory
        target_directory = scan_result.get('target_directory')
        if target_directory:
            output_dir = Path(target_directory)
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå¦‚æœæ²¡æœ‰ target_directory å­—æ®µï¼Œä½¿ç”¨ scan_result æ–‡ä»¶æ‰€åœ¨ç›®å½•
            output_dir = Path(scan_result_file).parent

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶ï¼š{scan_result_file}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_dir}")

    # æå–å…¨å¤ç”¨æ–‡æ¡£
    reuse_docs = [f for f in scan_result.get('files', []) if f.get('is_reuse_doc', False)]

    if not reuse_docs:
        print("\nâš ï¸  æœªæ‰¾åˆ°å…¨å¤ç”¨æ–‡æ¡£")
        results = []
    else:
        print(f"ğŸ”„ æ‰¾åˆ° {len(reuse_docs)} ä¸ªå…¨å¤ç”¨æ–‡æ¡£ï¼Œå¼€å§‹é¢„å¤„ç†...")

        # é¢„å¤„ç†å…¨å¤ç”¨æ–‡æ¡£
        results = preprocess_reuse_docs(reuse_docs)

        # ç»Ÿè®¡ç»“æœ
        resolved_count = sum(1 for r in results if r['status'] == 'resolved')
        need_translate_count = sum(1 for r in results if r['status'] == 'need_translate')
        failed_count = sum(1 for r in results if r['status'] == 'failed')

        print(f"\nğŸ“Š é¢„å¤„ç†ç»“æœï¼š")
        print(f"   âœ… å·²è§£å†³ï¼š{resolved_count} ä¸ª")
        print(f"   ğŸ”€ éœ€ç¿»è¯‘ï¼š{need_translate_count} ä¸ª")
        print(f"   âŒ å¤±è´¥ï¼š{failed_count} ä¸ª")

    # è¾“å‡ºç»“æœ
    if args.stdout:
        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šè¾“å‡ºåˆ° stdout
        print(json.dumps(results, indent=2, ensure_ascii=False))
    else:
        # æ–°ç‰ˆæœ¬ï¼šä¿å­˜åˆ°æ–‡ä»¶
        output_file = output_dir / args.output_file
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… é¢„å¤„ç†ç»“æœå·²ä¿å­˜ï¼š{output_file}")


if __name__ == '__main__':
    main()
