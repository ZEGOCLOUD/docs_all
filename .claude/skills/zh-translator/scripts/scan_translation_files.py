#!/usr/bin/env python3
"""
æ‰«ææŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆç¿»è¯‘è®¡åˆ’
æ”¯æŒ Markdown å’Œ YAML æ–‡ä»¶ï¼Œè‡ªåŠ¨è¯†åˆ« API æ–‡ä»¶ï¼ˆmdx + yaml å¯¹ï¼‰
"""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict


def scan_directory(directory: str, file_types: List[str] = None) -> List[Dict[str, Any]]:
    """
    é€’å½’æ‰«æç›®å½•ä¸‹æ‰€æœ‰æŒ‡å®šç±»å‹çš„æ–‡ä»¶

    Args:
        directory: è¦æ‰«æçš„ç›®å½•è·¯å¾„
        file_types: è¦åŒ…å«çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œå¦‚ ['.md', '.yaml', '.mdx']

    Returns:
        list: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    """
    if file_types is None:
        file_types = ['.md', '.yaml', '.mdx']

    dir_path = Path(directory)
    if not dir_path.exists():
        print(f"Error: Directory '{directory}' does not exist", file=sys.stderr)
        return []

    files = []
    for file_path in dir_path.rglob('*'):
        if file_path.is_file() and file_path.suffix in file_types:
            # åªå¤„ç†ä¸­æ–‡æ–‡æ¡£ï¼ˆè·¯å¾„ä¸­åŒ…å« /zh/ çš„ï¼‰
            if '/zh/' in str(file_path):
                # è®¡ç®—æ–‡ä»¶è¡Œæ•°
                line_count = 0
                has_doctype_api = False

                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        line_count = len(lines)

                        # æ£€æŸ¥æ˜¯å¦åŒ…å« docType: API
                        for line in lines[:20]:  # åªæ£€æŸ¥å‰ 20 è¡Œ
                            if line.strip() == 'docType: API':
                                has_doctype_api = True
                                break
                except Exception:
                    line_count = 0

                files.append({
                    'path': str(file_path),
                    'relative_path': str(file_path.relative_to(dir_path)),
                    'suffix': file_path.suffix,
                    'line_count': line_count,
                    'size_kb': file_path.stat().st_size / 1024,
                    'has_doctype_api': has_doctype_api  # æ–°å¢å­—æ®µæ ‡è¯†æ˜¯å¦ä¸º API æ–‡ä»¶
                })

    return files


def identify_api_files(files: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è¯†åˆ« API æ–‡ä»¶å¯¹ï¼ˆåŒå mdx å’Œ yamlï¼‰ä»¥åŠ docType: API æ–‡ä»¶

    è§„åˆ™ï¼š
    - åŒ…å« docType: API çš„æ–‡ä»¶è‡ªåŠ¨è·³è¿‡
    - åœ¨ä»»æ„ç›®å½•ä¸‹å­˜åœ¨åŒåçš„ .mdx å’Œ .yaml æ–‡ä»¶
    - è¿™ç±»æ–‡ä»¶åªéœ€è¦ç¿»è¯‘ .yamlï¼Œ.mdx æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„

    Returns:
        dict: {
            'doctype_api_files': [...],      # docType: API æ–‡ä»¶ï¼ˆè‡ªåŠ¨è·³è¿‡ï¼‰
            'mdx_yaml_pairs': {              # åŒå mdx+yaml æ–‡ä»¶å¯¹
                'yaml_files': [...],         # éœ€è¦ç¿»è¯‘çš„ yaml
                'mdx_files': [...]           # è·³è¿‡çš„ mdxï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
            },
            'regular_files': [...]           # æ™®é€šæ–‡ä»¶
        }
    """
    result = {
        'doctype_api_files': [],  # docType: API æ–‡ä»¶
        'mdx_yaml_pairs': {
            'yaml_files': [],  # éœ€è¦ç¿»è¯‘çš„ yaml
            'mdx_files': []    # è·³è¿‡çš„ mdx
        },
        'regular_files': []
    }

    # ç¬¬ä¸€æ­¥ï¼šåˆ†ç¦» docType: API æ–‡ä»¶
    non_doctype_files = []
    for file_info in files:
        if file_info.get('has_doctype_api', False):
            result['doctype_api_files'].append(file_info)
        else:
            non_doctype_files.append(file_info)

    # ç¬¬äºŒæ­¥ï¼šåœ¨æ‰€æœ‰æ–‡ä»¶ä¸­æŸ¥æ‰¾åŒåçš„ mdx å’Œ yaml å¯¹ï¼ˆä¸é™äº api-reference ç›®å½•ï¼‰
    file_map = defaultdict(lambda: {'.mdx': None, '.yaml': None})

    for file_info in non_doctype_files:
        file_path_obj = Path(file_info['path'])
        basename = file_path_obj.stem  # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
        suffix = file_info['suffix']

        if suffix in ['.mdx', '.yaml']:
            file_map[basename][suffix] = file_info

    # ç¬¬ä¸‰æ­¥ï¼šåˆ†ç±»æ–‡ä»¶
    for basename, file_dict in file_map.items():
        mdx_file = file_dict['.mdx']
        yaml_file = file_dict['.yaml']

        if mdx_file and yaml_file:
            # æœ‰æˆå¯¹çš„ mdx å’Œ yaml æ–‡ä»¶
            result['mdx_yaml_pairs']['yaml_files'].append(yaml_file)
            result['mdx_yaml_pairs']['mdx_files'].append(mdx_file)
        elif yaml_file:
            # åªæœ‰ yamlï¼ŒæŒ‰æ™®é€šæ–‡ä»¶å¤„ç†
            result['regular_files'].append(yaml_file)
        elif mdx_file:
            # åªæœ‰ mdxï¼ŒæŒ‰æ™®é€šæ–‡ä»¶å¤„ç†
            result['regular_files'].append(mdx_file)

    return result


def create_translation_batches(files: List[Dict[str, Any]], lines_per_batch: int = 5000) -> List[Dict[str, Any]]:
    """
    å°†æ–‡ä»¶ç»„ç»‡æˆç¿»è¯‘æ‰¹æ¬¡

    ç­–ç•¥ï¼š
    - å°æ–‡ä»¶ï¼ˆ< 100 è¡Œï¼‰ï¼šæŒ‰æ–‡ä»¶åˆ†ç»„ï¼Œæ¯æ‰¹å¤šä¸ªæ–‡ä»¶
    - ä¸­ç­‰æ–‡ä»¶ï¼ˆ100-500 è¡Œï¼‰ï¼šæ¯æ‰¹ 1-2 ä¸ªæ–‡ä»¶
    - å¤§æ–‡ä»¶ï¼ˆ> 500 è¡Œï¼‰ï¼šå•ç‹¬æˆæ‰¹ï¼Œå¯èƒ½éœ€è¦åˆ†æ®µç¿»è¯‘

    Args:
        files: æ–‡ä»¶åˆ—è¡¨
        lines_per_batch: æ¯æ‰¹å¤§è‡´çš„ç›®æ ‡è¡Œæ•°

    Returns:
        list: æ‰¹æ¬¡åˆ—è¡¨
    """
    # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼ˆå°æ–‡ä»¶ä¼˜å…ˆï¼‰
    sorted_files = sorted(files, key=lambda x: x['line_count'])

    batches = []
    current_batch = {
        'files': [],
        'total_lines': 0,
        'file_count': 0
    }

    for file_info in sorted_files:
        line_count = file_info['line_count']
        file_size_category = 'small' if line_count < 100 else 'medium' if line_count < 500 else 'large'

        file_info['size_category'] = file_size_category

        # å¤§æ–‡ä»¶ï¼ˆ> 500 è¡Œï¼‰å•ç‹¬æˆæ‰¹
        if file_size_category == 'large':
            # ä¿å­˜å½“å‰æ‰¹æ¬¡
            if current_batch['files']:
                batches.append(current_batch)
                current_batch = {'files': [], 'total_lines': 0, 'file_count': 0}

            # å¤§æ–‡ä»¶å•ç‹¬æˆæ‰¹
            batches.append({
                'files': [file_info],
                'total_lines': line_count,
                'file_count': 1,
                'needs_segmentation': True
            })
        elif file_size_category == 'medium':
            # ä¸­ç­‰æ–‡ä»¶ï¼Œæ£€æŸ¥å½“å‰æ‰¹æ¬¡
            if current_batch['file_count'] >= 2 or current_batch['total_lines'] + line_count > lines_per_batch:
                batches.append(current_batch)
                current_batch = {'files': [], 'total_lines': 0, 'file_count': 0}

            current_batch['files'].append(file_info)
            current_batch['total_lines'] += line_count
            current_batch['file_count'] += 1
        else:
            # å°æ–‡ä»¶ï¼Œå¯ä»¥å¤šä¸ªä¸€æ‰¹
            if current_batch['total_lines'] + line_count > lines_per_batch * 1.5:
                batches.append(current_batch)
                current_batch = {'files': [], 'total_lines': 0, 'file_count': 0}

            current_batch['files'].append(file_info)
            current_batch['total_lines'] += line_count
            current_batch['file_count'] += 1

    # ä¿å­˜æœ€åä¸€ä¸ªæ‰¹æ¬¡
    if current_batch['files']:
        batches.append(current_batch)

    return batches


def print_summary(result: Dict[str, Any]):
    """æ‰“å°æ‰«æç»“æœæ‘˜è¦"""
    print("\n" + "="*70)
    print("ğŸ“Š ç¿»è¯‘æ‰«æç»“æœ")
    print("="*70)

    # docType: API æ–‡ä»¶ç»Ÿè®¡
    doctype_api_files = result.get('doctype_api_files', [])
    print(f"\nâ­ï¸  docType: API æ–‡ä»¶ï¼ˆè‡ªåŠ¨è·³è¿‡ï¼‰ï¼š{len(doctype_api_files)} ä¸ª")
    if doctype_api_files:
        doctype_lines = sum(f['line_count'] for f in doctype_api_files)
        print(f"   æ€»è¡Œæ•°ï¼š{doctype_lines} è¡Œ")
        # æ˜¾ç¤ºå‰ 5 ä¸ªæ–‡ä»¶
        for f in doctype_api_files[:5]:
            print(f"   - {f['relative_path']} ({f['line_count']} è¡Œ)")
        if len(doctype_api_files) > 5:
            print(f"   ... è¿˜æœ‰ {len(doctype_api_files) - 5} ä¸ªæ–‡ä»¶")

    # åŒå mdx+yaml æ–‡ä»¶å¯¹ç»Ÿè®¡
    mdx_yaml_pairs = result.get('mdx_yaml_pairs', {})
    yaml_to_translate = mdx_yaml_pairs.get('yaml_files', [])
    mdx_to_skip = mdx_yaml_pairs.get('mdx_files', [])

    if yaml_to_translate:
        print(f"\nğŸ”— åŒå MDX+YAML æ–‡ä»¶å¯¹ï¼š{len(yaml_to_translate)} å¯¹")
        yaml_lines = sum(f['line_count'] for f in yaml_to_translate)
        mdx_lines = sum(f['line_count'] for f in mdx_to_skip)
        print(f"   âœ… éœ€ç¿»è¯‘ YAMLï¼š{len(yaml_to_translate)} ä¸ª ({yaml_lines} è¡Œ)")
        print(f"   â­ï¸  è·³è¿‡ MDXï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰ï¼š{len(mdx_to_skip)} ä¸ª ({mdx_lines} è¡Œ)")
        # æ˜¾ç¤ºå‰ 5 å¯¹æ–‡ä»¶
        for i, (yaml_file, mdx_file) in enumerate(zip(yaml_to_translate[:5], mdx_to_skip[:5])):
            print(f"   {i+1}. {yaml_file['relative_path']} â†’ {yaml_file['line_count']} è¡Œ")
            print(f"      {mdx_file['relative_path']} â†’ è·³è¿‡")
        if len(yaml_to_translate) > 5:
            print(f"   ... è¿˜æœ‰ {len(yaml_to_translate) - 5} å¯¹æ–‡ä»¶")

    # æ™®é€šæ–‡ä»¶ç»Ÿè®¡
    regular_files = result['regular_files']
    md_files = [f for f in regular_files if f['suffix'] == '.md' or f['suffix'] == '.mdx']
    yaml_files = [f for f in regular_files if f['suffix'] == '.yaml']

    if md_files:
        print(f"\nğŸ“„ Markdown/MDX æ–‡ä»¶ï¼š{len(md_files)} ä¸ª")
        md_lines = sum(f['line_count'] for f in md_files)
        print(f"   æ€»è¡Œæ•°ï¼š{md_lines} è¡Œ")

    if yaml_files:
        print(f"\nğŸ“‹ YAML æ–‡ä»¶ï¼š{len(yaml_files)} ä¸ª")
        yaml_lines = sum(f['line_count'] for f in yaml_files)
        print(f"   æ€»è¡Œæ•°ï¼š{yaml_lines} è¡Œ")

    # æ‰¹æ¬¡ç»Ÿè®¡
    batches = result['batches']
    print(f"\nğŸ“¦ ç¿»è¯‘æ‰¹æ¬¡ï¼š{len(batches)} æ‰¹")
    print(f"   æ€»æ–‡ä»¶æ•°ï¼š{result['total_files']}")
    print(f"   æ€»è¡Œæ•°ï¼š{result['total_lines']}")
    print(f"   å¹³å‡æ¯æ‰¹ï¼š{result['total_lines'] // len(batches) if batches else 0} è¡Œ")

    # å¤§æ–‡ä»¶æç¤º
    large_files = [f for f in result['all_files'] if f.get('size_category') == 'large']
    if large_files:
        print(f"\nâš ï¸  å¤§æ–‡ä»¶ï¼ˆ>500 è¡Œï¼‰ï¼š{len(large_files)} ä¸ª")
        for f in large_files[:5]:  # åªæ˜¾ç¤ºå‰ 5 ä¸ª
            print(f"   - {f['relative_path']} ({f['line_count']} è¡Œ)")
        if len(large_files) > 5:
            print(f"   ... è¿˜æœ‰ {len(large_files) - 5} ä¸ªå¤§æ–‡ä»¶")


def print_batch_plan(batches: List[Dict[str, Any]], show_details: bool = True):
    """æ‰“å°ç¿»è¯‘æ‰¹æ¬¡è®¡åˆ’"""
    print("\n" + "="*70)
    print("ğŸ“‹ ç¿»è¯‘æ‰¹æ¬¡è®¡åˆ’")
    print("="*70)

    for i, batch in enumerate(batches, 1):
        print(f"\næ‰¹æ¬¡ {i}/{len(batches)} ({batch['total_lines']} è¡Œ, {batch['file_count']} ä¸ªæ–‡ä»¶)")

        if show_details or batch.get('needs_segmentation'):
            for j, file_info in enumerate(batch['files'], 1):
                flag = ""
                if file_info.get('size_category') == 'large':
                    flag = " [å¤§æ–‡ä»¶-éœ€åˆ†æ®µ]"
                elif file_info.get('size_category') == 'medium':
                    flag = " [ä¸­æ–‡ä»¶]"

                print(f"  {j}. {file_info['relative_path']}{flag}")
                print(f"     â†’ {file_info['line_count']} è¡Œ, {file_info['size_kb']:.1f} KB")
        else:
            # ç®€ç•¥æ˜¾ç¤º
            file_names = [f['relative_path'].split('/')[-1] for f in batch['files']]
            print(f"  æ–‡ä»¶ï¼š{', '.join(file_names)}")

        if batch.get('needs_segmentation'):
            print(f"  âš ï¸  æ­¤æ‰¹æ¬¡åŒ…å«å¤§æ–‡ä»¶ï¼Œç¿»è¯‘æ—¶å¯èƒ½éœ€è¦åˆ†æ®µå¤„ç†")


def main():
    if len(sys.argv) < 2:
        print("Usage: scan_translation_files.py <directory> [lines_per_batch]", file=sys.stderr)
        print("Example: scan_translation_files.py docs/zh/product 500", file=sys.stderr)
        print("Example: scan_translation_files.py docs/zh/server/api-reference", file=sys.stderr)
        sys.exit(1)

    directory = sys.argv[1]
    lines_per_batch = int(sys.argv[2]) if len(sys.argv) > 2 else 5000

    print(f"ğŸ” æ‰«æç›®å½•ï¼š{directory}")
    print(f"âš™ï¸  æ¯æ‰¹ç›®æ ‡è¡Œæ•°ï¼š{lines_per_batch}")

    # æ‰«ææ–‡ä»¶
    files = scan_directory(directory)

    if not files:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶")
        print("æç¤ºï¼šç¡®ä¿ç›®å½•è·¯å¾„æ­£ç¡®ï¼Œä¸”åŒ…å« /zh/ å­ç›®å½•çš„æ–‡ä»¶")
        sys.exit(0)

    # è¯†åˆ« API æ–‡ä»¶
    categorized = identify_api_files(files)

    # åˆå¹¶æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶
    mdx_yaml_pairs = categorized.get('mdx_yaml_pairs', {})
    yaml_files = mdx_yaml_pairs.get('yaml_files', [])
    regular_files = categorized['regular_files']

    files_to_translate = yaml_files + regular_files
    all_files = (
        categorized.get('doctype_api_files', []) +
        mdx_yaml_pairs.get('yaml_files', []) +
        mdx_yaml_pairs.get('mdx_files', []) +
        regular_files
    )

    # åˆ›å»ºç¿»è¯‘æ‰¹æ¬¡ï¼ˆåªç¿»è¯‘é docType: API çš„æ–‡ä»¶ï¼‰
    batches = create_translation_batches(files_to_translate, lines_per_batch)

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_lines = sum(f['line_count'] for f in files_to_translate)

    # æ„å»ºç»“æœ
    result = {
        'directory': directory,
        'total_files': len(files_to_translate),
        'total_lines': total_lines,
        'doctype_api_files': categorized.get('doctype_api_files', []),
        'mdx_yaml_pairs': categorized.get('mdx_yaml_pairs', {}),
        'regular_files': regular_files,
        'all_files': all_files,
        'files_to_translate': files_to_translate,
        'batches': batches,
        'lines_per_batch': lines_per_batch
    }

    # æ‰“å°ç»“æœ
    print_summary(result)
    print_batch_plan(batches, show_details=True)

    # è¾“å‡º JSON æ ¼å¼ä¾›è„šæœ¬ä½¿ç”¨
    print("\n" + "="*70)
    print("ğŸ“„ JSON è¾“å‡ºï¼ˆä¾›åç»­å¤„ç†ï¼‰")
    print("="*70)
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == '__main__':
    main()
